{
  "data": {
    "allBloggerPost": {
      "edges": [
        {
          "node": {
            "kind": "blogger#post",
            "slug": "fp-cheat-sheet-for-absolute-beginners",
            "title": "FP Cheat Sheet For Absolute Beginners",
            "url": "http://blog.amitashukla.in/2020/05/fp-cheat-sheet-for-absolute-beginners.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2020-05-14",
                "slug": "fp-cheat-sheet-for-absolute-beginners",
                "title": "FP Cheat Sheet For Absolute Beginners"
              },
              "rawMarkdownBody": "\nFunctional Programming languages, in general, turn into a challenging venture at the very start. On one hand, it sounds simple when all you have to do is use functions instead of loads of language constructs. [Who needs a loop when we have folds](https://blog.amitashukla.in/2019/07/unfolding-folds.html)! But there is another problem. Now we don't know which function we need to use when. A lot of times for coding a simple task, I had to rush to the docs, search extensively, only to discover half an hour later that all I had to use was a `lift`. or a `fold`. or a `map`. Aghhh! At this learning level, what comes handy is a pool of functions to refer to first before jumping into the sea of all the libraries and functions ever created. Gradually over time, these functions (and their type signatures) embed themselves on our minds, and then programming becomes a breeze.\n\n  \n\n\n[![](https://1.bp.blogspot.com/-of1367G_UEw/Xr0YgC8QLyI/AAAAAAAANWo/6zVvXqXDTC4_GSrzMsF1X6q9Gf2hUKCgwCK4BGAsYHg/s320/meme.jpg)](https://1.bp.blogspot.com/-of1367G_UEw/Xr0YgC8QLyI/AAAAAAAANWo/6zVvXqXDTC4_GSrzMsF1X6q9Gf2hUKCgwCK4BGAsYHg/meme.jpg)\n\n  \n\n\nI have titled this post as something for 'absolute beginners', but this is what I have used most of the time, so I consider myself no more than an absolute beginner. And there is so much more, I guess I will remain an absolute beginner for ages to come. And if you're an absolute beginner, having a basic understanding of these functions will help you sail through a lot of code reading and writing.\n\n  \n\n\n## How to read this cheat sheet\n\nIn the given cheat sheet, I have used syntax in Haskell. Even if you don't understand Haskell, and you have never used it, with a little bit of syntax knowledge you will see that it is similar to Python with types sprinkled. As we progress, I may use the functions used before somewhere later, but I have kept this really small so just hover over the page and you'll find it. Let's now go over the basic syntax in Haskell first. If you know Haskell basic syntax, you can [skip this section](#fp_cheat_sheet) entirely.\n\n  \n\n\n### Function Syntax\n\nIn Haskell, everything is a function. These functions can be composed together, in turn creating other functions. Each function begins with its name. And then the input and output types. One thing here we need to remember here is this: **all functions take exactly one parameter**. You may obviously ask, then what do you do when we need more that one parameter? From the current function you return another function that again takes one parameter. In fact, there is not much emphasis on what a function 'returns'. There is no such distinction. The emphasis is on what is the **type signature**. A type signature is just an arrow separated list of what type is the input and what type is the output. Let's go over an example.\n\n  \n\n\nLet's define a function that takes an integer, adds 1, and returns another integer:  \n\n\n      addOne :: Int -> Int\n      addOne x = x + 1\n\n      \n\nNow this goes by the law, as `addOne` needs to take only 1 parameter. Let's move over to another function `add`, that takes two numbers and adds them to return another number:\n\n      add :: Int -> Int -> Int\n      add x y = x + y\n\n      \n\nThis function `add` actually takes one param only, that is the first integer x, and then it returns another function, that takes the second integer y and then returns the final value. So now I am going to cease writing (and stop thinking) in terms of what a function takes as input, and what it returns as output. Instead, let us think of it in terms of what the type signature is.\n\nAlso, functions can be named as symbols also. In this cheat sheet, I have mentioned the common name for the functions written as symbols.  \n\n\n  \n\n\n### Point Free Notation\n\nRemember in mathematical equations how we could cancel a variable from both sides of an equation? We can do something similar here, but of course, there are some conditions. One that I use is this: _We can remove an input parameter name, if it is the last parameter and is being used on both sides of the function_. e.g. `addOne` can be shortened as:\n\n      addOne :: Int -> Int\n      addOne = (+1)\n\n      \n\nNow, this is not a strict rule, and I am not sure how valid this rule stands. We can read more about it in the [Haskell wiki](https://wiki.haskell.org/Pointfree).\n\nPoint free notation makes the code look a lot cleaner, and more importantly, it is very useful in composing functions together. If we don't understand function composition, we can think of Unix pipes, where, the output of one command goes as input to another command. Just as easily we can 'pipe' our functions together by using point-free notation.\n\n  \n\n\n### List Syntax\n\nLists in Haskell are just written by wrapping comma-separated elements in square brackets. For representing types as a list of some other type, say `Int`, can be written as `[Int]`. For a generic type `a`, a list of type `a` is written as `[a]`.\n\n  \n\n\nI am purposefully not going into more details of Haskell syntax, as I want this to be focussed on general FP and not particularly Haskell. There are plenty of resources that we can learn Haskell from and I am trying hard to not convert this post into a Haskell tutorial.\n\n## FP Cheat Sheet\n\nHaving said that, here is the list of functions, definitions, constructs I keep coming back to again and again, whenever I have to read FP code or write a functional style code.  \n\n\n  \n\n\nHope this list would be helpful to someone (other than me!). All these functions are a topic in themselves and deserve a separate blog post for each of them. I also have tried to explain a lot of such FP practices using Scala and Haskell [here](https://blog.amitashukla.in/2019/07/unfolding-folds.html), [here](https://blog.amitashukla.in/2017/06/implement-functional-list-from-scratch-scala.html), [here](https://blog.amitashukla.in/2017/03/tail-recursion-in-functional-programming.html) and [here](https://blog.amitashukla.in/2017/02/why-functional-programming.html). I have also refrained from mentioning the laws associated with type classes to which most of these functions belong, but they also form an interesting read.\n"
            },
            "published": "2020-05-14T15:40:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "nlp-101",
            "title": "NLP 101",
            "url": "http://blog.amitashukla.in/2020/03/nlp-101.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2020-03-26",
                "slug": "nlp-101",
                "title": "NLP 101"
              },
              "rawMarkdownBody": "\nIn this post, I would go over a few commonly used Natural Language Processing techniques. There's a lot of emphasis on what techniques to use for processing data, be it for data analysis, or data science, or big data depending on the scenario. But just like for Physics problems we assume negligible air resistance, friction, etc., for data problems we assume negligible poor quality data. In real life though, poor quality data is not so negligible. In fact, it is substantial and significant effort goes into data preparation before it is ready to be consumed by our data science models.  \n  \nWe will be talking about these cleaning efforts here.  \n  \n\n\n[![](https://i.redd.it/pqtv2tnlwpb41.jpg)](https://i.redd.it/pqtv2tnlwpb41.jpg)\n\n  \nWhen I say 'cleaning up the data' what does it actually mean? Mostly it depends on your problem. At first, you may get your data from some source in a very unstructured format, like, from a website. For extracting the content of a web page, you would scrape through it, and with that, you would get a lot of gibberish along with the actual content. You might not need all of it though.  \n  \nIn this post, I will walk through where I applied it in my project: [Relevance of News Articles w.r.t. Economic News](https://github.com/amita-shukla/nlp-economic-news). Given a number of news articles, the goal is to detect if that article is relevant to U.S. economy (I'm choosing U.S. because that's the data set I got from here). This project is mainly text-heavy, so I will move ahead with discussing Natural Language Processing techniques I used.  \n  \nTo begin with, from all the news articles, I have chosen a random article, let's call it `sample_text`:  \n  \n  \n\n\n### Clean HTML\n\nThe first step is to eliminate the HTML style tags. Now for this purpose, the first thought that comes up is to use regex. However, it soon got a bit complicated...  \nAnd then I came across [this](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454?stw=2#1732454):  \n  \n\n\n[![](https://1.bp.blogspot.com/-eH4h7c8eN_w/XnZ09LAtTnI/AAAAAAAAM1A/pjBimgQsWpkgl1guCDHTdU3Jh8HY_P87wCLcBGAsYHQ/s640/stackoverflow_regex_parser.png)](https://1.bp.blogspot.com/-eH4h7c8eN_w/XnZ09LAtTnI/AAAAAAAAM1A/pjBimgQsWpkgl1guCDHTdU3Jh8HY_P87wCLcBGAsYHQ/s1600/stackoverflow_regex_parser.png)\n\n  \n  \nAnd therefore, I went ahead to use the well-known python library BeautifulSoup.  \n  \n  \n\n\n### Process Single Quotes\n\nNow as you see in the sample_text, there are a lot of special characters there. On some investigation, I observed that the pattern `'\\x89Ûª'` is basically the substitute of an apostrophe or a single quote. Therefore, particular to this data, I removed the pattern:  \n  \n  \n\n\n### Expand Contractions\n\nBut now the question that arises: do we want these apostrophes to processed as single words later? Suppose, if a word is _America's_, I know that the important word here is _America_ and not the apostrophe. But this might get treated as a separate word later. Therefore, I need to **decontract** these words, meaning I expand these words into their natural form. How to do it? Just by using simple regex replace.  \n  \n  \nNow this is not entirely accurate because I see words such as _he's_, or _let's_, which get transformed into _he is_ and _let is_ respectively. But I chose to ignore them as these words are unimportant and would get eliminated later.  \n  \n\n\n### Remove Special Characters\n\nAs you see in the `sample_text3` above, there are still some special characters left that seem to add no meaning to the content of news articles. Time to extract them out.  \n  \n  \n\n\n### Trim Extra Spaces\n\nIn the above part section, I substituted the special characters with spaces `' '` instead of an empty string `''`.  \n  \n  \nThis was done after careful consideration, because some characters were actually acting as hyphens (-) and replacing hyphens with nothing resulted in two words joined together. And this would have been difficult to separate out. Hence, just trim these extra spaces.  \n  \n\n\n### Tokenize words\n\nNow that we have dealt with the processing on the complete text, we can go on now to take things word-wise. But how do we create words out of text (This is called **tokenization**)? It's simple: split by space. But is it this simple? Because when we treat text as just a bunch of characters separated by spaces, we create a lot of meaning-less words when we split such a text. This is because, practically, text contains punctuation too. So if we split this text by spaces, what we get is a lot of words with punctuation attached: which for a program these are completely new words.  \n\n\n  \n\n\nSo what? You would say. Just remove the punctuation marks! I tried something like this:  \n  \nAt least for my case, this did not turn out to be that simple. Because while removing punctuation marks and then splitting the text by space sanitized my words, a lot of meaningful words got lost. e.g. _U.S.A._: this word gets split into 3 separate words: _U, S, A_. Totally meaningless.  \n  \nThe Solution I derived was using the function `word_tokenize` from `nltk` library, which is more intelligent in generating such tokens.  \n  \nFor a term like _u.s.a._  \n  \n  \nFor our `sample_text`, these were the tokens generated. Observe that these tokens have periods and commas and other punctuation generated as separate tokens, which can be filtered as given in the code above. But `word_tokenize` from `nltk` is smart enough in not splitting all the words by punctuation, such as the phrases _28-year-old_ and _U.S._ are treated as single tokens.  \n  \nObviously, this generic tokenizer is not fool-proof, as you would see some totally useless tokens generated, such as _years.Poland_. But this is a trade-off: you can either decide to handle each and every special case yourself, or give way to a bit more generalization.  \n\n\n  \n\n\nWhat is to be done with these token you ask? Let's move on to the next step.\n\n  \n\n\n### Stem Text\n\nThis is an important lesson (and the most commonly used) when it comes to Natural Language Processing.\n\nWhen we want to process the data, we usually need to determine the count of the occurrences of a word. For example, for our problem to detect economic news for US economy, we may need to count the number of times (frequency) the words such as _economy_, _America_, _USA_, _dollars_ etc occur in a given news article. But, as these articles are written in natural English, each English word may occur in a different form, such as, for _economy_different words can be _economic, economical, economics_ etc. Now, these words are to be treated in the same way by our model. How to do that? By reducing all these words to the same word, i.e. by reducing it to its root form.\n\nSo, _economy_ gets reduced to_economi_.\n\nThis reduction of words to its canonical roots is achieved by two techniques, Stemming and Lemmatization. Let's go over both of them.\n\n  \n\n\n#### Stemming v/s Lemmatization\n\nWhile the purpose of both techniques is the same, the results are quite different. Stemming relies on a set of certain rules to derive the root of a word. In a linguistic sense, these derived roots might not be actual words. Consider that Stemming applies a formula for a word to derive the result. It may remove prefixes, suffixes etc.\n\nLemmatization, on the other hand, relies heavily on linguistics knowledge. A proper dictionary, vocabulary and morphological analysis (the study of how a word is formed, from what language(s) etc.) is needed.\n\nWhat do we need for our purpose? I tried both:  \n  \n\n\n#### Stemming\n\nI used the `PorterStemmer` from `nltk` library for this purpose:  \n  \n  \n\n\n#### Lemmatization\n\nI used the `WordNetLemmatizer` from the nltk library for this purpose:  \n  \n  \n\n\n-   Though lemmatizer looks better to the human eye, it fails to solve our purpose. This is because of the way we're going to use these processed tokens. On passing these tokens to some vectorizer later (in very simple terms, [**vectorizers**](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) are used to turn text into vectors, to be processed later by the model), the number of features using stemmer turn out to be less than what lemmatizer produced. You can think of 'number of features' as the number of unique words generated. The frequency of these unique words decides how much they dominate the model results, hence acting as a feature. As the lemmatizer tries to generate a perfect English language word (lemma), it generates a lot more unique root words than the Stemmer overall. The number of features needs to calibrated very carefully for the overall performance of our model (threw me an OutOfMemory error), or even, may cause our data to [**overfit**](https://en.wikipedia.org/wiki/Overfitting).\n-   Theoretically too, a Stemmer is far simpler, and faster than Lemmatizer.\n-   Lemmatizer is stricter than Stemmer.\n-   Hence, for data science problems where the focus is not on the linguistics and it's not a language application but on using the text as input, we do not need such aggressive and perfect reduction of words that Lemmatizer provides. Stemming is usually sufficient.\n\n  \n\n\n### Process All\n\nTime to process all these steps together to get our nice, clean data!  \n  \n\n\n  \nWell, that's all for this post now. And this was just the pre-processing I covered here. A lot more insight about your data is needed before feeding your input to a model. For this problem, you can check out the rest of the notebook [here](https://github.com/amita-shukla/nlp-economic-news/blob/master/news_relevance.ipynb), if you want to see what all I did.  \nI would also suggest going through [the NLTK book](https://www.nltk.org/book/), it helped me a lot while trying to gulp the data set down.\n"
            },
            "published": "2020-03-27T01:06:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "undo-everything-in-git-part-1",
            "title": "Undo everything in Git - Part 1",
            "url": "http://blog.amitashukla.in/2019/12/undo-everything-in-git-part-1.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2019-12-14",
                "slug": "undo-everything-in-git-part-1",
                "title": "Undo everything in Git - Part 1"
              },
              "rawMarkdownBody": "\nI use git for most of my projects now, at work and off work. While I am easily able to save history on git, I need to get back to man pages to be able to manoeuvre through the git history backwards. So I decided to jot down how to rewind your git history, and undo the changes at several stages.  \n  \n\n\n[![](https://imgs.xkcd.com/comics/git.png)](https://imgs.xkcd.com/comics/git.png)\n\n  \nLet's go bottom-up:  \n\n\n-   [Undo git init](#git_init)\n-   [Undo unstaged work](#unstaged_work)\n-   [Undo staged work](#staged_work)\n-   -   [Difference between git rm --cached and git reset HEAD](#rm_vs_reset)\n-   [Undo commit - change commit message and other info](#commit_amend)\n-   [Undo a commit by making another commit on top of it](#commit_revert)\n-   [Undo a commit - and erase its history](#commit_erase_history)\n-   -   [Undo a commit and get back your changes back on staging area](#commit_reset_soft)\n    -   [Undo the commit and don't keep the changes](#commit_reset_hard)\n-   [Undo a commit that is not the latest one](#commit_not_latest)\n-   -   [Rebase](#rebase)\n\n### Undo git init\n\nI created a git repository inside a directory using the git init command. A git repository can be created in an empty repository or can be created with files already in it.  \n  \n\n\n    $ git init\n    Initialized empty Git repository in /home/ashukla/git_repo_demo/.git/\n\n  \nBut I decided I did not want git, or I just initialized git repo at a completely wrong place. To undo creating a git repository, you simply delete the .git repository.  \n  \n\n\n    $ rm -r .git/\n\n  \nThe .git/ directory is the git database that contains all the necessary information about the repo. Deleting the repo deletes the existence of git all altogether and your directory loses all its versioning superpower.  \n  \n\n\n### Undo unstaged work\n\nBut I hope you went ahead with git. You created some files to code on and then some work on them. But your code is like poetry, and you would rather throw it away and start afresh. You have not done anything using git on these files till now.  \n  \n\n\n    $ git status\n    On branch master\n    No commits yet\n    Untracked files:\n      (use \"git add ...\" to include in what will be committed)\n     file1\n     file2\n     file3\n    nothing added to commit but untracked files present (use \"git add\" to track)\n\n  \nAs you see above, we have 3 files which have not yet been touched by git. Git calls these files **untracked**. It simply means that these files have not yet started to be tracked by git. At this stage, anything you do with these files is not tracked by git, and cannot be reverted using git also.  \nTo delete these files, just delete these files.  \n  \n\n\n    $ rm file1 file2 file3\n\n  \n\n\nBut, at some point, you may be at a stage where some of your files are tracked, and some are not. Overall, you have added the work that was going to be committed, and only want to delete the work that was left untracked. For that, you may run the `clean` command. It is recommended that you first see what all would be deleted using -n flag and only then continue deleting:  \n  \n\n\n    $ git clean -n\n    Would remove file1\n    Would remove file2\n    Would remove file3\n\n    $ git clean -f\n    Removing file1\n    Removing file2\n    Removing file3\n\n    $ git status\n    On branch master\n    No commits yet\n\n  \n\n\n### Undo staged work\n\nSo after doing a number of deletions and additions, you finally end up with some work that is up for commit. You stage these changes by using git add command. All the work that is staged goes as a part of the next commit. At this point, note that, it has only been staged and not been commited.  \n  \n\n\n    $ git status\n    On branch master\n    No commits yet\n    Changes to be committed:\n      (use \"git rm --cached ...\" to unstage)\n     new file:   file1\n     new file:   file2\n     new file:   file3\n\n  \nBut what if some changes did not need to go to the next commit? Suppose we need to unstage file3. Git has always been helpful in suggesting the next possible steps, so here we do the same.  \n  \n\n\n    $ git rm --cached file3\n    rm 'file3'\n\n    $ git status\n    On branch master\n    No commits yet\n    Changes to be committed:\n      (use \"git rm --cached ...\" to unstage)\n     new file:   file1\n     new file:   file2\n    Untracked files:\n      (use \"git add ...\" to include in what will be committed)\n     file3\n\n  \nNote here we did what was suggested by git for us to do. There is however another suggestion that is sometimes made by git that is to do a `git reset`. So what's the difference? For that, we first need to understand what the command `git rm` does:  \n\n\n  \n\n\n_Remove files from the index, or from the working tree and the index. git rm will not remove a file from just your working directory_\n\n  \nHere working tree is the tree of committed files, and index is the staging area. In simpler terms, git rm is used to remove a file from a Git repository. It is a convenience method that combines the effect of the default shell rm command with git add . This means that it will first remove a target from the filesystem and then add that removal event to the staging index. Let's try it on terminal:  \n  \n\n\n    $ git rm file3\n    error: the following file has changes staged in the index:\n        file3\n    (use --cached to keep the file, or -f to force removal)\n\n  \nAs we have not committed anything yet, so there is no working tree. Therefore we get a warning.\n\nNow if I go via the shell `rm` command:  \n  \n\n\n    $ rm file3\n    $ git status\n    On branch master\n    No commits yet\n    Changes to be committed:\n      (use \"git rm --cached ...\" to unstage)\n            new file:   file1\n            new file:   file2\n            new file:   file3\n    Changes not staged for commit:\n      (use \"git add/rm ...\" to update what will be committed)\n      (use \"git checkout -- ...\" to discard changes in working directory)\n            deleted:    file3\n\n  \nAs you see above, git suggests us to record the deletion event of file3 separately by using `git add` or `git rm`  \n`\n`\n\n    $ git rm file3\n    rm 'file3'\n    $ git status\n    On branch master\n    No commits yet\n    Changes to be committed:\n      (use \"git rm --cached ...\" to unstage)\n            new file:   file1\n            new file:   file2\n\n  \nThis way, we have deleted the file from filesystem as well as from staging area. Please note at this point that our original intent was to just unstage the file, i.e. undo the add, and not delete the file completely. I have gone a little ahead to understand `git rm` at the first place. Now that we know `git rm`, `git rm --cached` simply means:\n\n  \n\n\n_--cached_\n\n_Use this option to unstage and remove paths only from the index. Working tree files, whether modified or not, will be left alone._\n\n  \n\n\nAll this means that by using --cached option with git rm, we only remove the file from the staging area (or index) and keep it in the file system.  \n  \n\n\n#### git rm --cached v/s git reset HEAD &lt;file>\n\nLet's move on to commit a file here:\n\n\n    $ git commit -m \"commit file1\"\n    [master (root-commit) f4585bb] commit file1\n     1 file changed, 1 insertion(+)\n     create mode 100644 file1\n\n\n\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git reset HEAD ...\" to unstage)\n            new file:   file2\n\n  \n\n\nWe have committed file1 here, having left with file2. Observe git suggestion here, instead of suggesting `git rm --cached` as it did before, it now suggests `git reset HEAD`. This is because before committing anything, there was no `HEAD` commit altogether. If we had gone ahead with `git reset` at that point, we would have gotten the error: `fatal: Failed to resolve 'HEAD' as a valid ref.`  \n  \nSo why not use `git rm --cached` all the time? I actually don't know any definite answer to that, other than that if we forget `--cached` option, we might end up deleting our precious files forever.  \n  \nIn short, do what git suggests, it's probably for the best. However, we should understand what is the meaning behind its suggestions, for that reason you can bookmark this blog post!  \n  \nWe'll be moving on to commits next. Let's take some rest and revisit the commands...  \n  \n\n\n[![](https://1.bp.blogspot.com/-Ze2SiBflkZ4/XbtF1TjELcI/AAAAAAAALL4/IDC6W-b5moU0eGu2eN60aZ4pxfXW1ybmQCLcBGAsYHQ/s320/take_a_break_git.gif)](https://1.bp.blogspot.com/-Ze2SiBflkZ4/XbtF1TjELcI/AAAAAAAALL4/IDC6W-b5moU0eGu2eN60aZ4pxfXW1ybmQCLcBGAsYHQ/s1600/take_a_break_git.gif)\n\n  \n  \n\n\n-   Undo git init: rm -r .git/\n-   Undo unstaged/untracked files: git clean -n ; git clean -f\n-   Undo staging or unadd: git rm \\[-r] --cached &lt;file> if no commits made, else git reset HEAD &lt;file>\n\n  \n\n\n### Undo commit - change commit message and other info\n\nIn the last section, we went a little ahead and made a commit.\n\n  \n\n\n    $ git log\n    commit f4585bbdcce4ffb4c04fbac1fb0796c3ac3a2726 (HEAD -> master)\n    Author: Amita Shukla <amita.shukla0906@work.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n\n        commit file1\n\n  \nBut wait! Now that I look at it, I realize that my commit message is not very helpful, and I would rather make it more descriptive. Also, I was using my work account here, instead of using my personal account. That's a mistake and I gotta amend it. The relief is, **this commit still lies on my local computer, i.e. this commit has not been pushed and it's guaranteed that I am the only one using it.** The --amend option can help me change the commit message:  \n  \n\n\n    $ git commit --amend\n\n```\n\n```\n\nA new editor opens up. The top line is the commit message, which can be edited now:\n\n\n    commit file1 to demonstrate the difference between git rm --cached and git reset\n    # Please enter the commit message for your changes. Lines starting\n    # with '#' will be ignored, and an empty message aborts the commit.\n    #\n    # Date:      Fri Nov 1 00:14:37 2019 +0530\n    #\n    # On branch master\n    #\n    # Initial commit\n    #\n    # Changes to be committed:\n    # new file:   file1\n    #\n    # Untracked files:\n    # file2\n    #\n\n  \n\n\nLet's move on to change the author's email address. This can be done inline as:  \n\n\n\n    $ git commit --amend --author=\"amita-shukla<amitashukla0906@gmail.com>\"\n\n\n    commit file1 to demonstrate the difference between git rm --cached and\n    git reset command.\n\n    # Please enter the commit message for your changes. Lines starting\n    # with '#' will be ignored, and an empty message aborts the commit.\n    #\n    # Author:    amita-shukla <amitashukla0906@gmail.com>\n    # Date:      Fri Nov 1 00:14:37 2019 +0530\n    #\n    # On branch master\n    #\n    # Initial commit\n    #\n    # Changes to be committed:\n    # new file:   file1\n    #\n    # Untracked files:\n    # file2\n    #\n\n  \nLet's have a look at out commit now:  \n\n\n\n    $ git log\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b (HEAD -> master)\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\nNote that by using the --amend option, we are playing with the history of your commits. The official documentation for the amend option says:  \n  \n\n\n\\--_amend_\n\n__  \n\n\n__Replace the tip of the current branch by creating a new commit. ... You should understand the implications of rewriting history if you amend a commit that has already been published.__\n\n__  \n\n\n  \n\n\nSo... there are implications. Observe that, the SHA id generated after the amend is different from the one before. So this is effectively a new commit. So as I put it on bold above, it is important that the commit you are going to commit is not shared with other people.  \n  \n\n\n### Undo a commit by making another commit\n\nTill now, we have added file1 and committed this file. Only now to realize this was a mistake and this commit should have never happened. So we need to undo the effects of the previous commit, and we want to be clear about it, by creating another commit. For this we run git revert HEAD:\n\n\n    $ git revert HEAD\n\n  \nAn editor window opens up:  \n\n\n\n    Revert \"commit file1 to demonstrate the difference between git rm --cached and git reset\"\n    This reverts commit 76ee43a95a3b56f7890c8d54e82ea931b916136b.\n    # Please enter the commit message for your changes. Lines starting\n    # with '#' will be ignored, and an empty message aborts the commit.\n    # On branch master\n    # Changes to be committed:\n    # deleted:    file1\n    # Untracked files:\n    # file2\n\n  \n\n\nChecking the git and filesystem status:  \n  \n\n\n    $ git status\n    On branch master\n    Untracked files:\n      (use \"git add <file>...\" to include in what will be committed)\n            file2\n    nothing added to commit but untracked files present (use \"git add\" to track)\n\n    $ ls\n    file2\n\n  \nThe previous commit resulted in the addition of file1, and hence reverting it resulted in the deletion of file. The commit logs clearly log the commits having this:  \n  \n\n\n    $ git log\n    commit 071133e449b7dde9fced704d3bd88911440a3c62 (HEAD -> master)\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 19:26:47 2019 +0530\n        Revert \"commit file1 to demonstrate the difference between git rm --cached and git reset\"\n        This reverts commit 76ee43a95a3b56f7890c8d54e82ea931b916136b.\n\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n  \n\n\n### Undo a commit - and erase its history\n\nWell, you never really erase anything in git, once you have committed it. But here you are, you have made an embarrassing mistake and so you want to undo it, without it popping up in git log.\n\n  \n\n\nLet's start with the commits we had above:\n\n  \n\n\n    $ git log\n    commit 071133e449b7dde9fced704d3bd88911440a3c62 (HEAD -> master)\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 19:26:47 2019 +0530\n        Revert \"commit file1 to demonstrate the difference between git rm --cached and git reset\"\n        This reverts commit 76ee43a95a3b56f7890c8d54e82ea931b916136b.\n\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n  \n\n\nAnd suppose we want to undo the latest commit (here, this commit was deleting the file named file1). There are 2 ways of doing this:  \n  \n\n\n#### Undo the commit and get your changes back on staging area\n\nFor this we use `git reset`:  \n\n\n\n    $ git reset --soft HEAD^\n\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git reset HEAD <file>...\" to unstage)\n            deleted:    file1\n    Untracked files:\n      (use \"git add <file>...\" to include in what will be committed)\n            file2\n\n    $ ls\n    file2\n\n    $ git log\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b (HEAD -> master)\n    Author: amita-shukla <amitashukla0906 gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n  \n**`git reset --soft` puts the changes made by the commit back to staging area**. The commit that we have undone here, deleted file1. On doing soft reset, it has gotten back to staging area, and being shown as deleted. The file system doesn't contain the file, because, as said earlier it was deleted. The `git log` only shows the previous commit now.  \n  \n\n\n#### Undo the commit and don't keep the changes\n\nFor this we use `git reset --hard`. Back to the state where we have to undo the latest commit:\n\n  \n\n\n    $ git reset --hard HEAD^\n    HEAD is now at 76ee43a commit file1 to demonstrate the difference between git rm --cached and\n\n    $ git status\n    On branch master\n    Untracked files:\n      (use \"git add <file>...\" to include in what will be committed)\n            file2\n    nothing added to commit but untracked files present (use \"git add\" to track)\n\n    $ ls\n    file1  file2\n\n    $ git log\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b (HEAD -> master)\n    Author: amita-shukla <amitashukla0906 gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n  \n\n\nAs can be seen in the above snippet, on doing hard reset, we lose the changes made by the commit at all. So, we should use hard reset when we don't want changes done by the commit lurking around. So in our case, the commit performed the action of deletion, therefore on doing hard reset, file1 is back as a committed file, back in the filesystem, and the commit disappears from the log.  \n  \nObserve a small difference here in the syntax between reset and revert. We **write revert command as `git revert HEAD` but reset as `git reset HEAD^`**. So if you have to undo the `HEAD` commit, for revert you supply the last commit, but for reset you supply the one before the last commit. This is because `git reset` resets the commit to the supplied state.  \n  \n\n\n### Undo not the latest commit\n\nWe have been trying to rever the latest commit, denoted by HEAD. But what if we made a misguided commit, and then went on to do a series of commits? How to pick one commit from middle and revert those changes?\n\nWe can go with git revert. As described in the last section, git revert picks up the changes made by the commit, and reverts those changes into a new commit.\n\nOr we call out the mighty rebase...\n\n  \n\n\n#### Rebase\n\nSuppose we have the following 4 commits and I need to revert the commit with SHA ending with a6db3e (the 3rd commit):  \n  \n\n\n    $ git log\n    commit 12ba23fd90a161b7762c82a6127bb9eecb0853ce (HEAD -> master)\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Sat Nov 2 22:32:34 2019 +0530\n        create file4\n\n    commit 0753b7231a33deba65afbbb0f364161bfea6db3e\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Sat Nov 2 22:32:03 2019 +0530\n        create file3\n\n    commit c4a38cb0b16d97cc60280d162a89576a3a153811\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Sat Nov 2 22:29:47 2019 +0530\n        create file2\n\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n  \n Execute the rebase command for a commit before:  \n  \n\n\n    $ git rebase -i c4a38cb0b16d97cc60280d162a89576a3a153811\n\n  \n\n\nThis opens up an editor like this:  \n\n\n\n    pick 0753b72 create file3\n    pick 12ba23f create file4\n\n    # Rebase c4a38cb..12ba23f onto c4a38cb (2 commands)\n    #\n    # Commands:\n    # p, pick = use commit\n    # r, reword = use commit, but edit the commit message\n    # e, edit = use commit, but stop for amending\n    # s, squash = use commit, but meld into previous commit\n    # f, fixup = like \"squash\", but discard this commit's log message\n    # x, exec = run command (the rest of the line) using shell\n    # d, drop = remove commit\n    #\n    # These lines can be re-ordered; they are executed from top to bottom.\n    #\n    # If you remove a line here THAT COMMIT WILL BE LOST.\n    #\n    # However, if you remove everything, the rebase will be aborted.\n    #\n    # Note that empty commits are commented out\n\n  \nTo delete the commit \"create file3\", we simply delete that line altogether. Save and quit the file. The logs now show up as:  \n  \n\n\n    $ git log\n    commit 7a79af7ddbfb2ddba4624f63bed36ea89f4edfd7 (HEAD -> master)\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Sat Nov 2 22:32:34 2019 +0530\n        create file4\n\n    commit c4a38cb0b16d97cc60280d162a89576a3a153811\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Sat Nov 2 22:29:47 2019 +0530\n        create file2\n\n    commit 76ee43a95a3b56f7890c8d54e82ea931b916136b\n    Author: amita-shukla <amitashukla0906@gmail.com>\n    Date:   Fri Nov 1 00:14:37 2019 +0530\n        commit file1 to demonstrate the difference between git rm --cached and\n        git reset command.\n\n\n    $ ls\n    file1  file2  file4\n\n  \nAs we can see above, the commit doesn't exist anymore, and also no file3 exists in the filesystem. Remember, I called the rebase 'mighty' for this reason. If not careful, rebase changes history and you may lose your work. Rebase is like a swiss knife for git, and comes with a lot of powerful features (as listed in the editor window that opens up during interactive rebase), which if we discuss here may take this post off track.  \n  \nIn this post, I have tried to put up all the undo steps that we may need on our local system, and for a single branch. A lot more is possible beyond the above list, and I will try to cover that in the next post.  \n  \n\n"
            },
            "published": "2019-12-15T02:18:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "expression-evaluation-strategies-val-def-lazy-scala",
            "title": "Deep Dive into Evaluating an Expression in Scala",
            "url": "http://blog.amitashukla.in/2019/10/expression-evaluation-strategies-val-def-lazy-scala.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2019-10-16",
                "slug": "expression-evaluation-strategies-val-def-lazy-scala",
                "title": "Deep Dive into Evaluating an Expression in Scala"
              },
              "rawMarkdownBody": "\nI have been using Scala for a while now. Coming from a Java background, it was eye soothing to see lesser boilerplate code. However, as I went deeper into more and more code written by Scala devs out there, there were a lot of things I just could not wrap my head around. Wait! This is not going to be a rant on the language. Instead, I will be touching upon the most basic stuff today - **declaring, initializing variables** (let's call them 'variable', though they may not necessarily vary) and **evaluating expressions**.  \n  \nThere are painfully a lot of different ways to declare stuff in Scala, along with the regular `var` and `val`. Let's quickly glance over what we will be looking into:  \n\n\n-   [`var`s](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#vars)\n-   [`val`s](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#vals)\n-   [`def`](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#defs)\n-   -   [functions v/s methods, difference b/w `val` and `def`](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#fvsm)\n-   [`lazy val`](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#lazy_vals)\n-   -   [a small exercise](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#exercise)\n-   [function parameters](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#function_params)\n-   -   [call by value v/s call by name](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#evaluation_strategies)\n-   [anonymous function](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#anon_functions)\n-   [class parameters](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#class_params)\n-   [case class parameters](https://www.blogger.com/blogger.g?blogID=1167440767733751967&pli=1#case_class_params)\n\nAs we go through all of the above, we shall take a peek into the related concepts.\n\n  \n\n\n### `var`s, that are allowed to vary\n\nIf you're coming from the Java world like me, then the simplest way to declare + define a variable is\n\n  \n\n\nYou can, sometime later, change this value as shown above.  \nA `var` must be initialized at the same place it is declared. The only place where it can be left undefined is when it is declared inside an abstract class or trait:\n\n  \n\n\n### `val`s, that can't vary\n\n-   `val`s are absolute values, which once assigned cannot be changed/reassigned at any point of time in the program.\n-   Like `var`s, `val`s cannot be left undefined outside of an abstract class or trait. But this is kind of obvious here, for something that cannot be changed later must not be left uninitialized.\n\n`val` should be the goto way of using variables, as it helps to **design immutable structures**. While there can be a lot written about immutable data structures, in short we can say that by using immutable values we can avoid the risk of changing them later unintentionally.\n\n  \n\n\n### Define a variable with `def`\n\nWe can also write a variable using `def`:\n\nObserve here, the REPL doesn't indicate the value of `x`, it just calls out that it has registered `x` with itself. Only when I call this _function `x`_ in the next step, that the execution happens. This is unlike what we have seen for `var` and `val`, where the REPL clearly indicates that it is storing an identifier `x` with a value `42`.  \n\n\nI had seen this style being used in a lot of places, and I found it weird. Why define a variable the way we define a function? When I can write something as `val x = 42`, what difference it makes if I write the statement as `def x = 42` ? Both can be invoked in the same way also:\n\n  \n\n\nThis is because **Scala differentiates between functions and methods**. The 'functions' we are calling out by using `def` is technically not a function but a method. Defining using `val` gives us the function in real sense in Scala.  \n  \n\n\n[![](https://1.bp.blogspot.com/-l4lUeMRIY2M/XadmgbFuDVI/AAAAAAAALA0/qUGzB2tcbGscuPR4RCXiGGwbjKYkFO9ZwCLcBGAsYHQ/s320/scala_meme.jpg)](https://1.bp.blogspot.com/-l4lUeMRIY2M/XadmgbFuDVI/AAAAAAAALA0/qUGzB2tcbGscuPR4RCXiGGwbjKYkFO9ZwCLcBGAsYHQ/s1600/scala_meme.jpg)\n\n  \n  \n\n\n#### Functions v/s Methods\n\nLet's divert briefly to understand the spaghetti that functions and methods are:  \n\n\n-   Functions in scala are instances of `Function0` - `Function22` class, and `Function` class contains methods such as `apply`, `toString`, `compose`, `andThen`. Hence, these functions can be applied on values defined using `val`.\n-   Methods in scala are a part of a class, just like a method in Java. These methods have access to other members of the same class. Methods also contain an implicit reference to `this`. And that is why we can call `map` on `List` (`map` has access to the instance of `List` it has been called upon).\n-   Hence, when we want certain behaviours as a part of a class, we define methods on that class, and for all other purposes, we use functions.\n\nLet's come back to where we left. In terms of evaluation, one difference there is: a value defined using `val` is evaluated at the very point, whereas, a value defined using a `def` is evaluated only when it is called.\n\n  \n\n\nHere, that I have added a print statement at the time of definition. Observe that, `val x` is evaluated immediately at the time of definition, and is never evaluated ever again. On the other hand, `def y` is not evaluated at the time of definition but is rather delayed till its invocation. However, it is evaluated again each time `y` is used (This is synonymous with what is expected from a function).\n\nWhile delaying execution till the time may be loosely termed as _lazy_, but this is not entirely lazy, as the execution happens every time the value is used.\n\n### Make a value lazy with lazy val\n\nIn scala, a value can be made explicitly lazy using the keyword `lazy` before declaring a `val`. This means:  \n\n\n-   The value is not evaluated till its first use,\n-   The evaluated result is then stored and reused whenever the value is used later.\n-   If in a program, a `lazy val` is defined but never used, it is never evaluated.\n-   Lazy `val`s can be used to implement **memoization** technique.\n\nThe above snippet first shows the simple case, just add the keyword `lazy` with `val` to make a word lazy. In the next case, we add a print statement to show when is the actual execution is taking place. Observe here that \"y is executed\" is printed only when the `y` is used for the first time.  \n  \n\n\n#### A small exercise\n\nLet's go through a small exercise that I found as a part of [Functional Programming Design in Scala course](https://www.coursera.org/learn/progfun2?specialization=scala), that may help to realize some of the above differences discussed above.  \nWhat should be the result of `println(expr)`?  \n  \nLet's summarize how `val`, `lazy val` and `def` works here:  \n\n\n-   `val` evaluates the expression on initialization and stores the value with itself. Hence `print(\"x\")` occurs just the first time `val x` it is initialized.\n-   `lazy val` does not evaluate the expression when initialized. Rather, it evaluates when it is first used, and then stores the value with itself. Hence, `print(\"y\")` occurs not when it is initialized but when first used.\n-   `def` is not evaluated when it is first declared, but is evaluated every time a call is made. Hence `print(\"z\")` occurs every time `z` is used.\n\nSo, did you manage to get the right answer? Let's check:  \nHope you got it right! If not, try going through the steps again.\n\n  \n\n\n### Function Parameters\n\nNow that we have covered `var`s, `val`s, `def`s and `lazy val`s. Let's look inside the functions. When we define functions, the parameters are `val` values. Here is a demonstration showing that once a parameter is received by a function, its value can't be changed:\n\n#### Call by value v/s Call by name\n\nBy default in Scala, function parameters are evaluated before the function is applied/called. This evaluation strategy for function parameters is called **call by value**.  \n  \nThe above statement shows Scala's depicts a call by value behaviour when a function is executed. First, the arguments passed to it are executed, and then the other statements in the body of the function.  \nHowever, we may want to avoid evaluating arguments as soon as the function is executed, and rather delay its execution until it is actually used. This may help us to avoid unnecessary evaluation which may never be needed during the execution of the function. This strategy is called **call by name**.  \n  \nTo accept a parameter as a call by name parameter, we insert a `=>` just before parameter type, like: `a : => Int` (This is the syntactic sugar for writing as `a : () => Int`). Observe the execution statements in the above snippet. The body of the function executes first, and the argument is evaluated only when it is actually needed.  \n  \n\n\n### Anonymous Functions\n\nAnonymous functions also behave in the same way as normal functions and accept arguments as `val`s.  \n\n\nNote that writing functions using `val` is simply assigning a variable name to an anonymous function.  \n  \n\n\n### Class Parameters\n\nA class in Scala can take parameters, which is regarded as its primary constructor. These parameters can be `var`s or `val`s.  \nEach instance of a class can be `var` or `val` too. But if we wish to create an immutable data structure, assigning an instance to a `val` is not sufficient. Instead, we must use `val` for class parameters too.  \n\n\nA simple class can be created as without specifying a var or val. In that case, the member is private.  \n  \n\n\n### Case Class\n\nA case class can also have `var` and val, but often it is used without keyword, and it defaults to `public val`. In fact, the use of `var` is 'strongly discouraged'.  \n  \n\n\nWhile we started with something really trivial, but we have covered a lot just by trying to understand how variables are declared and used in Scala programs. A lot of things I have just touched, and a lot are still left unexplored. But as I continue to program, I hope to continue to stumble into more and more challenges of writing beautiful code, and continue to write more and more about them here.\n"
            },
            "published": "2019-10-17T00:09:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "property-based-testing",
            "title": "Property Based Testing",
            "url": "http://blog.amitashukla.in/2019/09/property-based-testing.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2019-09-05",
                "slug": "property-based-testing",
                "title": "Property Based Testing"
              },
              "rawMarkdownBody": "\nLet's talk about testing today. And testing is _hard_. The most common way we have been testing is what is known as **Example Based Testing**.  \nFollowing steps are followed for writing test cases:  \n\n\n-   We start by taking a function\n-   To write a test for the chosen function, we start by defining a set of inputs and the expected outputs.\n-   For each test, we call this function for an input and match it with some expected value.\n\nHow do we practice testing? When given a feature:  \n\n\n-   we write the test cases first,\n-   run the test cases, verify that they fail,\n-   implement the function at hand,\n-   run the test cases against our implementation,\n-   make sure all test cases pass.\n\nLet's start with an example. I will be using ScalaTest framework for this small example function, say `add`.  \nLet's write a few test cases for the `add` function:  \n  \nNow I implement my add function:  \nObviously, I am being a bad programmer here. My test fails. But I can be worse. Now I have to deliver this thing, and for that, the test cases must pass. So I do whatever it takes.  \n  \nCool. Now my test case pass. But hey! this is not over yet. I try to get this pushed, but I can't really get away with just one test case. Huh! Let's add some more.  \nNow given my implementation of `add` above, one of my test cases are failing. But I am bent on passing my test cases by hook or by crook. So now I implement:  \nNow you would say one day or the other I will be caught, but I can always handle test cases like this. You would also say that this example is too obvious. Yes, I agree. But not all code is this obvious, and not all coders are malicious. This example shows that test cases can pass even when the code is bad and the logic is broken.  \n  \n\n\n[![](https://miro.medium.com/max/1208/1*ok5iNXeD1HjzDHhKUcl5cQ.gif)](https://miro.medium.com/max/1208/1*ok5iNXeD1HjzDHhKUcl5cQ.gif)\n\n  \nSo how do we correct this? One solution is trusting developers with their coding skills and let the error flow until it blows up in production. Or... try Property Based Testing.  \n  \n\n\n### Property Based Testing\n\nWhat is property based testing? In property based testing, instead of providing a specific set of input for each test case, we write properties.  \n  \n\n\n#### Property\n\nProperty is nothing but a testable unit. In property based testing, these properties need to be satisfied by the function we need to test. If we take a combined look at all the properties defined for a function, it should indicate the behaviour of the function under any circumstance. Now that we have defined a property, what sort of properties can we think up for our code? Let's move ahead with our `add` example.\n\n  \nWhat can be the properties of an `add` function?  \n\n\n-   Adding by 0 can be a good start. We know add on a number and 0 must give out the number. We call this property **identity**. So: `add(x,0)=x`\n\nLet's run this property:  \n\n\n    [info] ! Add.identity: Falsified after 0 passed tests.\n    [info] > ARG_0: 0\n    [info] > ARG_0_ORIGINAL: 1\n\n  \nThis test failed as expected, but the property alone is not sufficient. Suppose our bad code already contains this handling:  \nLet's run this property now:  \n\n\n    > test\n    > [info] AddTest:\n    > [info] + Add.identity: OK, passed 100 tests.\n\n  \nThis test easily passed. There can be many wrong such implementations of a function on an integer that return the same integer back. What properties can make `add` fool-proof to test?  \nLet's try putting one more property:  \n\n\n-   Flipping the order of inputs to add should return the same result. So: add(x,y) = add(y,x). We call this property **commutative**, which will help us distinguish the `add` from functions such as `subtract`. Looks like this should work. Let's try:\n\n  \nRunning this now:  \n\n\n    > test\n    > [info] AddTest:\n    > [info] + Add.identity: OK, passed 100 tests.\n    > [info] + Add.commutative: OK, passed 100 tests.\n\n  \nShockingly, our commutative property does not suffice. But why? Let's try printing the randomly generated tests here:  \nRunning tests now:  \n\n\n    > test\n    > [info] AddTest:\n    x = -283328897 and y = 1735471989\n    x = 2147483647 and y = 1\n    x = 902184796 and y = 0\n    x = 1761670528 and y = 2147483647\n    x = -1 and y = 1\n    x = -1766910549 and y = -2147483648\n    x = -1079495038 and y = -306732024\n    x = -1 and y = 1\n    x = -1 and y = -595376862\n    x = -1267109685 and y = 1221874588\n    x = 1710402698 and y = 1\n    x = 0 and y = 2147483647\n    x = -1496107197 and y = 1555536417\n    x = -1010882575 and y = 0\n    x = -148217383 and y = 1785131788\n    x = 2147483647 and y = 1\n    x = -1032994959 and y = -1\n    x = -207729455 and y = -1\n    x = -1 and y = -2147483648\n    x = -274047330 and y = 1\n    x = 931105896 and y = 0\n    x = -1 and y = 7392559\n    x = -1629543210 and y = -505234372\n    x = -2147483648 and y = -997498258\n    x = 664666819 and y = -2147483648\n    x = 0 and y = -1\n    x = 1 and y = -601536489\n    x = -2147483648 and y = -1\n    x = 810956687 and y = 1\n    x = 2147483647 and y = 1425588316\n    x = -1599729503 and y = 2147483647\n    x = -1 and y = 1\n    x = 1 and y = -1994173278\n    x = -1765121205 and y = -1\n    x = -2147483648 and y = -444252352\n    x = -94848801 and y = -418331736\n    x = 2147483647 and y = -2147483648\n    x = -1041475063 and y = -2066395354\n    x = 1426790203 and y = -1\n    x = -2147483648 and y = 1\n    x = 1 and y = 579849916\n    x = -1791008680 and y = -831946485\n    x = 0 and y = -128557305\n    x = -2147483648 and y = 0\n    x = 1 and y = 2147483647\n    x = -2108632480 and y = 1\n    x = 2147483647 and y = 1\n    x = -2100778803 and y = 1569433578\n    x = 0 and y = 0\n    x = 0 and y = -1321862054\n    x = -2147483648 and y = 574473982\n    x = 1992767230 and y = -235589010\n    x = 2147483647 and y = 936713378\n    x = 2147483647 and y = -2147483648\n    x = 479454965 and y = 791321877\n    x = 1673114886 and y = 32065938\n    x = 1143030900 and y = 1157140989\n    x = 1025857191 and y = 1355198771\n    x = -2048789776 and y = -1\n    x = 1790440328 and y = -173381408\n    x = -1 and y = 1\n    x = 368281449 and y = 1289228540\n    x = -302533624 and y = -1550296909\n    x = -2033588754 and y = 1\n    x = -1 and y = -2147483648\n    x = -2147483648 and y = -400996116\n    x = -1 and y = 1531590967\n    x = 0 and y = -2147483648\n    x = 1 and y = 1\n    x = -1682888892 and y = 951314722\n    x = -921144956 and y = -2147483648\n    x = 0 and y = 1257974224\n    x = 0 and y = 1303946082\n    x = 1642155181 and y = 2147483647\n    x = -2147483648 and y = 2147483647\n    x = 1 and y = -2147483648\n    x = 0 and y = -397273960\n    x = 924610080 and y = -2147483648\n    x = 1 and y = 1\n    x = -167739585 and y = -1\n    x = -2018431545 and y = -597953303\n    x = 1099702277 and y = -2034975121\n    x = -791315953 and y = -1489117288\n    x = -1708172828 and y = -911743133\n    x = 1 and y = 2147483647\n    x = -355069252 and y = 1\n    x = -1367711777 and y = -523554244\n    x = 2035562490 and y = -1\n    x = -2147483648 and y = 0\n    x = 749057419 and y = -2068921504\n    x = -1 and y = 231975227\n    x = -831717683 and y = -252453652\n    x = -2147483648 and y = 2147483647\n    x = 1799244601 and y = -1\n    [info] + Add.identity: OK, passed 100 tests.\n    x = 2147483647 and y = 2147483647\n    x = 1 and y = -2147483648\n    x = -2147483648 and y = -95933741\n    x = 1 and y = 2147483647\n    x = -2147483648 and y = 2147483647\n    x = -2147483648 and y = -987661912\n    [info] + Add.commutative: OK, passed 100 tests.\n\n  \nAs we see here, a lot of random test cases are generated, but our implementation puts a default answer for all the test cases that it doesn't cover, i.e. 42. So if `x = 1099702277` and `y = -2034975121`, `add(1099702277,-2034975121)` = 42 = `add(-2034975121,2034975121)`.  \n  \nSo is our property wrong? No, it isn't, but it's not sufficient.  \n\n\n-   So what can be other properties that `add` and only `add` can exhibit? One property can be: `the result of adding 2 positive integers is always greater than or equal to both the integers`. Now let's implement this property. Observe that here, we can not directly apply this property for all integers, rather for only positive integers. How do we achieve that?\n\nHere comes the role of Generators.  \n  \n\n\n### Generators\n\nGenerators are used to generate a specific set of data. Let's try Generators for our use case:  \n  \nHere, `Gen.posNum[Int]` generates a set of positive integers. The `Gen` class has a lot more methods like this. For example, if you need your data to be positive integers greater than 1000 only:  \n  \nTesting this:  \n\n\n    > test\n    > [info] AddTest:\n    [info] + Add.identity: OK, passed 100 tests.\n    [info] + Add.commutative: OK, passed 100 tests.\n    [info] ! Add.the result of adding 2 positive integers is always greater than or equal to both the integers: Falsified after 0 passed tests.\n    [info] > ARG_0: 1\n    [info] > ARG_0_ORIGINAL: 722748975\n    [info] > ARG_1: 59\n    [info] > ARG_1_ORIGINAL: 378231530\n    [info] ScalaCheck\n    [info] Failed: Total 3, Failed 1, Errors 0, Passed 2\n\n  \nOne more thing to mention here. We see scala check mentions two cases, one like  \n`ARG_0` and `ARG_1`, and other like `ARG_0_ORIGINAL` and `ARG_1_ORIGINAL`. This is a feature called Shrinking.  \n  \n\n\n### Shrinking\n\nShrinking is a mechanism by which we can simplify failure cases to present the minimal one, readable to the human eye. So as we see above, there are 2 sets of failed test cases presented, one with ARG_0 and ARG_1 and the other as ARG_0_ORIGINAL and ARG_1_ORIGINAL, where:  \n  \n\n\n    ARG_0: 1\n\n    ARG_1: 59\n\n    ARG_0_ORIGINAL: 722748975\n    ARG_1_ORIGINAL: 378231530\n\n  \nThe value of ARG_0 and ARG_1 is simplified as compared to the original one.  \n  \nWe can disable shrinking using `forAllNoShrink` method:  \n  \n  \n\n\n    [IJ]sbt:ScalacheckDemo> test\n    [info] Compiling 1 Scala source to /home/ashukla/code/scala/ScalacheckDemo/target/scala-2.13/test-classes ...\n    [info] Done compiling.\n    [info] + Add.identity: OK, passed 100 tests.\n    [info] ! Add.the result of adding 2 positive integers is always greater than or equal to both the integers: Falsified after 0 passed tests.\n    [info] > ARG_0: 996337608\n    [info] > ARG_1: 767214905\n    [info] + Add.commutative: OK, passed 100 tests.\n    [info] AddTest:\n    [info] ScalaCheck\n    [info] Failed: Total 3, Failed 1, Errors 0, Passed 2\n\n  \nObserve that here the failing test case given are huge integers, without further reduction.  \nSo that's all with the simple example. Let's go deeper and see how we would go about writing tests for a `Tree` data structure...  \n  \nTo create properties using this data structure, we first need tree generators:  \n  \nObserve here that we need to specify the concrete type of `Tree` that we want to generate here, instead of generic types.  \n  \n\n\n### The Art of defining Properties\n\nThroughout this post, we have gone through the process of defining properties for a simple `add` function. We have seen we might be sailing the Titanic if we are not able to define the right properties. Having incorrect/ insufficient test cases is infact more harmful as it gives an illusion of a perfect codebase. Here are a few suggestions when we start thinking about properties:\n\n-   For start, we can brainstorm (or look up Wikipedia) for some basic laws associated with the concerned function, data structure or algorithm. Some properties can directly be derived from their mathematical counterparts.\n-   Try `reverse`. Some properties can be derived by trying to reverse the order of inputs. Supose in case of sorting a list, the reverse of a list should produce the same output.\n-   Change the order of inputs. Some properties can be derived by changing the order of inputs/operations but arriving on the same output. This we have seen in the `add` function as well.\n-   Use Induction. Just like mathematical induction, we can verify if a property stands true for a smaller part, then it should work for the larger part as well.\n-   and... a lot more that I am not covering here.\n\nThere are many more ways in which we can think of defining properties. Still not able to? May be that is indicative of some deeper problem with the code itself. Maybe this is a call for abstracting general behaviours out of your program now.  \n\n\n  \nIt's been a while that PBT has existed, and its poularity has been growing ever since. It is being used in a number of real world applications. I myself am using it at my work. PBT was originally developed as part of QuickCheck framework in Haskell and since then it has been developed in a number of languages. Give it a shot and you might never look back!  \n  \n\n"
            },
            "published": "2019-09-05T11:02:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "unfolding-folds",
            "title": "Unfolding the folds",
            "url": "http://blog.amitashukla.in/2019/07/unfolding-folds.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2019-07-20",
                "slug": "unfolding-folds",
                "title": "Unfolding the folds"
              },
              "rawMarkdownBody": "\n[![](https://1.bp.blogspot.com/-q7gut7HRadU/XVkugQxIhZI/AAAAAAAAKj8/8wpokqXm-00y2r6cRYuyTzqSnZgm1MDegCLcBGAs/s320/fold.jpg)](https://1.bp.blogspot.com/-q7gut7HRadU/XVkugQxIhZI/AAAAAAAAKj8/8wpokqXm-00y2r6cRYuyTzqSnZgm1MDegCLcBGAs/s1600/fold.jpg)\n\n  \nLists can be represented as:  \n  \n`data [a] = [] | a : [a]`  \n  \nConsider the following functions:  \n\n\n    foldl :: (b -> a -> b) -> b -> [a] -> b\n    foldr :: (a -> b -> b) -> b -> [a] -> b\n\n  \nThese two functions are used for what we call _folding_ over a list. What does it mean by folding? In a broad sense, we can say that folds give us the power to evaluate a list by applying an operator between the list elements. First examples that come to mind can be finding the sum on a list of integers, append the elements of a list, etc. To fold, we also need a default value when we come to evaluate the end of list, or over an empty list, hence a seed value. Take a closer look at the type signatures, we can say that folds are much more powerful than these examples, as they also give us the power to change not only the structure of the list, but also the type of list.  \n  \nBoth foldl and foldr take a seed value of type `b`, a list of type `a`, and a function (let's call it `f`). We can notice that `foldl` and `foldr` are only different with regards to `f`.  \n`foldl` takes the seed value `b` and applies it to the head of the list,  \n`foldr` takes the seed value `b` and applies `f` to the end of the list. Let's see how.  \n  \n\n\n### Fold behaviour using examples\n\nSuppose we have a list, and we need to sum over this list. Finding the sum means running over the whole list and adding the elements using `(+)` operator.  \n\n\n    let x = 1 : 2 : 3 : Nil\n    foldl (+) 0 x = ((((0 + 1) + 2 ) + 3 ) + Nil)\n    foldr (+) 0 x = (1 + (2 + (3 + (Nil + 0))))\n\n  \nWhile it all looks ok, what stands out is applying `(+)` on Nil. How is that supposed to behave? Let's assume for now that `(+)` of an operand with `Nil` equals to that operand:  \n\n\n    x = 1 : 2 : 3 : Nil\n    foldl (+) 0 x = ((((0 + 1) + 2 ) + 3 ) + Nil) = (((1 + 2) + 3 ) + Nil) = ((3 + 3) + Nil) = (6 + Nil) = 6\n    foldr (+) 0 x = (1 + (2 + (3 + (Nil + 0)))) = (1 + (2 + (3 + 0))) = (1 + (2 + 3)) = (1 + 5) = 6\n\n  \nA few more examples:  \n`product = foldr (*) 1` or `product = foldl (*) 1`  \n`length = foldr (const (+1)) 0` or `length = foldl (const (1+)) 0`  \nBoth `foldl` and `foldr` produce the same answers.  \n  \nLet's implement both these functions to gain some more insights into their behaviour:  \n\n\n    foldl :: (b -> a -> b) -> b -> [a] -> b\n    foldl f z Nil = z\n    foldl f z (h : t) = foldl f (f z h) t\n\n  \n\n\n    foldr :: (a -> b -> b) -> b -> [a] -> b\n    foldr f z Nil = z\n    foldr f z (h : t) = f h (foldr f z t)\n\n  \nJotting down the key features here:  \nfoldl is  \n- lazy (Haskell is lazy by default),  \n- tail recursive (the function `f` is applied first, and the recursive call is made later, in `foldl f (f z h) t`),  \n- left associative (consider the example above: `(((0 + 1) + 2 ) + 3 )` )  \nfoldr is  \n- lazy (nothing is evaluated until result is needed),  \n- not tail recursive (recursive call to `foldr` is made first, and then `f` is applied on top of it, in `f h (foldr f z t)`)  \n- right associative (consider the example above: `(1 + (2 + (3 + 0)))` )  \n  \n\n\n### Too lazy to fold infinitely\n\nNow I am going to apply folds on an infinite list and see what happens. Wait what? Obviously, if we call any fold on infinity it's bound to overflow, right? But hey! we just forgot, that these folds are **lazy**. This means, that folds will only evaluate the list unless the result is actually needed. So if we have a function such as `find`:  \n\n\n    findl :: (a -> Bool) -> [a] -> Bool\n    findl p = foldr (\\a b -> if p b then True else a) False\n\n  \n\n\n    findr :: (a -> Bool) -> [a] -> Bool\n    findr p = foldr (\\a b -> if p a then True else b) False\n\n  \nObserve that the arguments are reversed for `findl` and `findr`. Now let's try to run these:  \n\n\n    >> findr even [1..]\n    >> True\n    >> findl even [1..]\n    ^CInterrupted\n\n  \nObserve that while `find` using `foldr` gives an answer, but `foldl` doesn't. But should that's how it should be with infinite list? What kind of magic is this `foldr` doing?? Well, it's no magic but laziness. The `foldr` is simply not doing much. Let's have a look at `foldl` and `foldr` implementations again:  \n\n\n    foldl f z (h : t) = foldl f (f z h) t\n    foldr f z (h : t) = f h (foldr f z t)\n\n  \nWhile `foldl` first makes the recursive call, `foldr` first applies the function `f` and then recursively calls itself. But in our case of `find`, the `f` here is a boolean function. So if `f h = True`, then it need not go into evaluating the entire list! But such is not the case with the poor `foldl`. Before even applying `f`, `foldl` needs to recursively call itself (in a way keep looping...). Therefore, `foldl` cannot use `f` until it has worked out its entire nested expression. And hence, `foldr` is always the recommended way of folding. The thing to remember here is that **laziness works for infinite lists when the second argument to the combining function is lazy**. That's why `findr` is possible but not `(+)`. If we remove laziness from the picture, then both the arguments to the function need to be evaluated immediately, and then it won't matter if we are calling `foldl` or `foldr`. Actually it would matter a bit, as `foldl` is tail recursive, and thus would be more efficient.  \n  \nDid not care to read the big para before? let's point what we learnt:  \n- both `foldl` and `foldr` use a combining function having 2 arguments.  \n- if the combining function is lazy in its second argument, `foldr` evaluates for infinite lists, whereas `foldl` doesn't.  \n- This is because `foldl` is implemented in such a way that it has to first construct the entire expression before evaluation, hence stack overflows.  \n- If `foldl` is made strict (there is a `foldl'`), then as tail recursive is more efficient, it can be used to improve the performance of the code.  \n- Hence, `foldr` is the recommended way of folding, in order to preserve lazyness across function composition.  \n- However for strict languages, `foldl` seems a more natural choice.  \n  \n\n\n### What all can be folded\n\nTill now we are seeing list being folded into a single value, but folds are not restricted to end into a single value. They can be anything as long as the type signatures match!  \nThere is something special about `foldr` if we take a different perspective. Till now we consider `foldr` as 'folding from the right', which, well, is like that. Let's look again at our foldr example:  \n\n\n    for the list 1 : 2 : 3 : Nil\n    foldr f z x = 1 `f` 2 `f` 3 `f` z\n\nThe similarity is quite striking! for every foldr operation, the cons `(:)` operator is replaced by infix `f` and `Nil` is replaced by `z`. This is what we call **constructor replacement**. Therefore, we can use `foldr` for actually replacing the list constructor.  \n\n\n  \n\n\n#### map\n\nLet's try mapping over a list using fold:  \n\n\n    map f =  foldr _f _z\n\nLet's now fill in `_f :: (a -> b -> b)`. For mapping over a list, we do not need to change the structure of the list. Hence, we need `(:)`. But just `(:)` is not sufficient. So at any point of time, if we are dealing with an element `a`, then we need it to be first transformed into `b` and then appended to the rest of the list as before. Voila! `_f = ((:) . f)`. Here, `(.)` operator is called **compose**, where `f . g` is equivalent to `\\x -> f (g x)`.  \nNext we need a default value for mapping a list in place of `_z`. What can be the default value for a list? Well, it's `Nil`. Hence:  \n\n\n    map = foldr ((:) . f) Nil\n\n  \n\n\n#### filter\n\nSimilarly, let's think about applying `filter :: (a -> Bool) -> [a] -> [a]`  \n\n\n    filter p = foldr _f _z\n\nHere, yet again, a list remains a list hence `_z = Nil`. Now think about `_f`. For filtering a list, at any point of time, if we have an element `a`, for it to go in the list we need to check if it satisfies the predicate `p` and then if it does we add it else we don't. So `_f = \\a b -> if p a then (a : b) else b`. Hence:  \n\n\n    filter = foldr (\\a b -> if p a then (a : b) else b) Nil\n\n  \n\n\n#### append\n\nLet's make it more challenging. What about appending two lists? i.e. implementing `(++) :: [a] -> [a] -> [a]`  \n\n\n    (++) xs ys = foldr _f _z\n\nso what should be the ending/default value `_z`? For appending two lists together, we need that in `Nil` of first list, we get the second list. Hence `_z = ys`:  \n\n\n    (++) xs ys = foldr (:) ys xs\n\nTo write this in point-free notation, flip the args: `(++) = flip (foldr (:))`  \n\n\n  \nI have dedicated a whole post to fold coz folds are not only widely used, for me they were the first steps into functional programming. Knowing the power of folds eabled me to write implementations of a lot of more functions in a crisp manner (Before that I was pattern matching for everything). I am a merrier fp programmer now that I have folded!\n"
            },
            "published": "2019-07-21T02:01:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "prepare-for-gcp-certification-exam-data",
            "title": "Prepare for GCP Certification Exam - Data Engineer",
            "url": "http://blog.amitashukla.in/2019/01/prepare-for-gcp-certification-exam-data.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2019-01-26",
                "slug": "prepare-for-gcp-certification-exam-data",
                "title": "Prepare for GCP Certification Exam - Data Engineer"
              },
              "rawMarkdownBody": "\nGoogle Cloud Platform (GCP) is fairly new in the cloud market, dominated by the AWS. Though Google has a long way to go in terms of the variety of tools offered in the cloud space, the good part is that its current set is enterprise ready. I had my share of the Google Cloud experience at work, and then while preparing for the Google Could Data Engineer exam. Studying and playing with these tools was so fun and securing the certificate (and a google hoodie) was a sweet award for it.  \n  \n\n\n### Google Cloud Certified Professional Data Engineer\n\n_A Professional Data Engineer enables data-driven decision making by collecting, transforming, and visualizing data. The Data Engineer designs, builds, maintains, and troubleshoots data processing systems with a particular emphasis on the security, reliability, fault-tolerance, scalability, fidelity, and efficiency of such systems._  \n_  \n_ A Data Engineer Certification proves that you are able to leverage the cloud platform for development, from using cloud storage, processing batch and real-time data, publish/subscribe messages, build machine learning models, save results to data warehouse, to visualize this data on cloud. The certification calls for not mere knowledge but prior hands-on with the GCP suite.  \n  \n\n\n### Google Resources\n\nThere are plenty of resources, provided by Google to prepare for the Data Engineer Certification. Here's the list:  \n\n\n-   [Certification Exam Guide](https://cloud.google.com/certification/guides/data-engineer/)\n-   [Coursera GCP Data Engineer Series](https://www.coursera.org/specializations/gcp-data-machine-learning)\n-   [Google Training](https://cloud.google.com/training/data-ml)\n-   [QuickLabs GCP Essentials](https://google.qwiklabs.com/quests/23?locale=en)\n-   [QuickLabs Data Engineer Quest](https://google.qwiklabs.com/quests/25?locale=en)\n-   [Practice Exam](https://cloud.google.com/certification/practice-exam/data-engineer)\n\n### My take on GCP Data Engineer Certification\n\nAs previously said, the GCP Data Engineer exam requires not only theory, but hands-on experience on these tools. I did have some experience with some of them, but definitely not all of them!\n\nWhat helped me with this was the Coursera GCP Data Engineer Series. The course is anyway to go for even if you are not aspiring for the certification. The course extensively teaches you not only the fundamentals, but how to store it, query it, retrieve it, and what to do with it.\n\nThe course is lengthy and thorough (it took me 1 month to finish it). Also, it is not enough for the certification.\n\n  \n\n\nThe exam is quite scenario bases. Thinking that the Case Studies mentioned in the guide only ones coming your way? Nope. There are many more scenario based questions, that are asked, testing your knowledge on the myriad of tools available.\n\n  \nMost of them were based on which were tool was appropriate at what situation. Here is a link that helped me prepare for the same: <https://cloud.google.com/storage-options/>  \n\n\n  \n\n\n[![](https://1.bp.blogspot.com/-xCrCGPRZaD8/XEy6UCY1fOI/AAAAAAAAJAc/w6inBYlllIY5v0c6WubJU4A1RF10cvlxgCLcBGAs/s320/GCP.png)](https://1.bp.blogspot.com/-xCrCGPRZaD8/XEy6UCY1fOI/AAAAAAAAJAc/w6inBYlllIY5v0c6WubJU4A1RF10cvlxgCLcBGAs/s1600/GCP.png)\n\n  \n\n\n-   Questions based on both the case studies mentioned in the exam guide appeared. Please read the case studies before hand to save time and directly jump to the questions.\n\n-   There were no direct questions. A rare, but simple question:\n\n    _\"... have to store transcational data that has to be global... which would be the most appropriate tool...\" options:Bigquery, cloud SQL, datastore, bigtable_\n\n-   Abundant questions on stack driver:\n\n    _\"... multiple people are doing big query jobs, you need to be get logs only for a particular table...\" options: use Stack Driver monitoring and filter, pass stack driver audit logs to pub sub and write a filtering logic in cloud dataflow, push logs into pub sub and access using your own monitoring tool\"._\n\n    __\n\n    Almost every question had a option proposing a solution using stack driver\n\n-   There were some questions not related to GCP at all.\n\n    _\"... what would you use to do ETL on large data\" select 3 options: redis, cassandra, hadoop, MySql, Hbase_\n\n    _You have map reduce jobs to do ETL. Now the data is going to increase tremendously.\" options: rewrite the jobs to pig, rewrite in spark, rewrite in hive\"_\n\n-   Machine learning algorithms and their use case were abundant.\n\n-   _\"You are given only a single machine to predict the housing prices... which algorithm to use?\" options: gradient descent, feed forward neural network, recurrent neural network, logistic regression\"_\n\n-   _\"a data scientist wants to build a machine learning model and visualize the data on your vm instance. but her laptop is not powerful enough. you want to help her. what will you do?\" options: set jupiter on her laptop, set up visualization on VM instance, give her cloud datalab access, use cloud ml \"_\n\n-   _\"your model given little error on training set but high error on test set. what will you do?\" (one of the option was dimentionality reduction)_\n\n-   _\"you are given a bank transaction data: name, transaction location, transaction amount\" which machine learning algorithm can you run on this data\" options(select 2): unsupervised learning to predict fraudalent transactions, supervised learning to predict fraudalent transactions, unsupervised leanrning to predict transaction location, supervised learning to predict transaction location\"_\n\n-   There were many more questions on supervised, unsupervised learning, fraudalent transaction prediction\n\n-   dataflow and pubsub were mostly combined  \n    _\"need to to do streaming analysis user activity data ... which window to use..\" options: global window, fixed window, sliding window, session window\"_\n\n-   bigquery access questions:  \n    _\"you have data used by several clients. how will you make sure that clients cannot see each others' data\" options: create service accounts, create IAM roles for each user and share datasets, use stack driver to notify users accessing unassigned dataset, restrict bigquery api access\"_\n\n-   _\"you uploaded a csv file into bigquery but the data loaded is inconsistent what has gone wrong?\" options: you forgot to select csv as file type, csv file had some bad records which were skipped..._\n\n-   _\"you had a table, you exposed a view on it by writing a sql query in legacy sql. now other people want to do analysis using API\". options: a) let users query as it is. b) create another view on top of the view using standard sql, c) create another view from table using standard sql, d) write a dataflow program that takes the data and puts data into another table\"_ Answer: c As per the recommendation, if the user has to use standard-sql , then c is the best option.\n\n-   Refer https&#x3A;//cloud.google.com/bigquery/docs/views-intro#view_limitations\n\n-   some questions on debugging, like  \n    _\"you are using streaming data from pubsub+dataflow and visualizing it. but some messages are missing. what can go wrong?\"_\n\n-   2/3 direct questions on how to construct row key in big table. This concept is explained thoroughly in coursera google data engineer course.\n\n  \n\n\nI took the test almost an year before, and i hadn't published these questions before as these questions were not 'defined'. These questions were part of my scribbling, straight out of the working memory. The exam questions format is strictly multiple choice questions, and the pattern can be recognized by taking the GCP Data Engineer practice exam as well (I did not take this myself, as it was not available at that time). I still keep getting a lot of queries, so I thought it worthwhile to publish these. Hope it helps!  \n  \n\n\n[![](https://4.bp.blogspot.com/-Si3YHSy7F3Y/XEy4P2KB2CI/AAAAAAAAJAQ/PNoPPl2e-bUqoNfduuGzbWie4gxgtD22gCLcBGAs/s320/af7a94db-8b68-48fb-9a2c-ec38d1855a5c-original.jpeg)](https://4.bp.blogspot.com/-Si3YHSy7F3Y/XEy4P2KB2CI/AAAAAAAAJAQ/PNoPPl2e-bUqoNfduuGzbWie4gxgtD22gCLcBGAs/s1600/af7a94db-8b68-48fb-9a2c-ec38d1855a5c-original.jpeg)\n\n  \n\n\n  \n\n"
            },
            "published": "2019-01-27T01:07:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "12-habits-that-will-make-you-smart-programmer",
            "title": "12 Habits That Will Make You a Smart Programmer",
            "url": "http://blog.amitashukla.in/2017/07/12-habits-that-will-make-you-smart-programmer.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-07-28",
                "slug": "12-habits-that-will-make-you-smart-programmer",
                "title": "12 Habits That Will Make You a Smart Programmer"
              },
              "rawMarkdownBody": "\nIt is said that \"Master the work you do most often\". So if programming is what we do most often, we should definitely come up with practices that help us to master whatever we do, along with learning new skills.  \n  \nHere are a few habits that I follow to make myself more and more efficient as a programmer, gain knowledge and garner appreciation from others!  \n  \n\n\n[![](https://4.bp.blogspot.com/-oaUVhocsUhM/WaLnXO55xgI/AAAAAAAAGSI/8Cv6X96NPvMv79k1P9tXLQPmiWEIQaOWgCLcBGAs/s320/UPSTART.png)](https://4.bp.blogspot.com/-oaUVhocsUhM/WaLnXO55xgI/AAAAAAAAGSI/8Cv6X96NPvMv79k1P9tXLQPmiWEIQaOWgCLcBGAs/s1600/UPSTART.png)\n\n  \n  \n\n\n### 1. Use Git\n\nGit is an excellent tool for code collaboration. Let's start with the popular advantages. It offers:  \n\n\n-   distributed development,\n-   feature branching/merging capabilities,\n-   flexible workflow\n\nBut you can put Git to you immediate uses well!  \n\n\n#### Git acts as a central repository for all your code.\n\nSo, you can have a look at your code wherever and whenever you want, as it is always online. I upload most of my personal code at [Github](https://github.com/amita-shukla) so that it is easily accessible to me and as well as to the public.\n\n  \n\n\n#### Git is useful to keep track of code changes.\n\nGit gives you the power to \"rewrite history\", so you can see what the changes you made and discard the changes that you no longer want. The git commit history itself acts as a development log.\n\n  \n\n\n#### Showcase your code to the world\n\nWhen you write awesome code, what is the point in keeping it hidden? Show Off. There is no better demonstration of a programmer's work than his code.  \n  \n  \n\n\n[![](https://1.bp.blogspot.com/-OGLGVyt9Zl8/WaA4rjPnVWI/AAAAAAAAGQY/FxAzPedcMaAENIChNkhxOo_C_iHPVOplgCEwYBhgL/s320/git.png)](https://1.bp.blogspot.com/-OGLGVyt9Zl8/WaA4rjPnVWI/AAAAAAAAGQY/FxAzPedcMaAENIChNkhxOo_C_iHPVOplgCEwYBhgL/s1600/git.png)\n\n  \n\n\n  \n\n\nBeware! Git is a steep learning curve if you have never tried it before. [Here](http://blog.amitashukla.in/2016/04/how-to-set-up-git-repository.html) is one article to get you started.\n\n  \n\n\n### 2. Learn Regex\n\nQuite often you must have stumbled upon pattern matching. And be it any programming language you use, regex is a tremendously handy tool to do so. It has the power to search through huge texts of code in the most concise way.  \n  \n\n\n[![](https://2.bp.blogspot.com/-p2_he1Enp7s/WaA4Vemh4pI/AAAAAAAAGQQ/do8lD19dHo4QifGQZNoYIAj0wBwRHagqwCLcBGAs/s320/regex.png)](https://2.bp.blogspot.com/-p2_he1Enp7s/WaA4Vemh4pI/AAAAAAAAGQQ/do8lD19dHo4QifGQZNoYIAj0wBwRHagqwCLcBGAs/s1600/regex.png)\n\n  \nHere is the basic regular expression notation:  \n\\[ ] matches a single character contained within the brackets.  \n\\[^ ] matches a single character that is not contained within the brackets.  \n^ matches the first character of the string  \n$ matches the last character of the string  \n\\* matches characters preceding it one or more times  \n  \nThere are several cheat sheets available on the internet, it is useful to keep one bookmarked. [Here](https://www.cheatography.com/davechild/cheat-sheets/regular-expressions/) is what I keep with me.  \n  \n\n\n### 3. Create aliases for the commands you use most frequently.\n\nSomeone told me if you have used a command for more than 21 times, create an alias for it.\n\n-   It reduces the amount of typing necessary from long commands. Suppose you need to edit one file regularly, by opening it in an editor. You can create an alias such as:\n\n`alias a=\"gedit /etc/httpd/conf/httpd.conf\"`  \nThen just type this single letter command and escape from the tedious task.  \n\n\n-   Aliases can be used as a shorthand for some other version of a command that you use more frequently.\n\n`alias ls=\"ls -lrt\"`, or,\n\n`alias hls=\"hadoop fs -ls\"` and so on.\n\n  \n\n\n[![](https://4.bp.blogspot.com/-p49gjTFJaDs/WaEhP44LWCI/AAAAAAAAGQk/1HILXtDQIqkx52WydZs5s5WEas_ZiRw2QCLcBGAs/s1600/aliases.png)](https://4.bp.blogspot.com/-p49gjTFJaDs/WaEhP44LWCI/AAAAAAAAGQk/1HILXtDQIqkx52WydZs5s5WEas_ZiRw2QCLcBGAs/s1600/aliases.png)\n\n  \n\n\nThe problem with aliases is that they are valid only for the current login session. To deal with this, an alias for any user can be added to the_.bashrc_file in that user's[home directory](http://www.linfo.org/home_directory.html). Because this file is read at login, the change will not take effect until the user has logged in again.  \n  \n\n\n### 4. Keep a text editor\n\nWhen we are involved in work, we need some place to keep temporary data, steps of execution or any other random data that we don't want to save but neither to just vanish away when shutting the computer down. And thus having a text editor handy is a plus, be it Notepad++ (it has two plus for a reason), or Sublime Text. Let's discuss some notepad++ features:  \n  \n\n\n-   Multi-tabbed feature that you can create several files at once (double click an empty space beside your current file and you get a new file)\n-   Support for several languages\n-   Syntax highlighting according to the language being used.\n-   Auto completion\n-   Document map etc.\n\n[![](https://3.bp.blogspot.com/-k6IpkulQxoU/WaEiy3LJ3uI/AAAAAAAAGQw/XkADFBi2ohYaMZI5moZzGozaXgFI5VD_gCLcBGAs/s1600/notepadpp.jpg)](https://3.bp.blogspot.com/-k6IpkulQxoU/WaEiy3LJ3uI/AAAAAAAAGQw/XkADFBi2ohYaMZI5moZzGozaXgFI5VD_gCLcBGAs/s1600/notepadpp.jpg)\n\n  \nKeep all the clutter out of your mind and on a notepad. Want to remember a set of commands? Note them down. Want to remember some file paths? Note them down. Want to remember execution steps? Note them down. At any later point of time, save these notes and get a raw documentation!  \n  \nFor Linux distributions, make Sublime Text your friend.\n\n  \n\n\nBonus tip: Enter`data:text/html, <html contenteditable>` on your google chrome new tab and convert it into a minimalistic notepad.  \n  \n\n\n### 5. Be Active On StackOverflow\n\n[![](https://2.bp.blogspot.com/-WKxU88pIUII/WaEl8gtUIVI/AAAAAAAAGQ8/1EWVFVnz0uEOwNOEe-2H5WB9kdZ9E-VigCLcBGAs/s320/so.jpg)](https://2.bp.blogspot.com/-WKxU88pIUII/WaEl8gtUIVI/AAAAAAAAGQ8/1EWVFVnz0uEOwNOEe-2H5WB9kdZ9E-VigCLcBGAs/s1600/so.jpg)\n\n  \nFiring a query on Google, and getting the answer from [StackOverflow](http://stackoverflow.com/) saves our day (and our career). What we forget is that it is a community run by people like us. And by saying 'being active' I do not mean just anonymously searching the answers to your questions, but creating an account there and actually 'being there' in as many ways possible. But why should you take the burden?  \n  \n\n\n#### It's a give-n-take relationship.\n\nYou get help from other people, and in return, you help other programmers out there. It doesn't take much time, but you will save the time and effort of some other programmer sitting in some other part of the world struggling with the same problem.\n\n  \n\n\n#### Earn Reputation.\n\n[![](https://1.bp.blogspot.com/-5Jl2Gb8irRw/WaEq4uwjKFI/AAAAAAAAGRM/nYbjzpIyjJsn29g3EileNt6AwwJ4mlWdQCLcBGAs/s1600/so_flair.png)](https://1.bp.blogspot.com/-5Jl2Gb8irRw/WaEq4uwjKFI/AAAAAAAAGRM/nYbjzpIyjJsn29g3EileNt6AwwJ4mlWdQCLcBGAs/s1600/so_flair.png)\n\n  \n\n\nYour contribution to the community doesn't go in vain. You earn reputation from other programmers who validate your answers and thank you in the form of upvotes termed as 'reputation'. Not only by answering, but even asking the right questions can fetch you reputation. Show it off and earn a high reputation in the real world!\n\n  \n\n\n#### Track yourselves.\n\nOK. This is important. If you do not believe in being 'social', then here is how Stack Overflow can help you. Just be logged in Stack Overflow and you can do a lot more with it. You can mark the questions that you liked as your favourites, or just upvote the answers which helped you. Stack Overflow keeps the record of your activity. Trapped in a situation when you know that the hack to your problem is present in Stack Overflow but can't actually recall it? Just track your activity and dig that question/answer out.\n\n  \n\n\n#### Earn Karma.\n\n\n\n### 6. Keep Linux Commands Handy\n\nThe terminal can be our friend if we know to use its potential to the fullest. Use these to hacks your Linux:  \n  \n\n\n[![](https://1.bp.blogspot.com/-3lVkUO_0vsg/WaLQskeQJMI/AAAAAAAAGRc/DTk_oTKnwVgVct6BthvBy-kk-6H7dwdxQCLcBGAs/s320/shell.png)](https://1.bp.blogspot.com/-3lVkUO_0vsg/WaLQskeQJMI/AAAAAAAAGRc/DTk_oTKnwVgVct6BthvBy-kk-6H7dwdxQCLcBGAs/s1600/shell.png)\n\n  \n\n\n#### Tab Completion\n\nNo, no. You don't need to type everything. Just type a letter, and press tab. The tab completion feature completes file names, commands, everything for you.\n\n  \n\n\n#### Pipes\n\nSend the output of one command to another as input using pipes ( | ).  \nOne of the most useful example:  \n`$ ps aux | grep conky | grep -v grep | awk '{print $2}' | xargs kill`\n\n  \n\n\n#### Wild Cards\n\nThe \\* character – that is, the asterisk – is a wild card that can match anything.  \nFor Example,  \n`rm a*.txt`  \nThis removes all files starting with 'a' that are of .txt format.\n\n  \n\n\n#### Output Redirection\n\n' `>` ' redirects the command output to a file instead of the terminal. This can come handy if you want to save logs of a command in a file.\n\n  \n\n\n#### Launch a command in background using '&'\n\n`firefox &`  \nThis is useful when you want to launch a command but continue using the terminal.\n\n  \n\n\n#### Conditional Execution\n\nYou can have 2 commands run one after the other. Writing a && between the two commands will only execute the 2nd command after the first one successfully executes. For example,  \n`cd /home/user/Documents && ls`  \n\n\n\n\n#### Search and Use the commands from the past\n\nDon't type a command again and again. Press `ctrl+r` and type any key words that you can recall. Shell looks up in the history and finds it for you. Voila!\n\n  \n\n\nThere are so many other tricks out there that an entire post (perhaps a book) can be dedicated to it. Also, a lot more can be done by scripting your long list of commands. I mentioned a few of them in my post [Shell In a Nutshell](http://blog.amitashukla.in/2016/12/shell-in-nutshell.html).  \n  \n\n\n### 7. Learn to make Diagrams and Presentations\n\nIf you end up addressing a large crowd, you will have to make presentations and lots of diagrams. This skill may be secondary, but what good that knowledge is that can't be expressed? Your Office software can be good enough for this, only if you learn to leverage it properly.  \n  \n\n\n[![](https://3.bp.blogspot.com/-8K18VnEM2aU/WaLZwUrtWuI/AAAAAAAAGRs/RoTEA2IsNk4bbDJQH0jpMBG_mpERnmmWQCLcBGAs/s320/diagrams.png)](https://3.bp.blogspot.com/-8K18VnEM2aU/WaLZwUrtWuI/AAAAAAAAGRs/RoTEA2IsNk4bbDJQH0jpMBG_mpERnmmWQCLcBGAs/s1600/diagrams.png)\n\n  \n\n\n###   \n\n\n### 8. Read Code. A lot of Code.\n\nThanks to the open source community, you can read the code that you use.\n\n-   Knowing the internal design of your code helps you realize if you are using it right.\n-   Life is short that you can write all the good code out there yourselves. Reading others' code transfers their knowledge to you. But for that, you not only need to 'read', but also understand why something was written that way.\n-   When you know what your code is doing to its depth, you know its strengths and limitations, and brag about it all, and get the appreciation for the knowledge resource you are! You can thank me later :P\n\n  \n\n\n### 9. Make Your Keyboard Your Friend\n\nMake sure your fingers know which key to hit in order to type what are you thinking. If you are still looking down while typing, you are not trusting your keyboard enough. If you have been using the same keyboard for quite some time, look up the screen and type. Just the same way you don't need to figure out how to write when you take notes, you should not think on how to type while coding. It may be obstructive at first, but you won't realize when you start typing at the speed you are thinking.\n\n  \n\n\nAlso, by looking down while typing, you are harming your neck, spine, eyes. Sit straight and type for hours.  \n  \n\n\n### 10. Document What You Learnt\n\nThere is one documentation that we all hate writing. But then there can be one another kind of documentation. Your personal one. Make a habit of documenting what all you learned today. How many times it has happened to you that you see a problem and realize that you have done it before but can't recall it now? You have no option than to do it all over again. Sad.\n\n  \n\n\nMaintaining a personal documentation, or call it a journal, helps you recall quickly the solution to a problem you have already encountered before. Not only this, a day when you feel downright stupid, you can look back at your doc to see the long list of things you have learnt and feel all up!  \n  \n\n\n### 11. Blog\n\nNow that you are maintaining the Journal, if something important pops up. You can go ahead and tell others about it! It also makes you a better presenter. If you can blog about it, you have gained the power to explain it.  \n  \n\n\n### 12. Read Books.\n\nI can't emphasize this point enough. There are excellent pieces of literature whose knowledge out there that are waiting to be digested by you.  \n  \n  \n\n\n[![](https://1.bp.blogspot.com/-Qg88CHCpJB0/WaLfYuH3jSI/AAAAAAAAGR8/AlIVcdNl8sE-bij49SsNeqw0N5dkXOVMQCLcBGAs/s320/how-to-read.jpg)](https://1.bp.blogspot.com/-Qg88CHCpJB0/WaLfYuH3jSI/AAAAAAAAGR8/AlIVcdNl8sE-bij49SsNeqw0N5dkXOVMQCLcBGAs/s1600/how-to-read.jpg)\n\n  \n\n\nToo busy to read? I have a trick that worked for me. Whenever you feel like picking up your phone and browse your feed, pick that book instead. And then you will realize how much time you actually have.\n\n  \n\n\nFor start, you can take inspiration from my reading list:\n\n-   Code Complete\n-   Clean Code\n-   Head First Design Patterns\n-   Hadoop The Definitive Guide\n-   Effective Java\n-   Hadoop in Action\n-   Learning Scala\n-   Hadoop Real World Solutions CookBook\n\nFor a more comprehensive list, you can read [this](https://stackoverflow.com/questions/1711/what-is-the-single-most-influential-book-every-programmer-should-read) thread.\n\n  \n\n\nThat's all for now. Eat right, exercise, and don't drink too much coffee. Try to be the best and you will surely get better and better. Have some excellent tips that you follow? The comments section is all yours!  \n  \n  \n  \n\n"
            },
            "published": "2017-07-28T13:11:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "implement-functional-list-from-scratch-scala",
            "title": "Implementing Functional List from Scratch in Scala",
            "url": "http://blog.amitashukla.in/2017/06/implement-functional-list-from-scratch-scala.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-06-25",
                "slug": "implement-functional-list-from-scratch-scala",
                "title": "Implementing Functional List from Scratch in Scala"
              },
              "rawMarkdownBody": "\nAfter studying the [why](http://blog.amitashukla.in/2017/02/why-functional-programming.html) and [how](http://blog.amitashukla.in/2017/03/tail-recursion-in-functional-programming.html) of Functional Programming, the time had come to study the real-life implementation of this paradigm. So, I went on reading Scala source code. And why not? Scala [claims](https://www.scala-lang.org/what-is-scala.html#functional) to be a full-blown functional language, and allows an easy migration from imperative to functional. It was plain sailing until I stumbled upon List.scala and saw this:  \n  \nThe above length method is used to find the number of elements in a list:  \n\n\n    List(1,2).length\n\nThe length function _iterates_ over the list and increments a len counter until the end of list is reached. Now is there something wrong with this code? Well, nothing. It was just... unexpected. Why? Because it is not functional! See the vars and the while. The length function could have been implemented like this:  \n  \nIt is not that I am against Imperative programming, but this was not something I came looking for.  \n  \n\n\n### With Expectations Come Disappointments. And then Hope.\n\nIn my previous [post](http://blog.amitashukla.in/2017/02/why-functional-programming.html), I discussed why functional programming does not favour iteration, and how [Tail Recursion](http://blog.amitashukla.in/2017/03/tail-recursion-in-functional-programming.html) is the way to overcome the need of iteration. Then why an imperative approach? Well, I researched heavily and got some leads that I will talk about [later](#why_imperative_approach). Now that I felt cheated, I took matters in my own hand.  \n  \n\n\n[![](https://3.bp.blogspot.com/-bs3U7ItWSLQ/WU06favmttI/AAAAAAAAFZ8/Ms1d1bTYRrATK4wF3TWPGtnW_5pauN3yACLcBGAs/s320/keep-calm-and-do-it-yourself.png)](https://3.bp.blogspot.com/-bs3U7ItWSLQ/WU06favmttI/AAAAAAAAFZ8/Ms1d1bTYRrATK4wF3TWPGtnW_5pauN3yACLcBGAs/s1600/keep-calm-and-do-it-yourself.png)\n\n  \n  \nAnd so, I, Amita Shukla, decided to implement my very own, MyList! But hey, wait. Just because the list in not implemented the way I want it, I want to implement my own list? Actually, yes. But there are more reasons as well.  \n  \n\n\n-   There are people who go about using data structures (like lists) without ever, ever implementing them. But the real thrill is in implementing one. And a linked list is the simplest one to start with.\n-   I have implemented linked list in [C](https://github.com/amita-shukla/programs/blob/master/TurboCFiles/CREATE_L.CPP) and [Java](https://github.com/amita-shukla/programs/blob/master/LinkedList.java) before, so it would be great to do the same in Scala. That would let me understand the philosophy behind each kind of implementation, and also, the syntactical differences between the languages.\n-   Reading Scala's List can be overwhelming. Scala's List is one of the most used classes in the language, and is power packed with functionality. It is abstract, covariant, has companion objects, implements classes/traits such as AbstractSeq, LinearSeq, Product, GenericTraversableTemplate, LinearSeqOptimised... It can be difficult to digest all in one go.\n-   Implementing List gives a better idea of the relative efficiency of list operations, which will help us to write fast and compact code using lists.\n\n### The Road Map\n\nBefore coding anything, let's ponder over what exactly are we going to make. Here is how we will be making our way ahead:  \n  \n\n\n-   [Determine the type of List to use (LinkedList v/s ArrayList)](#list_type)\n-   [Design the basic layout of MyList](#basic_list_layout)\n-   -   [Covariance](#covariance)\n    -   [Singleton Object](#object)\n    -   [Case classes](#case_class)\n-   Add methods to MyList\n-   -   [Take covariance further using add](#add)\n    -   [Pattern Matching with last](#last)\n    -   [Transform a list using map](#map)\n    -   [Understand foldLeft and Currying](#foldleft)\n    -   [Filter a list](#filter)\n-   [Some Afterthoughts](#footnotes)\n-   -   [The equivalence of MyList to scala.List](#similarities)\n    -   [The differences](#differences)\n    -   [Why List is the way it is](#why_imperative_approach)\n\n### Why is Scala List a 'LinkedList'?\n\nFundamentally, a linked list is a chain of nodes each referring to exactly one other node until you reach the end of the chain. Lists preserve order, can contain duplicates, can insert, remove elements in constant time (the first element, of course).  \n\n\n[![](https://4.bp.blogspot.com/-gjXJzX72dqs/WU_NPI74VcI/AAAAAAAAFbw/TqWvlBrtSF8CIjC7kYbd2rPsiPPwGxDdgCLcBGAs/s320/linked-list.png)](https://4.bp.blogspot.com/-gjXJzX72dqs/WU_NPI74VcI/AAAAAAAAFbw/TqWvlBrtSF8CIjC7kYbd2rPsiPPwGxDdgCLcBGAs/s1600/linked-list.png)\n\n  \nLinked List enables to make Scala's list **immutable**. Why immutable? I discussed the need of immutability in my post [Going The Functional](http://blog.amitashukla.in/2017/02/why-functional-programming.html)[Way](http://blog.amitashukla.in/2017/02/why-functional-programming.html). In short, we can say that immutability lets you write a code that is free of side effects.  \n  \nA list has simulated operations as add or update or remove, these operations in each case return a new collection and leave the old collection unchanged. Hence, we can rely on the fact that accessing the same collection value repeatedly at different points in time will always yield a collection with the same elements.  \nWe can try something similar to java.util.ArrayList, but then it can not be immutable.  \n  \n\n\n### Back to the drawing board...\n\nOur list should be able to hold a piece of data (let's call it `head`), point to the rest of the list (let's call it `tail`) and indicate if it is empty (a boolean variable `isEmpty`). So, all list operations can be defined in terms of these three operations:  \n  \n`MyList[A]` defines a generic list. The term generic means we can define many specific types with one generically written class. For example, a list can be `MyList[String]`, `MyList[Int]` etc. If `MyList` is of type `A`, then the `head` is of type `A` and the `tail` is of type `MyList[A]`.  \n  \n\n\n[![](https://3.bp.blogspot.com/-Tbku9YpHBY4/WU5QZmDZ7OI/AAAAAAAAFao/tKMotw8lQaE_dYTM09DgsLVgMwZA7j2KACLcBGAs/s1600/MyList.png)](https://3.bp.blogspot.com/-Tbku9YpHBY4/WU5QZmDZ7OI/AAAAAAAAFao/tKMotw8lQaE_dYTM09DgsLVgMwZA7j2KACLcBGAs/s1600/MyList.png)\n\n  \nHowever, this list doesn't suggest a way to indicate the end of the list. At first, it may occur to assign the `head` and the `tail` as `null`. But `null` has drawbacks associated with it (say, `NullPointerException` ). So, we need each node of the list to be either of the two types:  \n\n\n-   An object to mark the end of a list, let's say, `MyEmptyList`\n-   And a regular class to mark all the other nodes, let's say, `MyNonEmptyList`.\n\nAnd therefore, our list should be abstract: so that we cannot instantiate `MyList` by calling an empty constructor. By making the list abstract, we can now instantiate a list only in terms of either `MyEmptyList` or `MyNonEmptyList`.  \n  \n\n\nWe have a bunch of concepts here.  \n\n\n### Covariance\n\n`MyList` has a type parameter `A`. What does the `+` sign in front of it mean? In formal terms, A plus sign means that values of type A appear in **covariant** (+) position. In simpler terms, it means a list can also take the subtypes of A. A covariant position indicates that the type A always occurs as the output or return type. A `MyList[A]` is a subtype of a `MyList[B]`, if `A` is a sub-type of `B` (i.e. `A <: B`).  \n  \n\n\nSee? If we try to add a Cat to a list of Dogs, then the resulting list is a list of Animal. Covariance enables the compiler to find the suitable super type for all the type of objects inserted in a list. The implementation of the add method is discussed [later](#add).  \n  \nWe have applied the same concept for declaring the `MyEmptyList` as `MyList[Nothing]`. `Nothing` is the bottom-most type in Scala, a type that is the sub-type of any other type. We can thus have object `MyEmptyList` extending `MyList[Nothing]`, and thereby `MyEmptyList` becoming the sub-type of `MyList[A]` for any possible `A`. Whenever we need a list, no matter what the element type, we can use `MyEmptyList`.  \n\n\n### Object MyEmptyList\n\nThe `MyEmptyList` is not a class but a **Singleton object**.Unlike Java, there is no static keyword in Scala, instead, we have singleton object. We use an object here to define a single-use class for marking the end of the list.  \n  \nThe value of `isEmpty` in the `MyEmptyList` is always true (well, obviously) and it is not supposed to have a `head` element or a `tail`. The `MyEmptyList` extends from `MyList` of type `Nothing`, which is the bottom most type of all types. This gives the best of both worlds: it is used to signal the lack of value and still be type-safe. As discussed before, that is the reason we have `MyList[+A]` instead of `MyList[A]`, because we accept objects of type `A` and it's subtypes (`Nothing`).  \n\n\n### Case Class MyNonEmptyList\n\nThe MyNonEmptyList is a **case class**. What is a case class? With case class, you can define the primary constructor as part of the class declaration itself. So what is the constructor we are talking about here? Take a look:  \n  \nThis is cool as it allows us to force the user to parameterize the `MyNonEmptyList` with a `head` and a `tail` for instantiation. Obviously, a non-empty list must have a head and a tail. We use case class here because they let us magically perform Pattern Matching, as we will see [later](#last).  \n  \n\n\n### It's Time for Action!\n\nNow that we have our structure defined, we can add some functionalities in our MyList class.  \n\n\n#### Add an element to a list\n\nThe most basic function would be the ability to add an element to a list. It can be done as:  \n  \n\n\nAs explained in the covariance section, adding an element of a different type allows the compiler to return the list of the nearest common super type. Also, observe that the add function adds an element to the front of the list and not to the end, as adding to front takes O(1) time whereas adding to last takes O(n) time for linked lists.  \n\n\n#### Finding the last element of a list\n\nNow let us start with some pattern matching magic! Suppose we have to write a function to return the last element of a list:\n\n  \n\n\n  \n\n\nWhat is pattern matching here? Pattern matching is a mechanism for checking a value against a pattern. It is a more powerful version of the switch statement in Java. Its best use is Case Classes, as you see in the above implementation. The head and tail of a MyNonEmptyList can be used in the case body.  \n  \nThough Pattern Matching can be used to deconstruct complex structures and can be used in place of if-else statements, the compiler generates a lot of code under the hood if pattern matching is used for booleans.  \n  \n\n\n#### Mapping a List\n\nThe map applies the function passed to it to convert each element of the list into a different value or type. It is really simple to implement:\n\n  \n\n\nA map is a useful function as it can be used for list transformations. Let's have a look at another such important function: `foldLeft`.  \n\n\n#### FoldLeft\n\nThe signature of the foldLeft function is as follows:  \nfoldLeft\\[B](z:B)(f: (B,A)=>B):B  \nThe foldLeft function goes through the whole List, from head to tail, and passes each value to f. For the first list item, that first parameter, z, is used as the first parameter to f. For the second list item, the result of the first call to f is used as the B type parameter.  \n  \n  \n\n\nThe `foldleft`has a 'left' in it as it operates by taking elements of a list from left to right. Why is this important? Because there can be functions which output different result depending on whether the order of operands (e.g. divide operation, log function etc).\n\nThe foldLeft method is a **curried** function. In simple terms, it just means that it accepts two arguments in separate parentheses instead of one.  \n\n\n#### Filter\n\nA filter is a function that drops those elements of the list which do not satisfy a given condition.\n\n  \n\n\n  \n\n\nSo far, we have implemented the functions add, last, map, foldLeft, filter. There are many more functions in the original Scala List that we can implement in a functional way. However, there are some points that we should keep in mind.  \n\n\n### Foot Notes\n\n-   Remember that all the operations are on immutable lists, i.e. they return a new list every time they are called and do not modify the original list.\n-   The scala.List has a similar structure with a few differences. The `MyEmptyList` discussed here is similar to the object `Nil`, and `MyNonEmptyList` is equivalent to the class `::` (pronounced as 'cons'). In Scala, the special properties of any method-name ending with `:` is that it makes the operation right-associative. Therefore, `MyNonEmptyList(head,tail)` can be written as `tail.::head` or `head :: tail` .\n-   Not all functions in `MyList` are as efficient as they can be. As I discussed in my post about [Tail Recursion](http://blog.amitashukla.in/2017/03/tail-recursion-in-functional-programming.html), functions can be made tail recursive for efficiency. Let's take the simplest example, `length`:\n-   Why imperative approach for scala.List? [This](http://www.artima.com/pins1ed/implementing-lists.html#22.4) discussion, by Martin Odersky, Lex Spoon, and Bill Venners talks about why imperative implementation was used for immutable list implementation. Also worth reading is [this](http://debasishg.blogspot.in/2008/10/to-tail-recurse-or-not.html) article by Debasish Ghosh, where he talks about localized mutation to achieve performance, instead of a functional implementation of map function in Scala.\n\nThere can be lot more refinements possible, but taking the first step is a feat in itself. The complete code is available on Github [here](https://github.com/amita-shukla/functional-programming/blob/master/FunctionalList/src/com/amitashukla/test.sc). We have worked on a lot of elements, which are important constructs when doing functional programming and working with Scala in general. A lot can be taken further though. Stay tuned!\n"
            },
            "published": "2017-06-25T20:30:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "providing-hadoop-configurations-to",
            "title": "Providing Hadoop Configurations to MapReduce Application using ToolRunner",
            "url": "http://blog.amitashukla.in/2017/04/providing-hadoop-configurations-to.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-04-19",
                "slug": "providing-hadoop-configurations-to",
                "title": "Providing Hadoop Configurations to MapReduce Application using ToolRunner"
              },
              "rawMarkdownBody": "\nLet's talk about Map Reduce Programming. It is simple in the first go. In fact, dealing with distributed systems has never been simpler. Design your job into Map and Reduce tasks. Implement these functions, create a jar, and run the hadoop jar command on your Hadoop cluster. Voila! A whole lot of things done on any amount of data.  \nBut, Map Reduce runs with its default set of configurations, and these defaults may not fit your particular case. When it comes to dealing with big data over a distributed environment, we need some tweaks every now and then.  \n  \n\n\n### Let's take an example.\n\nThe number of Reducers. If the number of reducers is more, then it results in a lot of reshuffling over the network and reduces performance. If it turns out to be less, then it anyways results in overloading each reducer with too much of map data. So what is the solution? Make the number of reducers configurable, on each run, depending on the data you are dealing with.  \n  \nThe above example was just one of the configs. You may require a lot more :  \n\n\n  \n\n\nSo, there has to be a way to plug in these configurations into the code from outside. Now, for running our Map Reduce job, we need to fire the hadoop jar command :  \n\n\n  \n\n\n`hadoop jar <jar-path> <class-name> <options>`\n\n  \n\n\nWe know that the options passed through command line are directly treated as arguments to the java program. Here is where the role of Tool Runner comes to play.\n\n  \n\n\n> _The ToolRunner is a command interpreter. It works in conjunction with GenericOptionsParser to parse the generic hadoop command line arguments and modifies the Configuration of the Tool. The application-specific options are passed along without being modified._\n\n  \n\n\nLet's see the difference with this small program :  \n  \n\n\n  \nI trigger the following command :  \n\n\n> `hadoop jar tool.jar Test -Dmapred.reduce.tasks=0 arg1 args2`\n\n  \nThe output of the above program is as follows:  \n  \n\n\n  \nAs we can see, all the arguments are taken as it is by the main method. However, when the run method is called the ToolRunner magic happens. It interprets the configurations passed to the program and separates them out of the other arguments.  \n  \n\n\n## How ToolRunner works?\n\nTo get a deeper understanding of what happens under the hood, let's have a look at the source code of the ToolRunner class :  \n  \n\n\nIt's pretty simple. The run method internally calls the GenericOptionsParser : the class that does the command line arguments parsing, and parses the options. The call to run() at the last calls the run() of the Tool class, that is responsible for triggering the job.  \n  \nNow that we have our Hadoop settings as well as our arguments handled pretty well, we can focus on the rest of our MapReduce application!\n"
            },
            "published": "2017-04-19T18:18:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "tail-recursion-in-functional-programming",
            "title": "(Tail) Recursion in Functional Programming",
            "url": "http://blog.amitashukla.in/2017/03/tail-recursion-in-functional-programming.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-03-09",
                "slug": "tail-recursion-in-functional-programming",
                "title": "(Tail) Recursion in Functional Programming"
              },
              "rawMarkdownBody": "\nIn my previous post [Going The Functional Way](http://blog.amitashukla.in/2017/02/why-functional-programming.html), I discussed the reasons for venturing into functional programming. Taking my explorations further, I soon realised a truth: Functional Programming relies heavily on Recursion.  \n  \n\n\n| [![Recursion-google](https://4.bp.blogspot.com/-JEAvmp4-ZgE/WL0Gsg3YKZI/AAAAAAAAFU8/4IMbHJCa5LoSiNcjaCQxQwx-Exicf1VLQCLcB/s320/rec.png \"Recursion\")](https://4.bp.blogspot.com/-JEAvmp4-ZgE/WL0Gsg3YKZI/AAAAAAAAFU8/4IMbHJCa5LoSiNcjaCQxQwx-Exicf1VLQCLcB/s1600/rec.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| When Google plays Recursively with You!                                                                                                                                                                                                                                  |\n\n  \n  \nConsider a simple task: Write a function to calculate the factorial of a given number 'n'.  \nLet's attempt it with Java.  \n  \n  \nAttempting the same with Scala:  \n  \n  \nYou see there is a lot of difference. First Java code is the Imperative style whereas the second Scala code is the Functional Style. At first I thought it is just another way of looking through a problem, but looks like it's a lot more than that. Functional Style uses Recursion a lot. A hell lot.  \n  \nBut why?  \nThe first code looks so simple. You iterate through a loop, multiply the number with one less that it, until you reach 0. Looping has always been easy to learn. Moreover, it is always more intuitive to go by the 'loop' way - they are heavily embedded in our lives (if you are an Imperative programmer!) and we can't imagine a problem without loops.  \nAnother reason - Java has accommodated iteration seamlessly for us. There are for loops, while loops, foreach, do-while (yes, they exist.), Iterators, ResultSet...  \n  \nLook at the second code now. There is a function in a function (Oh! it's 'functional' programming by the way), the outer function does nothing other than calling another function defined within it with an extra parameter, the inner function computes factorial recursively. Even if we manage to understand the hierarchy of the code, the fact that it is recursive makes it difficult to understand. You need to keep in mind the previous stack while calculating the present stack.  \n  \n\n\n### Why Favour Recursion over Iteration?\n\nYes we know it - Recursion is bad for a code's health. For any given large number, recursion can get costly on memory. It is because the memory has to keep track of variables used in each cycle of recursion.\n\nConsider a recursive function to calculate factorial in java:\n\nThis code, though may be intuitive, can result in memory and performance related issues.  \n  \n\n\n### What stops Functional Programming from adopting Iteration?\n\nIn functional programming, iteration conflicts with the basic principle of functional programming:  \n\n\n> _\"Functions do not have side-effects.\"_\n\nConsidering the fact that a function does not produce side effects, a loop can also be considered as a function - given the number and a number as the counter. The value of this counter is supposed to change (decrease by 1, in this case) by each call to this function. However, this is not the desired effect: the result of the loop function depends on the number of times it has been called, a _side-effect._This leaves us to use recursion.  \n  \n\n\n### How Functional Programming deals with Recursion Related issues?\n\nIn functional programming, we use a trick known as Tail Recursion to overcome the implementation issues related with recursion.  \n_Tail Recursion is a form of recursion, in which the recursive call is the last action in the function._  \n  \nTail recursion has an inherent advantage: when the recursive call is the last call, then it gives the compiler the freedom to reuse the stack. This is because, in case of tail recursion, once a recursive call is made, no variable is used later. Hence, the variables can be forgotten and the stack can be reused for a fresh set of variables.  \n  \nIn general, if the last action of a function consists of calling another function ( which may be itself), one stack frame would be sufficient for both functions. Such calls are called _tail-calls_.  \n  \n_The above reason makes Tail Recursion equivalent to Iteration._  \n  \n\n\n### How To Make Your Function Tail Recursive?\n\nGiven the reason that a function is written recursively, how can we approach a solution to a problem in a tail-recursive way?\n\n#### Accumulator\n\nFunctional Programming gives us the freedom to define a function inside a function. Hence, we can create another function called 'loop', which takes up an extra parameter called `acc`. This variable, as its name suggests, is used to 'accumulate' the result over multiple recursive calls.  \n  \n\n\nThe original function is used to call the helper function, supplying it with the initial value of the accumulator. We keep the outer function to maintain the signature of the factorial function, so that the user is not affected by the implementation side of it.  \n  \n\n\n### How to indicate the Compiler for Tail Recursion?\n\nIn Scala, only directly recursive calls to the current function are optimised by the compiler to be used in a way equivalent to that of Iteration. One can require that a function is tail recursive by using the annotation `@tailrec`\n\n  \nI hope now the not-so-intuitive-functional-code starts to make sense.  \nA side - effect free language, though seems to have adopted complex ways, unfolds into really simple version as we get used to it. Let's see what all it has for us!\n"
            },
            "published": "2017-03-10T00:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "perplexed-in-world-of-science",
            "title": "Perplexed in the world of Science...",
            "url": "http://blog.amitashukla.in/2017/02/perplexed-in-world-of-science.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-02-26",
                "slug": "perplexed-in-world-of-science",
                "title": "Perplexed in the world of Science..."
              },
              "rawMarkdownBody": "\nAfter a long break, it was time to go through my YouTube Subscriptions, and dive in the world of Science. Science has never stopped to amaze me, and so happened when I was going through this channel - [Kurzgesagt (In a Nutshell)](https://www.youtube.com/channel/UCsXVk37bltHxD1rDPwtNM8Q). After watching each video, I got mixed feelings, of amazement, confusion, sadness, and hope. Giving you a list of some of them so you get the taste!  \n  \n\n\n  \n  \n\n\n-   There is our Earth, then the Solar System, the Milky Way, The Local Group, and Laniakea Supercluster.\n-   But how far can we go?\n-   It looks like we can not go outside our local group. And a time will come (in a few billion years) when we will not even be able to detect these outer galaxies, as they will be far, far away from us. And they are still moving far, far away from us. Depressing, huh?\n\n  \n  \n  \n\n\n-   We are prisoners of this Earth, in a way, that we owe it energy. Energy that was used up to build this planet together, us together. And hold it together.\n-   How can we break the shackles of this prison and hope to escape?\n\n  \n\n\n  \n\n\n  \n\n\n-   It is not about saving the planet. It is all about saving ourselves. The planet will survive, no matter how much we play with our nuclear toys.\n-   Our sun will die. And so will all the stars in the universe. How long will humans survive?\n-   Every day, 75 % of you is replaced. Are you really YOU??\n\n  \n  \n\n\n-   We may think we'are smart, but we are not. 90 % of our existence was as hunter-gatherers. And, in the Galactic time-scale, we are still embryos.\n\n  \n  \n\n\n-   We know the deep concepts of processors - transistors - and how our computers work in terms of bits.\n-   Let's get to Quantum Computers now. A different domain all together! There are qbits. And their state can be low and high of things like - spins, photons, magnetic field... and who talks about high and low? They can be in any proportion of these states!\n-   Quantum Computers may cause a revolution in the field of technology and medicine, but it can be used to break out present encrypted systems as well.\n\nHope these videos will motivate you into science as well. It is amazing to know how the technology around us is unfolding and what are its limits, if any.\n"
            },
            "published": "2017-02-26T19:17:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "why-functional-programming",
            "title": "Going the Functional Way",
            "url": "http://blog.amitashukla.in/2017/02/why-functional-programming.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-02-07",
                "slug": "why-functional-programming",
                "title": "Going the Functional Way"
              },
              "rawMarkdownBody": "\n2016 ended with me struggling to solve Scala assignments on Coursera. It was a mind-twisting experience, as I was accustomed to writing Java code. My [first assignment](https://github.com/amita-shukla/functional-programming) was on the topic Recursion, was a set of three problems, printing the Pascal's Triangle, checking balanced parenthesis, and change given the money. I had practised all these problems, but in Java. Doing these problems in functional programming was baffling, as it has an entirely different approach to solving problems.  \n  \nBut I wondered, why did I decide functional programming in the first place?  \n  \n\n\n### Functional Programming Makes You Look At Things Differently.\n\nFunctional programming was the answer to the question, \"What next?\" Even when you have spent sufficient time on programming, going the functional way made me an amateur again. I recalled my initial days in school, when I was given a problem and I just didn't know what to do next. Same happened here, it brought down my confidence on programming, only to achieve a new sense of confidence, a more humble one. It was the same as doing Mathematics : It is always better to solve a problem in more than one way.\n\n  \n\n\n### When You Have A Big Data Job, You Should Know Its Roots.\n\nI went through [this](https://www.joelonsoftware.com/2006/08/01/can-your-programming-language-do-this/) blog post ( I was later binge reading this blog, [Joel On Software](https://www.joelonsoftware.com/)), I realized that it was functional programming where the functions Map and Reduce were first used. I was reading a lot about Hadoop and Map Reduce before this, but nowhere I could relate all that. I decided that let's think about the Map Reduce in the way its creators thought about it. The Functional Way.\n\n  \n\n\n### A More Concise, Cleaner Code\n\nAs I went on reading code written by my colleagues in Scala, I realized that the same code in Java would have added a lot of boilerplate code. Scala was a much cleaner alternative. Though there are other languages that are more concise than Java (Python?), Scala was different. It was a mix of [Functional and Object-Oriented](https://www.scala-lang.org/).  \n  \n  \n\n\n[![](https://4.bp.blogspot.com/-Lsl1fJzasZ8/WJnHJPEqpQI/AAAAAAAAFR0/z0Gvp491Cx44Bk1njFAfBb4MCe5YuqG2ACLcB/s1600/FP.png)](https://4.bp.blogspot.com/-Lsl1fJzasZ8/WJnHJPEqpQI/AAAAAAAAFR0/z0Gvp491Cx44Bk1njFAfBb4MCe5YuqG2ACLcB/s1600/FP.png)\n\n  \n\n\n  \n\n\n### Functional Is The Way For Concurrency\n\nTo handle a huge amount of data, you take up chunks of data to handle them separately, without interacting with each other. Imperative Programming provides multi-threading of course, but we need to use them with extra care. Any thread that causes changes outside of what it is supposed to do (known as Side-Effects), it can crash the whole application. These side effects can cause threads to get entangled together (Ouch!)... and then you handle them with abstractions using locks, etc.\n\n  \n\n\nFunctional Programming, on the other hand, forces you to write side-effect free functions. And therefore, you can run these functions in any order. In this way, it becomes very simple to enable concurrency.\n\n  \n\n\n### Time v/s Space\n\nMartin Odersky, the creator of Scala, talks about the difference of time-space approach while working on the imperative or functional approach to programming.\n\nWhen we think of a time based approach, we write the code in the form of time-based steps, happening one after the other. Whereas, the functional approach guides to perform manipulation on data, making chunks, processing those chunks... this approach is space oriented.\n\nFor concurrency related problems, programming the time-based approach is more complicated as compared to the space-based approach.\n\n  \n\n\n  \n\n\n  \n\n\n  \nThere is a lot more to discuss, but I would prefer to code some of it and then write about my experiences...\n"
            },
            "published": "2017-02-07T18:01:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "writing-orc-files-using-map-reduce",
            "title": "Writing ORC files using Map Reduce",
            "url": "http://blog.amitashukla.in/2017/01/writing-orc-files-using-map-reduce.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2017-01-04",
                "slug": "writing-orc-files-using-map-reduce",
                "title": "Writing ORC files using Map Reduce"
              },
              "rawMarkdownBody": "\nLet's talk about text files first. Storing data as text files is the simplest thing to do. But there are many, many other requirements that just cannot be fulfilled by that. Dealing with text data comes with its challenges...  \n\n\n  \n\n\n### Hey, why don't you text me?\n\n#### Delimiters.\n\nThe delimiters give a hard time. When you have huge data to handle (we are talking about Big Data here), storing them as text files means we need to define a character that separates the data into columns and rows. But what if this special character is a part of the data itself? So, if you think that ^ is a character that is highly unlikely to occur in the data, you will most probably encounter it in the next batch! You do need data munging to make sure the data doesn't get messed up.\n\n  \n\n\n#### Performance.\n\nBeing Selective, suppose you have a huge dataset and you wish to query a small part of it. Let's say you write a query in Hive. But to answer your query on text data, hive now needs to read the whole data set until it finds the result. This incurs performance penalties.\n\n  \n\n\n### Column Oriented Formats\n\nThen comes this thing called Column Oriented Formats. According to Tom White in Hadoop The Definitive Guide :\n\n_A column-oriented layout permits columns that are not accessed in a query to be skipped._\n\n_  \n_\n\nSo, if I need to read a single columns only, then also the whole row is loaded into the memory. But with column oriented formats you can escape that. Hence, it gives you performance benefits when we need to fire queries involving only a small number of columns.\n\nColumn oriented formats need to maintain row splits in buffer, hence they need memory for reading and writing purposes.\n\n  \n\n\n### ORC File Format\n\nFirst thing first, ORC stands for Optimised Row Columnar. ORC is under the project Apache Hive, is used to efficiently store Hive data.It offers excellent compression ratios through the use of Run length encoding. Data stored in ORC format can be read through HCatalog so any Pig or MapReduce program can work with ORC format seamlessly.\n\n  \n\n\n### Writing ORC using MapReduce\n\nORC files can be written using Java MapReduce. For this, we need a Mapper class and a driver class.\n\n  \n\n\nLet us suppose we have data stored in the form of text files, in HDFS. We need to migrate that data to a hive table storing it in ORC format.\n\n  \n\n\nConsider the data first:\n\n  \nNow, it's time to write the mapper.  \n  \nThe mapper contains two methods, `setup()`and `map()`.  \nThe `setup()` method contains the code that is run once for all the instances of `map()` that are launched. The ORC Serde requires to specify the type string - A string that specifies the column name and the corresponding data types. Next, I create a `mapping` object, a mapping between columns and their datatypes. This mapping is used in the `map()` method later.  \n  \nThe `map()` method contains the code to read each line, process it, and write it in ORC format at the specified location. But, as seen from the signature, each line comes in `Text` format. For storing the data in respective data types, we spilt the line into columns and parse the data type according to the `mapping` object using the method `buildList()`. The `buildList()` method returns a list of objects, i.e. the parsed data in its respective data type.  \n  \nThe Driver class for calling the mapper is written like this:  \n  \n  \nThe method `setNumReduceTasks()` sets the number of reducers to 0. This is an indication that the output of the mapper goes as the final output. The input and the output path are taken as the arguments. For writing in ORC, we set the output key as `NullWritable` and output value as `Writable.`  \n\n\nLet me now provide other POJOs used here :  \n  \n  \n  \nIn the above method `buildList()`, I have caught the exception instead of throwing it so that the mapper doesn't stop entirely if the data is not according to its expected datatype (Suppose a null value).  \n  \nFor running the application, export the class files in a jar archive, and then execute the hadoop jar command, providing the input and output HDFS locations: However, here it is important to export the `HADOOP_CLASSPATH`. Also, all external jars needed, like here, I included the hive jars under the libjars option.  \n\n\n\n    $ classpath=`echo /usr/lib/hive/lib/* | sed  's/ /:/g'`\n    $ export HADOOP_CLASSPATH=\"$classpath\"\n    $ libjars=`echo /usr/lib/hive/lib/* | sed 's/ /,/g'`\n    $ hadoop jar ORCWriter.jar FileMapperDriver -libjars $libjars /user/cloudera/in /user/cloudera/output \n"
            },
            "published": "2017-01-04T16:35:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "shell-in-nutshell",
            "title": "Shell In A Nutshell",
            "url": "http://blog.amitashukla.in/2016/12/shell-in-nutshell.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-12-11",
                "slug": "shell-in-nutshell",
                "title": "Shell In A Nutshell"
              },
              "rawMarkdownBody": "\nIt looks like I am getting quite proverbial these days. For those who didn't understand, I was talking about the title. I am working on automation of my project in office, and it involved a lot of SHELL scripting. Oh yes, you got it now. Please don't kill me.\n\n  \n\n\n[![](https://4.bp.blogspot.com/-9iag99Llw-M/WEaLilMFRRI/AAAAAAAAFPM/73BBEPdmUroYGnCtAKbbw_v9jVKvXWOmACLcB/s320/m1rI9.png)](https://4.bp.blogspot.com/-9iag99Llw-M/WEaLilMFRRI/AAAAAAAAFPM/73BBEPdmUroYGnCtAKbbw_v9jVKvXWOmACLcB/s1600/m1rI9.png)\n\n  \n\n\nBack a few years I took up shell scripting in college, did some of it and then forgot it. I still have those programs somewhere in my backup drive, with a few loops and a few commands like echoing date, your name, etc. I made another modification that the script asked for your name and then echo,`\"Hi <your name> ! Nice to meet you! \"` . Then I got bored, as studying the syntax without any actual purpose did not interest me. But that knowledge definitely helped me understanding how Linux commands work and how I can play around with them.\n\n  \n\n\nI claimed I know some of shell scripting, and so was handed a two days deadline to automate the whole thing. Looks like even the experts claim to know 'some' shell scripting. I learnt a lot while I was on it, that I am going to write here.\n\n  \n\n\n### The Variables\n\nOf course, declaration of a variable was never difficult. Where can I go wrong here?\n\n`path = \"/path/to/some/directory/that/I/will/use/a/lot/many/times\"`\n\non using the command `cat $path/some-fancy-name-of-dir/some-fancy-name-of-a-file`\n\nI get a \"no such file or directory\" error. After an hour of toil and reading shell scripting basics, I realized the problem was the spaces : before and after '`=`' . After writing lots of neat and formatted code, I was subconsciously doing it. No unnecessary spaces Amita, No.\n\n  \n\n\n### The Quotes\n\nSingle quotes for string. Double quotes for variables in string.\n\n  \n\n\n### The Curly Braces for Isolating a Variable\n\nIf I have a variable `$var` and I want to append '`_temp`' to `$var` and assign it to another variable `$var2`, I would write it as :\n\n`var2=${var}_temp` , instead of confusing the shell by writing `$var_temp`.\n\n  \n\n\n### Indirect Expansion using !\n\n! is used for indirect expansion, that is, introducing one level of expansion of variable. Let me illustrate:\n\n``  \n\n\n    var1=first\n    var2=second\n    i=1\n    readvar=var$i\n    echo $readvar  #prints var1\n    echo ${!readvar} #prints first, i.e. the value of $var1\n\n  \n\n\n  \n\n\n### Replace command\n\nThe replace command comes handy whenever I want to replace string in-place in files. As simple as:\n\n`replace from to from to <input-file >output-file`\n\nIt is really convenient as I used it for replacement of multiple strings. But I had to be careful that I had to use different files for input and output.\n\n  \n\n\n### Sed\n\nYes, this is the time. Finally got my hands dirty with sed.\n\nSed is a stream editor, comes handy when you want to modify files, or do some complex manipulation in each line of each file. Just write the script, or use it directly, to one or more files. Sed does what the replace does, and much more than that. I dealt mainly with the substitution command, and delete command.\n\n-   My purpose : to replace one string with another string. As simple as:`sed 's/from/to/g' <input-file >output-file`\n-   Here, the 's' stands for substitution, and 'g' defines it global. If used without the 'g'. Sed will replace only the first occurrence of each line.\n-   Use double quotes instead of single if you want to use variables instead of the actual string.\n-   The/is a delimiter. If there is a / in the string itself, we can use any other delimiter, such as colon ( : )\n-   Similar to s, you can use 'd' to delete the line in which the string matched.\n-   One of my tasks was to remove anything that occurs after a string in each line. For this, we can simply use sed :`sed 's/word*/word'`\n\n  \n\n\nThe list seems too short for now. Possibly it is rather the experience that counts. We can learn a hundred facts from books, as I did in college, but it is its application that brings that confidence in you.\n\n  \n\n\n  \n\n\n  \n\n\n  \n\n"
            },
            "published": "2016-12-12T00:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "inevitable-vi",
            "title": "Inevitable Vi",
            "url": "http://blog.amitashukla.in/2016/12/inevitable-vi.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-12-05",
                "slug": "inevitable-vi",
                "title": "Inevitable Vi"
              },
              "rawMarkdownBody": "\nOk I confess, I had heard like a hundred times that you just can't escape Vi, the powerful text editor of all times. But even when I had worked on Ubuntu or to say, Linux machine for a while, I never felt that dire need to work on Vi. Oh common, you have GEdit! Or Nano -- I had used it a number of times. And then, of course, I knew a few commands (I know only some even now), and my favourite was :q! , just in case I accidently get to use Vi.  \n\n\n  \n\n\nBut it has been a while that I have been using Vi. It was never that I had any kind of aversion from it, so when I had to access some distant server using Putty that offers you no GUI support for Gedit, or no Nano, you had to venture into the Vi world. So from :q! , I moved to :wq.\n\n  \n\n\n[![](https://4.bp.blogspot.com/-cWAxqJoloiQ/WEVdc8SltnI/AAAAAAAAFO8/pSg4D4VbhuY_LpUrkU6CYisI6Iprol4pACEw/s1600/main-qimg-f157a9584f79e958652338eae9a28fc9.png)](https://4.bp.blogspot.com/-cWAxqJoloiQ/WEVdc8SltnI/AAAAAAAAFO8/pSg4D4VbhuY_LpUrkU6CYisI6Iprol4pACEw/s1600/main-qimg-f157a9584f79e958652338eae9a28fc9.png)\n\n  \n\n\n  \n\n\nI am not going to write the regular stuff that I read when I was learning to use Vi. I am just going to jot down a few commands that I keep handy while using Vi. This list will be expanding definitely.\n\n  \n\n\n### History Repeats Itself\n\nAnd when such situation arises, just type : or / to navigate or edit to the previous command you used.The command :his lists the command history, and :his/ lists the search history.\n\n### Arrow keys work, check.\n\nMy Ubuntu machine gave me a tough time using Vi. Why? Because I was not even able to navigate! This was because arrow keys are not enabled in Vi. You need to usehjkl instead. And this is because arrow keys are 'far' in the keyboard. Well, I had a deadline to meet, so I used:set nocompatibleto deal with it.\n\n  \n\n\n### Insert Mode\n\nYes, though it happened only initially, I would forget to go into insert mode and start typing, and something else will happen to my file! Yes, some commands get executed. Oh God why! I finally learnt my lesson. The best way was to be in insert mode only when typing. Any pause in typing, I press esc and then press i when resuming.\n\n  \n\n\n### Line numbers\n\nYou won't get your script right on running the script the first time. All you get is a line number!\n\nPress esc, and then use the command :set nu for displaying the line numbers.\n\nI used the goto command for moving to a particular line number. Press esc, then type your line number (yes, the line number you type won't show) and then press shift+g. Your cursor will move to that location. If you do not specify a line number, it moves to the end of file.\n\n  \n\n\n### Undo\n\nTried some command and whoosh! a disaster happened. Haha! ctrl+z is not going to work. press escand u. Thank god this exists.\n\n  \n\n\n### Redo\n\nWith undo comes redo (is it because they rhyme?) . press esc and then a dot (.) .\n\n  \n\n\n### Find and Replace\n\n  \n\n\n-   :%s/from/to does it.\n-   /word highlights all the word in the document.\n-   Press n for find next and N for find previous.\n\nThe special characters, like '.' and '\\_' should be used with a back slash '\\\\' .\n\n  \n\n\n### Highlighting\n\nIt is similar to finding all occurrences of a word. If highlighting is enabled, the \\* key will highlight all occurrences of the word that is under the cursor. I stumbled into doing this by mistake, but it made me realize that Vi is no less than any other recently developed text editor.  \nAnd obviously, following the above find options does our job of highlighting.  \n  \n\n\n### Moving To the First Line\n\nJust pressing gg (key 'g' two times) places the cursor on the first line.\n\n  \n\n\nThere is a lot to learn, and a lot to explore. [This](http://stackoverflow.com/questions/1218390/what-is-your-most-productive-shortcut-with-vim/1220118#1220118) post on StackOverflow is a must read for those who want to grasp the power of Vi. And though the list seems short now, I will keep adding up more and more as I keep on working on Vi.\n\n  \n\n\n  \n\n\n  \n\n"
            },
            "published": "2016-12-05T18:01:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "read-hive-metadata-using-hcaltalog",
            "title": "Read Hive metadata using HCatalog ",
            "url": "http://blog.amitashukla.in/2016/11/read-hive-metadata-using-hcaltalog.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-11-23",
                "slug": "read-hive-metadata-using-hcaltalog",
                "title": "Read Hive metadata using HCatalog "
              },
              "rawMarkdownBody": "\nApache Hive is a client side library that is used to provide an abstraction of the data in HDFS, in the form of tables. Hive jobs are internally converted to MR plan, submitted to Hadoop cluster for execution. Now let's move on to know what is the Hive metastore.  \n  \n\n\n### The Metastore\n\nThe Hive table definitions and mappings are stored in what is called the Hive Metastore. The metastore is nothing but two of its components :  \n\n\n-   A service to which the Hive Driver connects to and queries the database schema.\n-   A relational database to hold metadata, suppose MySQL.\n\nSo what if we have some hive tables, and we want to work on this metadata while, suppose, using Pig? We can either make a way out to query metadata using our own tool, or we can make use of the Hive metadata that is already stored.\n\n  \n\n\nHere comes the job of HCatalog.\n\n  \n\n\n### HCatalog\n\nAs discussed, HCatalog makes Hive metadata available to users of other Hadoop tools like Pig, MapReduce, Hive (yes! why not!). It provides connectors for MR and Pig so that users can read/write from/to hive metastore. HCatalog provides read and write interfaces for Pig and MapReduce and uses Hive’s command line interface for issuing data definition and metadata exploration commands. Once you have the HDFS data stored in Hive, then you do not need to rewrite the schema when using other tools. You can directly access metadata of tables using HCatalog.\n\n  \n\n\nHCatalog has some other functions as well:\n\n-   Users do not need to worry about the data format being used. Table abstraction presents users a relational view of data. HCatalog supports reading and writing files in any format for which a Hive SerDe (serializer-deserializer) can be written.\n-   It also presents a REST interface to allow external tools access to Hive DDL (Data Definition Language) operations, such as “create table” and “describe table”.\n-   Notification service : Notifies workflow tools, e.g. Oozie that some data has changed.\n\nToday we will discuss using HCatalog in Java.\n\n###   \nWhy not JDBC?\n\nNow that you know that hive metastore is stored in a relational database, why not make a simple JDBC connection? Why not directly query this meta table stored in MySQL using simple SQL queries? I too had the same doubt, but there can be a few reasons for not doing so.\n\n-   What if you do not get the credentials? We know that to connect using JDBC, we need to provide the username and password. But what if you are not given access to that? Have a look at [this](http://stackoverflow.com/questions/22964302/is-there-a-way-to-access-hive-metastore-tables-from-hcatalog) StackOverflow question to understand what I am talking about. HCatalog gives you good info about metadata, without the need to directly access it.\n-   Just a connection to HCatClient does it all. One does not need to go into further details of the connection or provide any other configuration settings. HCatalog abstracts it all for us.\n\n### The Code\n\nNow let us see how we can code HCatalog to get Hive metadata.\n\nFirst of all, we need the required dependencies :\n\n  \n\n\n  \nApart from these, we may need other dependencies as well, so as to be able to run the complete application.  \nNow, let's start writing our main program. In this example, I have attempted to extract the column details of a table in hive. Therefore, I have put the result in a HashMap that maps column name to the extracted information.  \n  \n\n\nHere, class Metadata contains the extracted metadata.  \n  \n\n\nThe output is stored in metadata.txt file, as follows:  \nAlso, as we discussed the other approach, let's see its code as well :  \n  \n  \nAs we can see, here we require the connection and configuration settings. These settings may change over time and that is the reason I prefer the first approach.  \nThe effort to use HCatalog pays off. On one hand, we access data in the file system, copy/paste data, keep it in different file formats, run jobs on that data, and what not. On the other hand, HCatalog relieves us from the worries of dealing with data stored in any format, any schema. This makes us developers really powerful. We can now harness the full potential of data while sticking to the Hadoop framework.\n"
            },
            "published": "2016-11-23T11:47:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "hadoop-10-architecture",
            "title": "Hadoop 1.0 Architecture",
            "url": "http://blog.amitashukla.in/2016/08/hadoop-10-architecture.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-08-06",
                "slug": "hadoop-10-architecture",
                "title": "Hadoop 1.0 Architecture"
              },
              "rawMarkdownBody": "\n  \n\n\n### What is Hadoop?\n\nHadoop is an open source framework by Apache Foundation for handling the storage, processing of large datasets.  \n  \nHadoop 1 provides with two components, a distributed storage (HDFS) and distributed computation engine (Map Reduce). These components run their own daemons.  \n  \n\n\n### HDFS (Hadoop Distributed File System)\n\n  \nThe Hadoop Distributed File System is designed to provide fault tolerant and scalable storage deployed on commodity hardware. By commodity hardware, we mean that it is based on low-cost hardware. It provides high throughput access to large datasets. It has a master-slave architecture, comprising of master and slave nodes.  \n  \n\n\n#### Name Nodes\n\nThe name node is a daemon whose single instance runs for a single cluster, on the master node. Its responsibility is to manage the meta data of all the files that are distributed across the cluster. The name node acts as a single point of failure here.  \n  \n\n\n#### Data Nodes\n\nSeveral instances of data node run on the slave nodes. The data nodes store data in slots that are of size 64 MB by default. A single data block is replicated several times depending upon the replication factor. Data nodes send heart-beat (a signal) to name node to indicate it is running.  \n  \n\n\n### Map Reduce\n\nMap Reduce is a programming model, that does distributed computing on a Hadoop cluster. It consists of two daemons:  \n  \n\n\n#### Job tracker\n\nA single instance of job tracker runs on the same node as the name node. The client application submits the MapReduce Job to the Job Tracker first. One Map Reduce Job is broken into multiple mapper and reducer tasks.  \n  \n\n\n#### Task trackers\n\nThere are multiple instances of task trackers that running on data nodes. A task tracker executes the job assigned to it by the job tracker and sends the status of those jobs to the job tracker.  \n  \n  \nLet’s have a look at the following figure to understand the work-flow of Hadoop architecture:  \n  \n\n\n[![](https://2.bp.blogspot.com/-a2HnO1tuoSU/V6ZK9OMP2NI/AAAAAAAABlQ/dTfzh-da73Eww6at-8C8AVuDRBUVrxosACLcB/s640/hadoop2.x-components-architecture.png)](https://2.bp.blogspot.com/-a2HnO1tuoSU/V6ZK9OMP2NI/AAAAAAAABlQ/dTfzh-da73Eww6at-8C8AVuDRBUVrxosACLcB/s1600/hadoop2.x-components-architecture.png)\n\n  \n\n\n-   Clients interact with Hadoop through master nodes.\n-   They send their requests to the master node.\n-   Each job, as submitted by the clients, is received by the job tracker.\n-   The Job Tracker divides the job into multiple mapper and reducer tasks. It talks to name node to determine the location of data. It decides to run task manager on the same node or the nearest node to the one where the data is located.\n-   These tasks are passed to the task trackers, that are on the slave nodes.\n-   It is the role of task trackers to perform the tasks.\n-   Once all task trackers are finished with their tasks, job tracker takes up those results and produces the final result.\n-   This final result is sent to the client.\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n"
            },
            "published": "2016-08-07T02:11:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "decomposition-rules-in-databases-lossless-and-dependency-preservation",
            "title": "Decomposition Rules In Databases",
            "url": "http://blog.amitashukla.in/2016/07/decomposition-rules-in-databases-lossless-and-dependency-preservation.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-07-09",
                "slug": "decomposition-rules-in-databases-lossless-and-dependency-preservation",
                "title": "Decomposition Rules In Databases"
              },
              "rawMarkdownBody": "\nIn my previous posts, we discussed the [terms used in database design](http://shuklaamita.blogspot.com/2016/06/relational-database-functional-dependencies-canonical-cover-keys.html), and the [principles used to design relational databases](http://shuklaamita.blogspot.com/2016/07/normalization-in-databases.html). We discussed as to how Normal Forms can be used to determine whether or not to decompose a database, and how to decompose it.  \n  \nWe need to be very careful while decomposing a database. Any improper decomposition may lead to errors in database design.  \n  \nTo check if a decomposition is proper, we need to satisfy the following properties:  \n  \n\n\n1.  It must be a lossless join\n2.  It must be dependency preserving\n\nLet's discuss these properties in detail.\n\n  \n\n\n### Lossless\n\nSuppose a relation R is decomposed into R1 and R2.\n\nA decomposition is said to be loss less if R1 ∩R2 is the candidate key of any decomposed relation.\n\nHence, for relation R(ABC) \\[ Primary Key A] the following relations are lossless:\n\n-   R1( A,B) and R2( A, C) \\[ R1 ∩ R2 = A, and A is the primary key of R1 & R2]\n-   R1( A, C ) and R2( C, A ) \\[ R1 ∩ R2 = C, and C is the primary key of R2]\n-   R1( A, B ) and R2 ( B,C ) \\[ R1 ∩ R2 = B, and B is the candidate key of R2]\n\nOn the other hand, the decomposition\n\nR1( A,C ) and R2( B,C ) is not lossless, as R1 ∩ R2 = C, which is not the primary key of any of the relations R1 or R2.\n\n  \n\n\nHence, a loss less decomposition ensures that the attributes involved in the natural join (R1 ∩ R2) are candidate key if at least one of the two relations.\n\nThis, in turn ensures that we can never get a situation where false tuples are generated. For any value on the join attributes there will be a unique tuple in one of the relations.\n\n  \n\n\n### Dependency Preserving\n\nDependency is said to be**preserved**if we can derive all the original dependencies from the FDs after decomposition.\n\nFormally stating, if closure of functional dependencies after decomposition is same as closure of Fds after decomposition, then dependencies are preserved.\n"
            },
            "published": "2016-07-10T00:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "normalization-in-databases",
            "title": "Normalization in Databases",
            "url": "http://blog.amitashukla.in/2016/07/normalization-in-databases.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-07-02",
                "slug": "normalization-in-databases",
                "title": "Normalization in Databases"
              },
              "rawMarkdownBody": "\nIn my previous [post](http://shuklaamita.blogspot.in/2016/06/relational-database-functional-dependencies-canonical-cover-keys.html), we discussed Relational Database Design. To store data effectively, we must ensure that the data is non-redundant. This reduces conflicts. But how to design such a database that the conflicts are reduced? The answer lies in Normalization.  \n  \n[](<>)  \nA database designed keeping in mind normalization techniques leads to a more robust design and avoid the problems that can crop up later. This design is viewed in terms of Functional Dependencies, that we studied in the previous post.  \nRemember that a relation containing only 2 attributes is always normalized.  \n  \nLet's start now.  \n  \n\n\n### First Normal Form\n\nThe first states a simple rule : If all attributes in a relation are atomic, then the relation is in First Normal Form.  \n\n\n#### What does it mean for an attribute to be atomic?\n\nAn atomic attribute means that the values of that attribute can not be further divided.  \n  \nSuppose a relation has an attribute called 'Name'. Now, a name can have sub-attributes like First Name, Middle Name, and Last Name. In this case, instead of having one attribute, we should divide it into separate attributes. Therefore, we should delete the attribute 'Name' and place 3 attributes : 'First Name', 'Middle Name' and 'Last Name'.  \n  \n  \n\n\n### Second Normal Form\n\nAny relation is said to be in Second Normal Form:\n\n-   if it is in First Normal Form, and\n-   all non-prime attributes are fully, functionally dependent on the candidate key.\n\nTo check if a relation is in Second Normal Form,\n\n-   find the Candidate Key. To know how to find candidate key in a relation, check my previous post :[Relational Database Design](http://shuklaamita.blogspot.in/2016/06/relational-database-functional-dependencies-canonical-cover-keys.html)\n-   Find **Prime attributes**. Prime Attributes are those attributes that comprise a candidate key. So, if a Relation(ABC) has AB as its primary key, then A and B are prime attributes.\n-   Find **Non-Prime attributes**. All those attributes that are not prime are non-prime attributes (that was simple :D) . Hence, as in the above example, C is a non-prime attribute.\n\nLet's elaborate on what is a fully functional dependency before moving further.\n\n#### Fully Functional Dependency\n\nFor an FD to be fully functional, any subset of the candidate key (i.e. the prime attributes) should not determine any non-prime attribute.If so happens, it is called as**Partial Dependency**.\n\n  \n\n\nConsider the following diagrams for a relation R(ABCD), here the arrows represent dependency.\n\n| [![](https://1.bp.blogspot.com/-B98Be2W44Mc/V3ZPh8bumSI/AAAAAAAABOs/TlFmJii3KfAzo0tc3VQBA521ZHR1JtoJACLcB/s1600/Fully%252BFunctional%252BDependency.png)](https://1.bp.blogspot.com/-B98Be2W44Mc/V3ZPh8bumSI/AAAAAAAABOs/TlFmJii3KfAzo0tc3VQBA521ZHR1JtoJACLcB/s1600/Fully%252BFunctional%252BDependency.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Fully Functional Dependency                                                                                                                                                                                                                                                                                   |\n\n  \n\n\n| [![](https://2.bp.blogspot.com/-0C0A464XgsU/V3ZP-adQklI/AAAAAAAABOw/FTrTT_26-aQo6isUxeJ9ft12_DnZ2XSzACLcB/s1600/Partial%252BDependency.png)](https://2.bp.blogspot.com/-0C0A464XgsU/V3ZP-adQklI/AAAAAAAABOw/FTrTT_26-aQo6isUxeJ9ft12_DnZ2XSzACLcB/s1600/Partial%252BDependency.png) |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Partial Dependency                                                                                                                                                                                                                                                                  |\n\n  \n\n\n  \n\n\nYou might think, what if one non-prime attribute determines another non-prime attribute? Wait wait. We will get to that.\n\n  \n\n\nBut first, we must discuss what should be done if we find a relation that is not in 2 NF.\n\n#### Decomposing a relation into 2NF\n\nA relation can be decomposed into multiple relations in 2NF. The partial dependencies with the same attribute on the left are combined together to form a separate relation. Consider the following diagram:\n\n[![](https://4.bp.blogspot.com/-0C0A464XgsU/V3ZP-adQklI/AAAAAAAABO4/F7NmOheyNVcuoBMjewiACIDMU2VaoC_4ACKgB/s1600/Partial%252BDependency.png)](https://4.bp.blogspot.com/-0C0A464XgsU/V3ZP-adQklI/AAAAAAAABO4/F7NmOheyNVcuoBMjewiACIDMU2VaoC_4ACKgB/s1600/Partial%252BDependency.png)\n\n  \n\n\n  \n\n\nHere,\n\nAB →C : full\n\nAB →D : full\n\nB →C : partial\n\n  \n\n\nTherefore R(AB, C, D ) can be decomposed into:\n\nR1(AB, C, D) \\[Primary Key: AB]\n\nR2(B, C) \\[Primary Key : B]\n\n  \n\n\n| [![](https://3.bp.blogspot.com/-B98Be2W44Mc/V3ZPh8bumSI/AAAAAAAABO0/XkJIIb8ceRQovPz-IwS8K314RRjJ2JXAgCKgB/s1600/Fully%252BFunctional%252BDependency.png)](https://3.bp.blogspot.com/-B98Be2W44Mc/V3ZPh8bumSI/AAAAAAAABO0/XkJIIb8ceRQovPz-IwS8K314RRjJ2JXAgCKgB/s1600/Fully%252BFunctional%252BDependency.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| R1 in 2 NF                                                                                                                                                                                                                                                                                                    |\n\n  \n\n\n| [![](https://3.bp.blogspot.com/-9WgR-Qd_Bjo/V3acYI8RLtI/AAAAAAAABQA/keQ8eI1g7PASQSzeX2tgb3LQj3HjVKFGwCLcB/s1600/R2%252BIn%252B2%252BNF.png)](https://3.bp.blogspot.com/-9WgR-Qd_Bjo/V3acYI8RLtI/AAAAAAAABQA/keQ8eI1g7PASQSzeX2tgb3LQj3HjVKFGwCLcB/s1600/R2%252BIn%252B2%252BNF.png) |\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| R2 in 2NF                                                                                                                                                                                                                                                                           |\n\n  \n\n\nNote that when the candidate key contains a single attribute, the need for looking up for full or partial dependencies is eliminated, as no subset of the candidate key is possible.\n\nHence, such a relation is automatically in 2NF. You can **save** yourself from all the above analysis :P\n\n  \n\n\n### Third Normal Form\n\nA relation is in 3NF if it is in 2NF and all non-prime attributes are non-transitively dependent on candidate key.\n\nConsider the following diagram for a relation R(ABCD) with FDs:\n\nAB→C\n\nAB→D\n\nC →D\n\n[![](https://2.bp.blogspot.com/-qI9BVFFvhew/V3Z6DSi7HAI/AAAAAAAABPM/kb4YvKwHaHcQC_q1NfZ_ZTsBQrPnPi-EACLcB/s1600/Not%252BIn%252B3NF.png)](https://2.bp.blogspot.com/-qI9BVFFvhew/V3Z6DSi7HAI/AAAAAAAABPM/kb4YvKwHaHcQC_q1NfZ_ZTsBQrPnPi-EACLcB/s1600/Not%252BIn%252B3NF.png)\n\n  \n\n\nHere C is said to be transitively dependent on D. You can take it as, D has two owners: C, and AB. This can cause conflict in the schemas, at the time of insertion, deletion or updation.\n\n  \n\n\nThe wait ends here. The above diagram is very well in 2nd Normal Form but violates the rule of the Third Normal Form.\n\n  \n\n\n#### Decomposition of a relation into 3NF\n\nThe above relation R can be decomposed into two relations:\n\nR1(ABC) \\[Primary Key : AB]\n\nR2(CD) \\[Primary Key : C]\n\n  \n\n\n| [![](https://2.bp.blogspot.com/-KvqlY8he8iA/V3Z60tnXBFI/AAAAAAAABPU/oWcSwgouNdwYob6edEEgVGwU5LpElQpIACLcB/s1600/R1%252BIn%252B3NF.png)](https://2.bp.blogspot.com/-KvqlY8he8iA/V3Z60tnXBFI/AAAAAAAABPU/oWcSwgouNdwYob6edEEgVGwU5LpElQpIACLcB/s1600/R1%252BIn%252B3NF.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| R1 in 3 NF                                                                                                                                                                                                                                                                |\n\n| [![](https://3.bp.blogspot.com/-tkrREusspjI/V3Z7p5Umo5I/AAAAAAAABPg/8fIy1QK1SkciNk45AVpFCpKftFgQ5ZoKQCLcB/s1600/R2%252BIn%252B3NF.png)](https://3.bp.blogspot.com/-tkrREusspjI/V3Z7p5Umo5I/AAAAAAAABPg/8fIy1QK1SkciNk45AVpFCpKftFgQ5ZoKQCLcB/s1600/R2%252BIn%252B3NF.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| R2 in 3 NF                                                                                                                                                                                                                                                                |\n\n  \n\n\n  \n\n\nSteps to decompose a relation into 3NF :\n\n-   Find Canonical Cover\n-   Find Candidate Key\n-   Consider all the FDs a new relation\n-   Combine those relations where the primary key is same.\n-   If none of the decomposed relations contain candidate key, add a new relation containing candidate key.\n\n### Boyce-Codd Normal Form\n\nA relation is said to be in BCNF if all determinants are candidate keys.\n\n-   Find Non-Redundant Cover.\n-   Determine the candidate key.\n-   Compare with determinants.\n\nBelow is an example depicting a relation which is in 3 NF but not in BCNF:\n\n  \n\n\n| [![](https://3.bp.blogspot.com/-QbabxlUaZlc/V3aduDnAolI/AAAAAAAABQM/DIZz7GxyrIQQKaBZm0S_PXgHZxjzeXClgCLcB/s1600/Not%252BIn%252B3NF.png)](https://3.bp.blogspot.com/-QbabxlUaZlc/V3aduDnAolI/AAAAAAAABQM/DIZz7GxyrIQQKaBZm0S_PXgHZxjzeXClgCLcB/s1600/Not%252BIn%252B3NF.png) |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| In 3 NF but NOT in BCNF                                                                                                                                                                                                                                                     |\n\n  \n\n\nThe above are prominent Normal Forms that exist, and implied upon during database modeling.\n\nHowever, normalizing 'too' much a database can completely dissolve the purpose of a database. It can give rise to many small relations related to each other in a complex way.\n\nTherefore, the designers need to maintain a trade-off between normalization and performance. Some designers choose the other way: they deliberately store redundant data to improve search performance.\n\n  \n\n\n_Want to suggest edits? Get this post on GitHub : https&#x3A;//github.com/amita-shukla/blog/blob/master/23Normalization.md_\n\n  \n\n"
            },
            "published": "2016-07-03T00:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "relational-database-functional-dependencies-canonical-cover-keys",
            "title": "Relational Database Design ",
            "url": "http://blog.amitashukla.in/2016/06/relational-database-functional-dependencies-canonical-cover-keys.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-06-25",
                "slug": "relational-database-functional-dependencies-canonical-cover-keys",
                "title": "Relational Database Design "
              },
              "rawMarkdownBody": "\nDatabase systems are used to manage large bodies of information. For an enterprise, database management is crucial, for purposes such as sales, accounting, manufacturing, banking etc. Almost every institution in today's world needs to maintain a database.  \n  \n\n\n### Relational Database\n\nRelational Databases became dominant for commercial applications. Other types of database models that exist are Network, Object, Hierarchical systems. In a relational database, the data is organized in the form of tables (or relations ). These tables are organized into rows and columns. This model is named so because of its underlying theme, it stores **inter-related** data.\n\n  \n\n\n### Primary Goals of a Relational Database\n\n-   Reduce Redundancy\n-   Minimize Access Times for information retrieval\n\n  \n\n\nLet us now discuss the formal approach to relational database design.\n\n  \n\n\nWhile E-R model is the graphical representation of entities and their relationships, relational database design requires representing all data in tables, by the use of some principles, known as **Normal Forms.**We will dig in them some other time. Let's get into some concepts about relational databases.\n\n**  \n**\n\nDatabase design aims to reduce (but not eliminate) Redundancy and perform INSERT, UPDATE and DELETE operations without confronting inconsistency.\n\n  \n\n\n### Functional Dependency\n\nA relational database is expressed in terms of relations. There are several attributes that **depend** on each other, and in many different ways. For large and complex databases, it gets difficult to analyze which dependencies are logical and direct, and which ones are trivial and derived. We can ignore the later ones, because, if implied, they can cause redundancy and inconsistency in a database.  \n  \nTo formally represent these 'dependencies', we have Functional Dependencies. It can be stated as:  \n\n\n#### A→ B\n\nmeans, A functionally determines B, i.e. B ⊆ A.\n\n  \n\n\n### Closure of Attribute Sets\n\nThe full set of values that can be determined from a set of known values for a given relationship using its functional dependencies is called Closure.\n\n  \n\n\nFor example, R(ABC)\n\nIt means a relation R containing A,B,C columns , given the following dependencies exist :\n\nF: A→ B\n\nB→ C\n\n  \n\n\nthen, the closure F+ = A→ B  \nB→ C  \nA→ C  \n  \n  \n\n\n### Armstrong's Axioms\n\nClosure is computed using Armstrong's Axioms:  \n\n\n**1.****Reflexive**\n\nA → B ⇒ B ⊆ A\n\n**2. Augmentation**\n\nA→ B ⇒CA → CB\n\n**3. Transitivity**\n\nA→B, B→ C⇒A→ C\n\n**4. Union**\n\nA→ B, A →C ⇒ A →BC\n\n**5. Decomposition**\n\nA→ BC ⇒ A →B, A → C\n\n**6. Pseudo-transitivity**\n\nA→B, BC → D ⇒ AC → D\n\n  \n\n\n  \n\n\n  \n\n\nFor example, let a set F be:\n\n**A →B  \nA →C  \nBC →D**\n\nThen the closure F+ will be  \n(i) A →B  \n(ii) A →C  \n(iii) BC →D  \n\\[ The given FDs are of course a part of closure ]  \n(iv) A → BC \\[ Union ]  \n(v) A →D \\[ Transitivity Rule on (iv) and (v) ]  \n(vi) A → BCD \\[ Union on (iv) and (v) ]  \n(vii) AC →D \\[ Augmentation and then Transitivity ]  \n  \n\n\n### Non- Redundant Cover\n\n-   For a given set of FD's, choose any desired FD.\n-   Find the closure of the attribute on the left, not considering the chosen FD.\n-   If the closure of the FD contains the attribute on the right of the chosen FD, we say that the FD is redundant.\n-   Hence, remove that FD and move on to next one.\n\nFor example, given set of FDs :\n\n**A →BC**\n\n**CD →E**\n\n**E →C**\n\n**D →AEH**\n\n**ABH → BD**\n\n**DH →BC**\n\n**  \n**\n\nLets find out the redundant FDs:\n\nA+ = A \\[ Remember, we are not considering the FD whose closure we are finding ]\n\nCD+ = CDAEHB \\[ As this FD contains E int its closure, we mark it as **redundant**]\n\nE+ = E\n\nD+ = D\n\nABH+ = ABHC\n\nDH+ = DHAEBC \\[ As this FD contains BC in its closure, we mark it as **redundant**]\n\n  \nThe problem is that they depend on the order in which you start evaluating. Solution to non redundant cover may not be unique if there are more than 1 candidate key.  \n  \n\n\n### Canonical Cover\n\nA Canonical cover for a relation is a reduced set of Functional Dependencies whose closure will be the same as the actual FDs. A canonical cover is a simplification of the original dependencies and hence it is easier to test for any dependency violations in a relation.  \n  \n Following are the steps to compute canonical cover:  \n  \n\n\n-   Make the attributes simple. That is, apply Decomposition Rule to all dependencies such that there is only a single attribute on the right of all FDs.\n-   Now, remove the redundant FDs by finding closure, using the same procedure as above for redundant cover.\n-   Now make a check again. Make sure that the left side of each dependency does not have any **extraneous** attributes. An attribute of a functional dependency is said to be extraneous if we can remove it without affecting the closure of the set of FDs. If there exist any such attributes, then remove them.\n\n  \nLets take the above example,  \n  \n\n\n**A →BC**\n\n**E →C**\n\n**D →AEH**\n\n**ABH → BD**\n\nAs you can see, I have already removed the redundant dependencies.  \n**  \n** Step 1: Make the FDs 'simple'.  \nA →B  \nA →C  \nE →C  \nD →A  \nD →E  \nD →H  \nABH → B  \nABH →D  \n  \n\n\n  \nStep 2: Remove redundant dependencies.  \nA+ = AC  \nA+ = AB  \nE+ = E  \nD+ = DHEC  \nD+ = DABHC  \nD+ = DAEBC  \n  \nWe can not find any redundancy here.  \n  \nStep 3:  \nLet us check for any redundant attributes on the left side.  \n  \nSince A → B \\[ To understand it better you can interpret it as B⊆ A]  \nTherefore the FD:ABH →D can be written as AH →D.  \n  \nHence, the canonical cover is:  \nA →B  \nA →C  \nE →C  \nD →A  \nD →E  \nD →H  \nAH →D  \n  \n\n\n### Keys, Keys Everywhere\n\nLets get in terms with the keys and know about their role in a schema:\n\n  \n\n\n#### Candidate Key\n\nA candidate key is a key, or a column ( or a set of columns) that can be used to uniquely identify a row in a table. Let an attribute be A. If A+ contains all the attributes of the relation to which it belongs, then we can take it as a super set, and A can be taken as a candidate key.\n\nA candidate key is called so because they are candidates for primary key.\n\n  \n\n\nFor example, given the FDs:\n\nA →D\n\nA → B\n\nB →C\n\nD →A\n\n  \n\n\nA+ = ABCD\n\nD+ = ABCD\n\n  \n\n\nHence, A and D are candidate keys.\n\n  \n\n\n#### Primary Key\n\nThe primary key is the 'chosen one'. Out if all the candidate keys, we choose one key that is used to determine uniquely the rows of a table. Remember that, a primary key:\n\n-   is unique.\n-   does not contain null values.\n\nAll the candidate keys other than the primary key (the not chosen ones) are termed as **Alternate Keys.**\n\nIn the above example, we can choose A as the primary key, then D becomes the alternate key.\n\n**  \n**\n\n#### Super Key\n\nIf the closure of a key contains all the attributes of a relation, but the one that can be minimized further, is called super key.\n\n  \n\n\nLet us take a key DC. Since D is already a candidate key, DC is super key. Here, C is redundant.\n\n  \n\n\n### How to Find Candidate Key\n\nAs you can understand now, the key lies in finding the candidate key. Following are the ways to find the Candidate Key:\n\n-   Choose any attribute and take its closure. This time, remember to include the attributes on the right side of the chosen FD.\n-   If the closure contains all the attributes that exist in the given relation, then it is a candidate key.\n-   If the closure of a single key is not able to produce all the attributes, take the union of one more attribute and try again.\n-   In the worst case, all the attributes of the relation will comprise of the candidate key.\n\n  \n\n"
            },
            "published": "2016-06-26T00:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "java-watch-service-api-file-change-notification",
            "title": "JAVA API for recording changes in a directory",
            "url": "http://blog.amitashukla.in/2016/06/java-watch-service-api-file-change-notification.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-06-19",
                "slug": "java-watch-service-api-file-change-notification",
                "title": "JAVA API for recording changes in a directory"
              },
              "rawMarkdownBody": "\nWhile I was making my [File Scanner Project](https://github.com/amita-shukla/file-scanner), the most initial task was to set a watch over given property files. If any change occurred in any of the properties files, it had to be reported.  \n  \n\n\n[![Java+Watch+Service+api](https://1.bp.blogspot.com/-N5Lm08r-JlE/V2_r17fYbtI/AAAAAAAABNU/j_RBqo0FrUcmwsKKgRsuz65Eqg6QdytXQCLcB/s1600/JAVA_%2Bwatch_service_api.jpg)](https://1.bp.blogspot.com/-N5Lm08r-JlE/V2_r17fYbtI/AAAAAAAABNU/j_RBqo0FrUcmwsKKgRsuz65Eqg6QdytXQCLcB/s1600/JAVA_%2Bwatch_service_api.jpg)\n\n  \n  \nYou may have seen this functionality in the form of 'file change notification'. Suppose you are writing a program, and the file is modified by some other program. You then see a notification saying to load the changes.  \nAnother time it may happen that you are working on a project with several files and any change in a file in the same project prompts a notification that a file is changed.  \n  \nTo make this functionality, we need to keep a regular watch over the directory. One way we can think of is that we can poll the directory (file system) from time to time to record any changes.  \n  \nBut the API that comes to our rescue is Watch Service API, in java.nio.file package.  \n  \n\n\n### How does Watch Service API work?\n\nWhen a watch service is initiated, a separate thread is launched that keeps track of the changes in the specified directory.\n\nFrom the main(), I call a method called runWatch(). This initiates the whole process.\n\n  \n\n\nAs you can see I call a method of the WatchDir class.  \nThe WatchDir class contains the functionalities needed for watching over the directory.  \nIn the constructor, we can initiate the 'watcher'. The watcher is nothing but an instance of WatchService API, that will do the job for us.  \n  \n  \n\n\n  \nThe register() assigns the watcher. Other events can also be specified, such as  \n  \n\n\n-   ENTRY_CREATE\n-   ENTRY_DELETE\n-   OVERFLOW\n\nNext is the processEvents(). This method creates an infinite loop which polls for events and as and when they happen, it reports them.\n\n  \n\n\n  \n\n\n  \n\n\nThe processing events are described aptly in the Oracle WatchService API tutorial :\n\n  \n\n\nThe order of events in an event processing loop follow:\n\n> 1.  Get a watch key. Three methods are provided:\n>\n>     -   [`poll`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchService.html#poll--) – Returns a queued key, if available. Returns immediately with a `null` value, if unavailable.\n>     -   [`poll(long, TimeUnit)`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchService.html#poll-long-java.util.concurrent.TimeUnit-) – Returns a queued key, if one is available. If a queued key is not immediately available, the program waits until the specified time. The`TimeUnit` argument determines whether the specified time is nanoseconds, milliseconds, or some other unit of time.\n>     -   [`take`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchService.html#take--) – Returns a queued key. If no queued key is available, this method waits.\n>\n> 2.  Process the pending events for the key. You fetch the `List` of [`WatchEvents`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchEvent.html)from the [`pollEvents`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchKey.html#pollEvents--) method.\n>\n> 3.  Retrieve the type of event by using the [`kind`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchEvent.html#kind--) method. No matter what events the key has registered for, it is possible to receive an `OVERFLOW` event. You can choose to handle the overflow or ignore it, but you should test for it.\n>\n> 4.  Retrieve the file name associated with the event. The file name is stored as the context of the event, so the [`context`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchEvent.html#context--) method is used to retrieve it.\n>\n> 5.  After the events for the key have been processed, you need to put the key back into a `ready` state by invoking [`reset`](https://docs.oracle.com/javase/8/docs/api/java/nio/file/WatchEvent.html#reset--). If this method returns `false`, the key is no longer valid and the loop can exit. This step is very **important**. If you fail to invoke `reset`, this key will not receive any further events.\n\n  \nWhen an event occurs, we can either print the result using System.out.println , or call another function that takes these values further and does whatever else we may want.  \nFor example, in this project, I have transferred the file name and the event type, which passes these values to another object to further work on it.  \n  \nSo, we are done! You might get overwhelmed thinking about the complexity of the task, but it's quite simple as we dig into it.  \n  \nHere is the complete code of WatchDir class that handles Watch Service API.  \n  \n  \n\n\nYou can get the code and project [here](https://github.com/amita-shukla/file-scanner/blob/master/src/WatchDir.java) at GitHub.  \n  \n  \n_Want to suggest edits? Get this post on Github : <https://github.com/amita-shukla/blog/blob/master/21WatchService.md>_\n\n_  \nWant to view how I tackled other problems in other projects? Check Out : <http://shuklaamita.blogspot.in/2016/02/implement-own-session-mechanism-java.html>  \n  \nEDIT (26/06/2016) : Image added_\n"
            },
            "published": "2016-06-19T11:59:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "change-auto-resize-blogger",
            "title": "How I resized the post image of blog posts",
            "url": "http://blog.amitashukla.in/2016/06/change-auto-resize-blogger.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-06-12",
                "slug": "change-auto-resize-blogger",
                "title": "How I resized the post image of blog posts"
              },
              "rawMarkdownBody": "\nMaintaining a blog is a real problem. And when using a custom template, it gets really difficult to even make a single change, as it may reflect somewhere else, if any careless action is made.\n\n  \n\n\nOut of the one change, a major (though it seemed trivial) problem that I faced was to change the default size of the pictures in the posts. Previously, the default behaviour of this blog post was to resize the picture on the home page to the post area.\n\nThis led to extremely large and blurred pictures.\n\n  \n\n\nAnd when it comes to the look of your page. What does wonders is:\n\n### CSS !!\n\n[![](https://2.bp.blogspot.com/-DNLmmOlaZP8/V1Rg8-JI4kI/AAAAAAAABMY/I843zqOZC5MHJ9IVKzyzAoUAws2oeTMTQCLcB/s1600/blog_css.png)](https://2.bp.blogspot.com/-DNLmmOlaZP8/V1Rg8-JI4kI/AAAAAAAABMY/I843zqOZC5MHJ9IVKzyzAoUAws2oeTMTQCLcB/s1600/blog_css.png)\n\n  \nFirst I needed to find out the class that surrounds this image.  \n  \nAfter search (using ctrl + f ) in the 'template' section, we can find classes like `post-image`, `img` .  \nThese classes are most likely to affect the image in the blog.  \n  \nI found out the code as :  \n  \n\n\n    .post-image img{\n        max-width:100%;\n        height:auto;\n    }\n\nI changed the attributes here, as:  \n  \n\n\n    .post-image img{\n        max-width:50%;\n        height:auto;\n     }\n\n  \n\n\nThis is because I realized that this is the setting for images in individual posts, where the images were displayed normally.  \nAnd voila! it worked.  \nBut this caused another problem, all the images were shifted to the left!  \n  \nTo fix this, I decided to make it up by coding CSS to bring images to the center area of the surrounding `div`. This is done by :  \n  \n\n\n    .post-image img{\n        display:block;\n        margin-left:auto;\n        margin-right:auto;\n        max-width:50%;\n        height:auto;\n    }\n\nLets review what these properties do.  \n  \n\n\n#### display\n\nThe display property controls how an element is displayed in accordance with the parent element. The display property can be of two types: block and inline.\n\n  \n\n\nBlock means that the element will acquire a complete block, that is, will take up the whole area in which it is extended, from left to right. e.g. div\n\nInline means, that the element will be lined up with the surrounding text. e.g. span.\n\n  \n\n\nHere the img is block that means it takes up the whole space.\n\n  \n\n\n#### margin\n\nThe margin specifies the space around the elements, outside the border. It can be margin-top, margin-bottom, margin-left, margin-right.\n\nTo bring the image to the center, I defined the left and right margin to auto. The auto property lets the margin to be calculated by the browser. Using this, we align the image element in the center horizontally.\n\n  \n\n\nAs I could not find this fix anywhere else, I added it on [Stack Overflow](http://stackoverflow.com/a/37643409/3858467).\n"
            },
            "published": "2016-06-12T11:31:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "dynamic-programming-rod-cutting-problem",
            "title": "Dynamic Programming : Rod Cutting Problem",
            "url": "http://blog.amitashukla.in/2016/06/dynamic-programming-rod-cutting-problem.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-06-05",
                "slug": "dynamic-programming-rod-cutting-problem",
                "title": "Dynamic Programming : Rod Cutting Problem"
              },
              "rawMarkdownBody": "\nOne of the most popular problem based on Dynamic Programming is Rod Cutting.  \n  \n\n\n### Problem Statement\n\nGiven a rod of n inches and a table of prices, determine the maximum revenue that can be obtained by cutting up the rod and selling the pieces.\n\n  \n\n\nFor example, let the prices be as:\n\n  \n\n\n| **Length** | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  |\n| ---------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| **Price**  | 1   | 5   | 8   | 9   | 10  | 17  | 17  | 20  | 24  | 30  |\n\n  \n\n\nFor further details of the problem, have a look in the CLRS book.  \n  \nGiven a rod of a particular length, there can be many combinations in which it can be cut. However, the length of each piece can be sold as per given in the table, yielding different revenue. Hence, the task is to maximize this revenue.  \n  \n  \n\n\n[![](https://www.cs.indiana.edu/~achauhan/Teaching/B403/LectureNotes/images/07-rodcutting-example.jpg)](https://www.cs.indiana.edu/~achauhan/Teaching/B403/LectureNotes/images/07-rodcutting-example.jpg)\n\n  \n  \nA recursive solution may seem obvious:  \n  \n\n\nHowever this solution is really inefficient. This is because the above routine calls itself again and again with the same parameter values. Hence, it solves its subproblems repeatedly.  \n  \nSo we need some optimizations. Dynamic Programming comes to rescue!  \n  \n\n\n#### Top Down Memoization\n\nA minor tweak is that we can save the results as and when they are computed.\n\n  \n\n\n  \n\n\nThis is top down approach.  \n  \n\n\n#### Bottom Up Method\n\nIn this method, we first evaluate the revenue for subproblems and save it in a array. The result of sub problems that is saved is used to solve a larger problem.\n\n  \n\n\nIn the above code, you may observe that I have written the condition of the inner loop as `j <= i / 2`. This is an optimization. If the condition was instead `j < i`, then, the loop would have computed the same result twice.  \ne.g. The revenue for a cut 1,3 is the same as the cut 3,1.  \nA discussion on the above : <http://stackoverflow.com/questions/7198585/dynamic-programming-rod-cutting>  \n  \n\n\n#### Print Complete Solution\n\nTill now our function just returns an int value, that is the maximum obtainable revenue. However, we might like to know the points at which the rod should be cut. To get the optimum solution, we need to extend the above solution to save the points of cutting in a 'solution' array.\n\nThis 'solution' array is then supplied to the print function that prints the cuts.  \nYou can view the code for this problem here:  \n<https://github.com/amita-shukla/programs/blob/master/DpRodCut.java>  \n  \n\n\n  \n\n\nThe solution can be printed using the top down approach as well.  \nThe other versions of this problem may be : A cost is associated with each cut as well. To solve this problem, what we can do is write the dp condition as:  \n  \n`q = max( q, p [j]+ dp[ i−j ] − c )`  \n  \nAnother interesting version of the rod cutting problem is <http://qa.geeksforgeeks.org/4063/minimize-the-cutting-cost-latest-google-question>.\n"
            },
            "published": "2016-06-05T21:50:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "dynamic-programming-introduction",
            "title": "Dynamic Programming",
            "url": "http://blog.amitashukla.in/2016/06/dynamic-programming-introduction.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-06-01",
                "slug": "dynamic-programming-introduction",
                "title": "Dynamic Programming"
              },
              "rawMarkdownBody": "\nAah! Its been a long time since I last updated. Sorry my dear readers about that. College has ended, and that brought with it a lot many hassles to deal with.  \n  \nNow back to my home, I thought of writing my notes in this post. And what could be a better topic than Dynamic programming! So lets get started, the Cormen way.  \n  \n\n\n### What is Dynamic Programming?\n\nDynamic programming deals with optimization problems. This implies that this technique was developed to minimize the time, or space, or both of a problem, which, had it been solved in usual way could consume a lot of time/space.  \n  \n  \n\n\n[![](https://1.bp.blogspot.com/-Ipk2UXKZCzA/V1QvPmNEJoI/AAAAAAAABLo/QMoA3Rcjw7Et1sQvnF2yRLPhmkJtVqX0QCLcB/s320/Blog_DP_Quote.png)](https://1.bp.blogspot.com/-Ipk2UXKZCzA/V1QvPmNEJoI/AAAAAAAABLo/QMoA3Rcjw7Et1sQvnF2yRLPhmkJtVqX0QCLcB/s1600/Blog_DP_Quote.png)\n\n  \n  \n  \nThe technique involves two basic approaches:  \n  \n\n\n-   Top Down method with Memoization\n-   Bottom Up method\n\n#### Top Down method with memoization\n\n1.  Write down the recursive solution to the problem.\n2.  This solution is generally inefficient.\n3.  Hence, to optimize it, save the result of each function call in a table.\n4.  This table can be an array (1-D or 2-D), map etc\n5.  Also, on each function call, first check if a solution is already saved in the table.\n6.  If so, then return the result.\n7.  If not, then continue the computation. (Step 3)\n\nThis approach is top down as it naturally goes on to solve a problem, attempting to solve the problem first and then its subproblems are solved during recursion.\n\n  \n\n\nMemoization is the term denoting the use of 'memo' or a table in this approach.\n\n  \n\n\n#### Bottom Up method\n\nBottom up method underlines the idea of solving sub problems first and then using these solutions to subproblems to find the solution to the actual problem.\n\n1.  Initialize an array (or a similar structure) that will be used to store the problems to the subproblems.\n2.  Solve the smallest subproblem whose result is obvious.\n3.  Use this solution to solve the suproblems in increasing order of size.\n\n  \n\n\n#### How is Bottom up method different from Divide And Conquer Approach?\n\nYes, both involve solving of subproblems. But there are differences:\n\n1.  The key in Dynamic programming is remembering. It saves the result of the subproblems it solves. Divide and Conquer Approach involves recursion.\n2.  The Divide and Conquer Approach does not need to save the result as each subproblem is different. However, in bottom up method, solution to a subproblem may be used in solution to any other problem. Hence, saving the result matters.\n\n### Elements of Dynamic Programming\n\nProblems that can be solved using Dynamic Programming tend to have the following properties:\n\n#### Optimal Substructure\n\nThis means that the optimal solution to a problem contains within it the optimal solution to its subproblems. Hence, we build the optimal solutions to a problem from optimal solutions to its subproblems.\n\n  \n\n\n#### Overlapping Subproblems\n\nIf we observe that the recursive solution to a problem involves solving the same subproblems over and over again, it is an indicator that a DP solution might work.\n\n  \n\n\nA lot more can be written over this topic, which I will continue in my future posts.\n\nKeep Reading!\n"
            },
            "published": "2016-06-02T00:59:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "ted-talk-by-linus-torvalds",
            "title": "Ted Talk By Linus Torvalds!",
            "url": "http://blog.amitashukla.in/2016/05/ted-talk-by-linus-torvalds.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-05-02",
                "slug": "ted-talk-by-linus-torvalds",
                "title": "Ted Talk By Linus Torvalds!"
              },
              "rawMarkdownBody": "\nWas just browsing some videos on the Ted website that I came across the interview of Linus Torvlads. It is so interesting to have a peek into the lives of people who change the world. How he lead to transform lives of people, with softwares he made but did not went on to commercialize them.  \n  \nAnd yes, the Linux World Headquarters view is quite amusing! :D\n\n  \n\n\n  \n\n"
            },
            "published": "2016-05-02T13:11:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "how-to-set-up-git-repository",
            "title": "How to set up Git Repository",
            "url": "http://blog.amitashukla.in/2016/04/how-to-set-up-git-repository.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-04-28",
                "slug": "how-to-set-up-git-repository",
                "title": "How to set up Git Repository"
              },
              "rawMarkdownBody": "\n  \n\n\n[![Github](https://1.bp.blogspot.com/-wHOJz6aX0Mk/V1QxYb3-n0I/AAAAAAAABL0/MQfFIdPTZ0wCkoTr8EJ9X-G8j1Q4WUqGACLcB/s1600/Github.png \"Github\")](https://1.bp.blogspot.com/-wHOJz6aX0Mk/V1QxYb3-n0I/AAAAAAAABL0/MQfFIdPTZ0wCkoTr8EJ9X-G8j1Q4WUqGACLcB/s1600/Github.png)\n\n  \nIts been a while I have been working with git and Github. But I almost forgot how confused I got at the the starting! I could understand all the theory and command, but how to start? This was a big question back then.  \n  \nIn this article, I would like to discuss about as to how you can set up your git repository and get going.  \nIts simple, you can merge any of your coding activities with git, enjoy a better control over your code and save yourself if anything gets messed up!  \n  \nI will discuss the theory , commands and other aspects in probably some other article. For this one, I am focusing on the basic setup (as the heading says).  \n  \n\n\n### Prerequisites\n\n#### Git installed in your system\n\n<https://git-scm.com/downloads>\n\n  \n\n\nI use git in both my operating systems, Ubuntu and Windows. And the command line is my favourite tool.  \nIn debian systems, the command is as simple as:\n\n  \n\n\n`sudo apt-get install git`  \n  \nFor windows, I have downloaded the Git Bash desktop app ( woohoo! ). Sorry Git GUI I will touch you some other time!\n\n  \n\n\n#### GitHub Account\n\nWe need a remote repository too. I have worked on other ones like BitBucket, but GitHub is good to go with.\n\n  \n\n\n### Let's Start\n\n#### Create Online Repository\n\nLog in your GitHub account and click the '**+**' sign. This is the first thing that GitHub asks you to do.\n\n  \n\n\nCreate a repository. Let's say you name it 'hello-world'.\n\n  \n\n\nObserve the pattern of naming. Lowercase letters and spaces marked by hyphens.\n\nYou can give it the description you want, as it says, it is optional.\n\n  \n\n\nLet all other things remain as it is. If you wish, though, you can add a README.md file here as well, but I prefer creating it afterwards (just a preference).\n\n  \n\n\nYou are done here until now.\n\n  \n\n\n#### Configure Account\n\nLets move to you local machine. The local machine is the system on which you will be working, on which you save your code and have installed git.\n\n  \n\n\nFirst of all, Configure Your Account on your computer. Enter the commands:  \n  \n`git config --global user.name \"your-user-name\"`\n\n`git config --global user.email \"your-email\"`\n\n  \n\n\nThis is how you have informed the git as to what your user name is and by what name should it recognize you.\n\n  \n\n\n#### Create Local Repository\n\nNow its the time to set up your local workspace, i.e. the directory where you will be working.\n\nCreate a local directory at your preferred location with the same name as your online repository name (again, a preference, nothing else).\n\n  \n\n\n`mkdir hello-world`\n\n  \n\n\nMove to this newly created directory\n\n  \n\n\n`cd hello-world`\n\n  \n\n\nNow your are in the directory. I have been calling it a directory and not arepository because it is not yet. Let's initialize it as a git repo.\n\n  \n\n\n`git init`\n\n  \n\n\nYou will observe a hidden directory named '.git' here. This indicates you have initialized it.\n\n  \n\n\n#### Work now!\n\nNow you can work on this repository the way you like and code as many files you want. When you create a file, just add it:\n\n  \n\n\n`git add \"file name\"`\n\n  \n\n\nor your can add all files in a go\n\n  \n\n\n`git add .`\n\n  \n\n\nThis let's the git to monitor changes. You call this action as 'Staging'\n\n  \n\n\nNow that your files are staged, you can work on it and want to permanently store the changes. Do it by using the git commit command:\n\n  \n\n\n`git commit -m 'commit message'`\n\n  \n\n\nThe commit message tells about the reason of commit .\n\n  \n\n\nDo not worry if you have done something wrong, you can always revert back to any previous commit anytime.\n\n  \n\n\n#### Connect To remote Repository\n\nLet the git know that to which remote repository you want it to point to:\n\n  \n\n\n`git remote add origin \"link to GitHub repository\"`\n\n  \n\n\nThis link is mentioned at the side of your repository page. Make sure you choose http version. We will try the ssl way some other day!\n\n  \n\n\n#### Push Changes To GitHub\n\nYou can push the changes to your remote repository from time to time.\n\n  \n\n\n`git push origin master`\n\n  \n\n\nThe command asks you your user name and password. Don't worry if the password is not shown typed. It is an excellent feature of Linux systems.\n\n  \n\n\nIf an error is displayed like:\n\n  \n\n\n`ssl certificate problem:self signed certificate in certificate chain`\n\n  \n\n\nTry the command:\n\n  \n\n\n`git config --global http.sslVerify false`\n\n  \n\n\n  \n\n\nExplore More\n\nA lot more can be done with git. We can fork, branch, merge and what not!\n\n  \n\n\nI have a repository that is a cheat sheet for git at the following link:\n\n<https://github.com/amita-shukla/git-guide>\n\n  \n\n"
            },
            "published": "2016-04-28T17:09:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "cell-arrays-in-matlab",
            "title": "Cell Arrays in MATLAB",
            "url": "http://blog.amitashukla.in/2016/04/cell-arrays-in-matlab.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-04-22",
                "slug": "cell-arrays-in-matlab",
                "title": "Cell Arrays in MATLAB"
              },
              "rawMarkdownBody": "\nAs I dig deeper and deeper into the MATLAB world, I learn new concepts everyday. I must say, MATLAB is very flexible. After working on languages like JAVA and C for long, working on MATLAB has given me a new sense of freedom : I have got rid of the braces ! I am so habitual of defining scope in the form of curly braces {} , that I tend to use them in MATLAB without realizing it to the point of compilation error.  \n  \nBut hey! Who says the braces have gone? The are here to stay. This time they have come in a rather more dramatic way. In the form of The Notation of Cell Arrays.  \n  \n\n\nUntil now, I was happily working with the following form of indexing:\n\n  \n\n\nIf A = \\[1 2; 3 4; 5 6],\n\nthen A(2,4) = 4.\n\n  \n\n\nJust the normal way of indexing.\n\nBut reading more into machine learning projects, I encountered this notation:\n\n  \n\n\nA{1,2} ...\n\n  \n\n\nNow what was this? Soon I found out it is a data type in MATLAB known as Cell Arrays.\n\n  \n\n\n### What are Cell Arrays?\n\nA Cell Array is made up of cells (of course). You can say these are containers, which can contain any type of data. Yes, any type, a character, a piece of text, a small matrix, any other big matrix and so on.  \n  \n  \n\n\n### Referencing a Cell Array\n\nNow here came the mind bender. I came across different kinds of notations, such as\n\n  \n\n\nA{1,2} = {1,2,3}; and\n\nA(1,2) = {1,2,3};\n\n  \n\n\nI assumed it is indexing in the same way in both cases. But there is a huge difference.\n\n  \n\n\nIf you enclose the indices in smooth parenthesis, i.e. '()' you mean to say that the value being assigned is a set of cells. Whereas, if you enclose them in curly braces, i.e.,'{}' you are actually referring to the content in individual cells.\n\n  \n\n\nAn example would make it clear.\n\nSuppose, I have\n\nThe two notations act in the same way if a single cell has to be updated:  \n\n\nBut as said above, smooth brackets can be used to refer to a set of cells and hence we can change the values of set of cells in a single sentence:\n\nAll these things look simple, but it took me a lot of time to debug these errors in my code. So beware!  \n  \nFor greater insight into it, you can look into the official [MATLAB page](http://in.mathworks.com/help/matlab/matlab_prog/access-data-in-a-cell-array.html).  \n  \nOn a side note, I used the [Online Octave Tool](http://octave-online.net/) to test the above code, as MATLAB is proprietary, Octave is suitable for most of the purposes.\n"
            },
            "published": "2016-04-22T19:42:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "clear-all-close-all-and-clc-in-matlab",
            "title": "Clear all, close all and clc in MATLAB",
            "url": "http://blog.amitashukla.in/2016/04/clear-all-close-all-and-clc-in-matlab.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-04-13",
                "slug": "clear-all-close-all-and-clc-in-matlab",
                "title": "Clear all, close all and clc in MATLAB"
              },
              "rawMarkdownBody": "\nI was studying some machine learning projects I glanced over the following startup lines:  \n\n\n  \n\n\nclc;\n\nclose all;\n\nclear;\n\n  \n\n\nI myself have used these commands several times assuming that they clear the workspace, and the command window. But what actually happens?\n\n  \n\n\n#### clc\n\nAs the documentation says, the clc command :\n\n> clc clears all input and output from the Command Window display, giving you a \"clean screen.\"\n\nAs the screen is cleared, we can still have a look at the commands used by using the up arrow key.  \n  \n\n\n#### close all\n\nThe close all command deletes all figures from the screen.\n\n  \n\n\n#### clear\n\nThe clear command removes all the variables from current work space thus releasing up the system memory.\n\n  \n\n\nAlso there is the function:\n\n  \n\n\n#### clear all\n\nThere is also the command clear all. This command as the documentation says, clears items from the memory and resets the MuPAD Engine.\n\n  \n\n\nInstead of the clear all command, the clear command must be used. This is because it takes a longer time to startup as it clears the cache memory as well. Here, the MuPAD engine is the part of the Symbolic Toolbox.\n\n  \n\n\nThe difference between clear all and clc is explained in [this](http://stackoverflow.com/q/36575677/3858467) Stack Overflow question I asked.\n\n  \n\n"
            },
            "published": "2016-04-13T18:51:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "multiple-inheritance-mixins",
            "title": "Multiple Inheritance and Mixins",
            "url": "http://blog.amitashukla.in/2016/02/multiple-inheritance-mixins.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-02-25",
                "slug": "multiple-inheritance-mixins",
                "title": "Multiple Inheritance and Mixins"
              },
              "rawMarkdownBody": "\nThis post discusses about the issues related to multiple inheritance and where it can be useful.  \nAs the concept goes, we call it multiple inheritance when a class inherits characteristics from more than one parent class.  \nInheritance is a powerful tool in object oriented programming but it should be used with caution. Languages such as Java, C# avoid multiple inheritance (though we can implement multiple interfaces) due to the potential problems it can cause.  \n  \n\n\n### The classic Diamond Problem\n\nConsider the inheritance situation as displayed below:\n\n  \n\n\n[![](https://4.bp.blogspot.com/-YvYw4MTsW64/VtHTSpQa6oI/AAAAAAAAAx4/AqK0ZjxpPZkdING188Hek_mRRGcJkQ4WgCKgB/s1600/Diamond%252BProblem.png)](https://4.bp.blogspot.com/-YvYw4MTsW64/VtHTSpQa6oI/AAAAAAAAAx4/AqK0ZjxpPZkdING188Hek_mRRGcJkQ4WgCKgB/s1600/Diamond%252BProblem.png)\n\n  \n\n\n  \n\n\nLet class B and C override a function defined in A differently. Now the ambiguity arises when class D tries to use that function. Which one should it use? The B's version or the C's version.\n\n  \n\n\nHence, multiple inheritance is disallowed in Java language to keep up with its motto to keep it simple. It, however, allows us to implement multiple interfaces, so that we can write our own implementation of the functions declared in the inherited interfaces without giving rise to any ambiguity.\n\n  \n\n\n## Mixins\n\nThe primary use of multiple inheritance is to define \"mixins\" - a set of objects to set some properties to an object. Mixins are called so because they allow properties can be mixed in to derived classes. It is like an interface, but already implemented. These are classes that provide some functionalities and are standalone in nature. This means that mixins are independent of each other and do not have inheritance with other mixins.Mixins might be classes like Displayable, Persistant, Serializable, or Sortable.\n\nJava 8 introduces a new feature in the form of default methods for interfaces. It allows a method to be defined in an interface with application in the scenario when a new method is to be added to an interface after the interface class programming setup is done. To add a new function to the interface means to implement the method at every class that uses the interface.\n\n  \n\n\nSo, mixins uses multiple inheritance but are not subject to the diamond problem.\n\n  \n\n\nSource: <http://stackoverflow.com/questions/533631/what-is-a-mixin-and-why-are-they-useful>\n\n<https://en.wikipedia.org/wiki/Mixin>\n"
            },
            "published": "2016-02-26T01:45:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "authentication-different-from-authorization",
            "title": "How is Authentication different from Authorization?",
            "url": "http://blog.amitashukla.in/2016/02/authentication-different-from-authorization.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-02-21",
                "slug": "authentication-different-from-authorization",
                "title": "How is Authentication different from Authorization?"
              },
              "rawMarkdownBody": "\nWe all hear the words 'authentication' and 'authorization' frequently. However, many a times these words are used interchangeably. This post discusses the difference between the two.  \n\n\n  \n\n\n### Authentication\n\nAuthentication means verifying the identity of the user. The process of logging in somewhere using your username and password is called Authentication. The user name, and the password are checked against an entry in the database and the user is verified. It is then the user is allowed to enter into his login space.\n\n  \n\n\n### Authorization\n\nAuthorization is basically based on access rules. There may be some resources that are accessible to you depending upon the role you play. You can be an anonymous user, a registered user, admin etc. Depending upon your role, you may or may not access resources.\n\n  \n\n\nWe can infer that authentication leads to authorization. Once a user logs in and verifies who he is, it is decided what he is allowed to do.\n\n  \n\n"
            },
            "published": "2016-02-21T09:58:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "scope-rules-facts-c",
            "title": "Scope Rules In C",
            "url": "http://blog.amitashukla.in/2016/02/scope-rules-facts-c.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-02-10",
                "slug": "scope-rules-facts-c",
                "title": "Scope Rules In C"
              },
              "rawMarkdownBody": "\nVariables to programming is the same as words to a language. These are probably the first thing that we start to deal with as soon as we start making programs. But as we go on more and more, we get to face an issue:  \n\"To what parts of the program is this variable accessible?\"  \n  \nEven if we get the answer to the above question, we may not be satisfied.  \nWhat if I want this variable to be accessible to only a few functions of the file?  \nWhat if I want this variable to be accessible outside this file as well?  \nWhat if I want this variable to never change?  \nWhat if I want this variable to be accessed faster?  \n  \nWhen we start write a program, we want to govern the way it works, instead of being governed by it! Understanding the scope rules helps us to handle the behaviour of variable easily.  \n  \n\n\n### What is a Scope?\n\nA scope of a name is the part of the program within which the name can be used.  \n  \nSo, if you use a variable 'a' as follows:  \n  \n  \nthen you can access the variable in the scope of the `if` section and no where else.  \n  \n\n\n### Local Variables : Automatic\n\nThe variables described as above are called automatic variables, aka local variables.  \nFor an automatic variable declared at the beginning of the function, the scope is the function in which it is declared. It is recreated every time the function is called. Local variables of the same name in different functions are unrelated.  \n  \nThe parameters of a function are also regarded as local variables to that function.  \nAutomatic variables are the simplest ones we deal with. We can declare them as  \n  \n`auto int a;`  \n  \nor simply,  \n  \n`int a;`  \n  \n\n\n#### \n\n#### Register Variables\n\nSome variables can be declared as register. This declaration 'advises' the compiler to place the variable in machine register, for faster access (may be due to very frequent use). However, the compiler can ignore this advice as well. If that is the case, the register variables are treated similar to automatic variables.\n\n  \n\n\nRegister variables come with some restrictions:\n\n-   A limited number of variables can be placed in registers,\n-   A register declaration can be applied to automatic variables and formal parameters to a function,\n-   It is not possible to know the address of a register, hence & operator cannot be applied.\n\nThe above restrictions may vary from machine to machine.  \n  \n\n\nWhat if we want a variable to be accessed outside a function?\n\n### Global Variables: External\n\nIf we declare a function at the beginning of the file, it is accessible all throughout the file. If we place it somewhere in between the definitions of two functions, it is accessible to all functions following the declaration.  \nAs beautifully illustrated in K&R : if we want some variables to be common to the `push()` and `pop()` functions, but not visible to other functions such as `main()`, then we can declare them after the `main()` function and before the `push()` and `pop()` functions.\n\n  \n  \n\n\nThe variables `top` and `val` are called external variables.  \nBut what if we want to use a variable before it is defined?\n\nor,what if it is defined in a different source file other than in which it is being used?\n\nIn such case, we need to declare the variable extern:  \n  \n  \nHere, the variables `sp`, `val` are defined in file 2, so to use them in file 1, we need to declare these variables as `extern` to be accessed by `push()` and `pop()` functions.  \n  \n\n\n### Static Variables\n\nThe static keyword is used to modify scope in several ways  \n\n\n#### External static\n\nThere are a few variables or function that we may want to use privately in that file. The static keyword, applied to an external variables, limits the scope of that object to the rest of the source file being complied. Similarly, if a function is declared as static, then the name is only visible to the file in which it is declared, instead of being visible to the entire program (as functions are global).  \n  \n\n\n#### Internal static\n\nIf a variable is declared as static inside a function, they are local to the function (like the automatic variables), but its value persists through the entire life of the program. This means that internal static variables provide private, permanent storage within a single function.  \n  \n  \nThe external and static variables are restricted to be assigned only constant and initialized only once, whereas automatic and register variables may be constant, or a part of expression, or can be assigned to the result of a function call.  \n  \n\n"
            },
            "published": "2016-02-10T21:16:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "implement-own-session-mechanism-java",
            "title": "How I implemented my own Session Mechanism in my project Mail Aggregator",
            "url": "http://blog.amitashukla.in/2016/02/implement-own-session-mechanism-java.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-02-03",
                "slug": "implement-own-session-mechanism-java",
                "title": "How I implemented my own Session Mechanism in my project Mail Aggregator"
              },
              "rawMarkdownBody": "\nWhile working on my project [Mail Aggregator](https://github.com/amita-shukla/mail-aggregator/tree/master/src), I went on to implement my own session mechanism, which I share in this post.  \n  \n\n\n### What is a Session?\n\n[Http](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) is a stateless protocol, i.e. it does not remember you the instant you move on to another page.\n\nBut this poses a problem. Some information needs to be present throughout some or all the pages of a website. For example, the user information. You usually see a message similar \"Welcome! Your name\" on the top of every page of the website in which you are logged in.\n\n  \n\n\n### Why was Session needed in Mail Aggregator?\n\nThe Mail Aggregator also uses session to maintain user information across the application. The client-server communication in this project occurs through web services, which do not maintain sessions , unlike those on which I previously worked, .NET, PHP, J2EE...\n\n  \n\n\nWriting my own implementation offered simplicity and flexibility. Personally, learning to build my session mechanism gave me an insight on how a session works which are otherwise beautifully packaged in popular web frameworks.\n\n  \n\n\n### An Outline\n\n1.  When a user logs in, verify if the credentials are correct.\n2.  If verified, create a token, such that it is unique for every user.\n3.  Save this token in the database with primary key as the token, along with user_id. We can have other details like timestamp (login time).\n4.  Send this token back to the client side where it can be saved as cookie.\n5.  Whenever any other web service is invoked, this token is sent back to server with other request data.\n6.  The token is received on the server side and its presence is checked in the database.\n7.  If an entry does not exist in the database, make the session invalid and send an error message to the client.\n8.  If an entry exists, extract the corresponding user_id, and carry forward the request.\n9.  On logging out, delete the token on the client side and the database entry on the server side.\n\nLets dive into the details.  \n  \n\n\n#### 1. User Log In\n\nThe details of the user are taken from the login form and packed as [JSON](http://www.json.org/) object and communicated to the server side by `LoginWebService`. The `LoginWebSerice` the calls the `LoginController`.  \nDig more: [LoginWebService.java](http://mail-aggregator/src/webservices/LoginWebService.java), [LoginController.java](http://mail-aggregator/src/controller/LoginController.java)  \n  \n\n\n#### 2. Create a unique token for every user\n\nFor creating a unique token, I assume that no two users attempt to login at the same time instant. This assumption holds true until the interface receives a lot of hits.\n\nThe token is chosen as:  \n  \n\n\nThe code above returns a 9 digit number.  \n  \n\n\n#### 3. Save the token in database\n\nWe can write a function that inserts this token in the database, such as given below. Let the table name be `token`.\n\n  \n\n\n  \n\n\n#### 4. Send token back to client side\n\nFor this project, I need to send a lot of information back for every request. But, as we know, we can only return a single object in java. Hence I wrap all the information in an object `serverResponse`.\n\nThe `serverResponse` object contains two fields, an object of `Object` type and an object of `Status` type.\n\n  \n\n\nThe `status` object contains information if the request made was successful or not.\n\n  \n\n\nAn object of Object type allows me to send any information irrespective of its type.\n\n  \n\n\nFor example, here I send the token (int type), whereas I send an arrayList of emails in another request.\n\nSo here, I set the object as token:\n\n  \n\n\n  \n\n\nThis token is wrapped as JSON object and extracted on the client side using AJAX. The access token is saved in the user's browser:  \n  \n\n\n  \nDig in more: [Object type in java](https://docs.oracle.com/javase/7/docs/api/java/lang/Object.html), [Status.java](https://github.com/amita-shukla/mail-aggregator/blob/master/src/Utils/Status.java), [ServerResponse.java](https://github.com/amita-shukla/mail-aggregator/blob/master/src/Utils/ServerResponse.java)\n\n  \n\n\n#### 5. Send token with other request data on each subsequent request\n\nThe token is attached with the data for each request that is made after the login as follows:\n\n  \n\n\n  \n\n\nFor example, you can check function `invokeAddAccount()` in this [file](https://github.com/amita-shukla/mail-aggregator/blob/master/WebContent/UI/js/login.js).\n\n  \n\n\n#### 6. Verify the token entry in the database\n\nThe following function makes an SQL query to check if the token exists in the table.\n\n  \n\n\n  \n\n\n#### 7. If no entry exists, declare the session invalid.\n\nThis function is called in a `Validator` class. If no entry exists, i.e. `selectUserIdFromToken.first()` returns false, an error message is displayed.\n\n  \n\n\n#### 8. Extract user information if an entry exists\n\nGiven a token if it exists, we can extract the corresponding `user_id` from the `token` table. Hence we can obtain all the user information, as a `user` table exists with all the user information with `user_id` as the primary key.  \n  \n\n\n#### 9. On logging out, delete the token\n\nOnce the user clicks on the logout button, the entry of token stored in the browser using the following javascript code.\n\n  \n\n\nOn the server side, we need to delete the token entry. This is a precautionary measure, if suppose the token is not deleted even on logout. Also, once user has logged out, the entry with the token becomes useless. So it should be deleted for reducing memory overhead.\n\n  \n\n\n  \n\n\n  \n\n\nTo explore more, you can check out [OAuth 2](http://oauth.net/2/), popular for its use by Google APIs for authentication and authorization.\n"
            },
            "published": "2016-02-03T19:14:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "how-to-enable-clicks-on-carousel",
            "title": "How to enable clicks on Carousel",
            "url": "http://blog.amitashukla.in/2016/01/how-to-enable-clicks-on-carousel.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-01-24",
                "slug": "how-to-enable-clicks-on-carousel",
                "title": "How to enable clicks on Carousel"
              },
              "rawMarkdownBody": "\nYesterday as I was editing my [Portfolio](http://amita-shukla.github.io/) which has the carousel functionality, I encountered a peculiar functionality. None of the left clicks on the link worked. However, the links opened on pressing the right click and clicking \"open in new tab\".  \n  \nAfter a little search, I got the answer at the the life saver [Stack Overflow](http://stackoverflow.com/a/23812607/3858467). It explains that the Carousel API prevents the default functionality of any click using `e.preventDefault()`. Hence, none of the clicks are going to work.  \n  \nNow this was a problem as Carousel is an important element for my website and I could not afford to get rid of the links as well.  \n  \nSo I tried the following approach:  \n  \nIn my file [script.js](https://github.com/amita-shukla/amita-shukla.github.io/blob/master/js/script.js), I wrote:  \n  \n``  \n\n\n    $(document).ready(function(e) {\n        $('.regular-link').click(function(e){\n            e.stopPropagation();\n        });\n        //more code here\n    }\n\n  \n`\n`The `e.stopPropagation()` prevents an event to bubble up to its parent, i.e, this event is not caught by the parent element `data-slide=\"1\"`.  \nNow whenever I needed a link to work, I added class `regular-link` in the `<a>` tag and whoa! it works now!\n"
            },
            "published": "2016-01-24T12:04:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "bitwise-operators-cheat-sheet",
            "title": "Bitwise Operators Cheat Sheet: Little Programming Tricks using Bit Operations",
            "url": "http://blog.amitashukla.in/2016/01/bitwise-operators-cheat-sheet.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-01-21",
                "slug": "bitwise-operators-cheat-sheet",
                "title": "Bitwise Operators Cheat Sheet: Little Programming Tricks using Bit Operations"
              },
              "rawMarkdownBody": "\nHere is the list that I use when dealing with bit-wise operations.  \nBit-wise operations are considered to be slightly faster than corresponding multiplication/division operations.  \nAlso, Bit-wise operations make the code cleaner at a few places, such as, when we have to check if a number is even or odd.  \n  \nHowever, my personal opinion is to code in such a way that it easily showcases your intent. So, one should not use bit-wise operators deliberately as it can make the code a bit vague at some places.  \n  \n\n\n-   Subtraction of 1 from a number toggles all the bits (from right to left) till the rightmost set bit(including the righmost set bit)\n\n  \n\n\n-   A >> 1 division by 2\n\nA &lt;&lt; 1 multiplication by 2  \n  \n\n\n-   if ((x & 1) == 0) x is even, else odd\n\n  \n\n\n-   if (x & (1&lt;&lt;n)) n-th bit is set\n\n  \n\n\n-   y = x | (1&lt;&lt;n) set the nth bit x and save as y\n\ny = x & ~(1&lt;&lt;n) unset(clear) the nth bit of x and save as y  \n  \n  \n  \n\n\n-   y = x ^ (1&lt;&lt;n) toggle the nth bit of x and save as y\n\n\n-   x & (x-1) will clear the lowest set bit of x or, turns off the rightmost set bit.\n\n\n-   x & ~(x-1) extracts the lowest set bit of x (all others are clear). Pretty patterns when applied to a linear sequence.\n\n  \n  \n\n\n-   x & (x + (1 &lt;&lt; n)) x with the run of set bits (possibly length 0) starting at bit n cleared.\n-   x & ~(x + (1 &lt;&lt; n)) the run of set bits (possibly length 0) in x, starting at bit n.\n\n  \n  \n  \n\n\n-   x | (x + 1) x with the lowest cleared bit set\n\n  \n  \n  \n\n\n-   x | ~(x + 1) extracts the lowest cleared bit of x (all others are set)\n\n  \n  \n  \n\n\n-   x | (x - (1 &lt;&lt; n)) x with the run of cleared bits (possibly length 0) starting at bit n set.\n\n  \n  \n  \n\n\n-   x | ~(x - (1 &lt;&lt; n)) the lowest run of cleared bits (possibly length 0) in x, starting at bit n are the only clear bits.\n\n  \n  \n\n\n#### Properties of Bit-wise Operations:\n\nx^x =0\n\nx^y^x = y  \n  \nx^y = (~x & y) | (x & ~y)  \n  \n\n\n#### Swap two numbers x and y\n\nx = x ^ y ;  \ny = x ^ y ;  \nx = x ^ y ;  \n  \n  \n\n"
            },
            "published": "2016-01-22T02:32:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "how-to-host-images-on-web-conveniently",
            "title": "How To Host Images on the Web conveniently",
            "url": "http://blog.amitashukla.in/2016/01/how-to-host-images-on-web-conveniently.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-01-16",
                "slug": "how-to-host-images-on-web-conveniently",
                "title": "How To Host Images on the Web conveniently"
              },
              "rawMarkdownBody": "\nIn this post we talk about how to host images on the web so that it can be viewed by everybody.  \n\n\nAs I was developing my blog, I had to post my photograph for the 'About Me' section.\n\nI went on to write my content as:  \n  \n\n\n    <div class=\"textwidget\">\n    <img height=\"240\" src=\"\" style=\"margin-bottom: 10px;\" width=\"240\" /> <br />\n    <br />\n    Hello I am <strong>Amita Shukla</strong>...blah blah blah... This blog is a\n\n    place where I want to share all the things that I learn every now and then.\n\n    blah blah blah...<br />\n    <center> </center>\n    </div>\n\n  \nThe main problem here was the attribute '**src**'. For displaying the image, I needed it to host somewhere on the web, so that I can provide the link here.\n\n#### The Failed Attempt\n\nThe main problem here was the attribute 'src'. For displaying the image, I needed it to be hosted somewhere on the web, so that I can provide the link here.  \nThe first idea was Google Drive. I uploaded the image, and acquired the shareable link. But, as I placed the link, an **aria-hidden**tag was automatically put, set to **true**. This tag automatically made the image hidden for public viewing.  \n\n\n  \n\n\n#### [Photobucket](http://s1159.photobucket.com/) paved the way!\n\nI decided to try Photobucket, and quickly created an account.\n\nIt has a very nice and clean interface. I uploaded the image. As soon as I selected the image, a few options flashed below in blue.\n\nOne of the options was 'Links'.\n\nClicking on the option provided me with the links that can be hosted on several interfaces, such as Email,IM, Blogs, HTML, Forums etc.  \n  \n\n\n[![](http://4.bp.blogspot.com/-iK89vvb5cvc/VppfHBKQoMI/AAAAAAAAAww/JYX_Z8BNOc8/s400/Links-Photo-Sharing.png)](http://4.bp.blogspot.com/-iK89vvb5cvc/VppfHBKQoMI/AAAAAAAAAww/JYX_Z8BNOc8/s1600/Links-Photo-Sharing.png)\n\n  \n\n\n  \nI quickly clicked on the HTML option that handed me with the following code:\n\n  \n\n\n\n    <center>\n    <a href=\"http://s1159.photobucket.com/user/amitashukla0906/media/Amita-Shukla_\n\n    zpsxjmxhbdt.jpg.html\" target=\"_blank\"><img src=\"http://i1159.photobucket.com/\n\n    albums/p632/amitashukla0906/Amita-Shukla_zpsxjmxhbdt.jpg\" border=\"0\" alt=\"\n\n    photo Amita-Shukla_zpsxjmxhbdt.jpg\"/></a>\n    </center>\n\n  \n\n\n  \n\n\nThanks PhotoBucket!\n"
            },
            "published": "2016-01-16T20:48:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "how-i-made-google-chrome-my-chrome",
            "title": "How I Made Google Chrome 'My Chrome'",
            "url": "http://blog.amitashukla.in/2016/01/how-i-made-google-chrome-my-chrome.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-01-07",
                "slug": "how-i-made-google-chrome-my-chrome",
                "title": "How I Made Google Chrome 'My Chrome'"
              },
              "rawMarkdownBody": "\nI have been using Google Chrome since many years and I have not found a single reason to choose any other browser over it!\n\n  \n\n\nCurrently, I am working on not Google Chrome but Chromium, open source web browser project from which the Google Chrome draws its source code.\n\n  \n\n\n[![](https://vignette4.wikia.nocookie.net/logopedia/images/2/27/DncJWGy.png/revision/latest?cb=20151102014735)](http://vignette4.wikia.nocookie.net/logopedia/images/2/27/DncJWGy.png/revision/latest?cb=20151102014735)\n\nNot a fuss about it, that's what you get when you search the Ubuntu Software Center. And I discovered what I was using quite later.\n\n  \n\n\n### My Account, My Space\n\nChrome logs me in with my personal account, and it maintains a sync across all the devices I use. I love the way it gives the window my name, providing a sense that I own this browser, and its my personal space.\n\n  \n\n\n[![](https://2.bp.blogspot.com/-nwnDq-mdcE4/Vo6EB1E9nzI/AAAAAAAAAtA/2oOqd2MwcCM/s1600/ChromeAccount.png)](http://2.bp.blogspot.com/-nwnDq-mdcE4/Vo6EB1E9nzI/AAAAAAAAAtA/2oOqd2MwcCM/s1600/ChromeAccount.png)\n\n  \n\n\nIt syncs between all the devices I use, so I do not need to worry whether I am using Google Chrome on Ubuntu or Windows or Android. It even maintains the history sites visited on all devices.\n\nAny other person who wants to use my browser gets the Guest account, or I have Mozilla Firefox! :D\n\n  \n\n\n[![](https://1.bp.blogspot.com/-slCKEWfnDto/Vo6EdJc4MLI/AAAAAAAAAtI/eLmY7nYzFxg/s640/GuestAccount.png)](http://1.bp.blogspot.com/-slCKEWfnDto/Vo6EdJc4MLI/AAAAAAAAAtI/eLmY7nYzFxg/s1600/GuestAccount.png)\n\n### The Little Bookmark Icons\n\nThe best hack I use is the way to get my favourite sites all at once, by keeping all my bookmarks in front of my eyes, on the Bookmarks Bar.\n\nWhen adding bookmarks in the usual way it is done, my chrome can accommodate only 5/6 bookmarks that are visible. However, my bookmarks bar looks like this:\n\n  \n\n\n[![](https://3.bp.blogspot.com/-3CcuSchd1qk/Vo6IXOtJj0I/AAAAAAAAAtU/zHxZRm3enbM/s640/HighlightBookmarks.png)](http://3.bp.blogspot.com/-3CcuSchd1qk/Vo6IXOtJj0I/AAAAAAAAAtU/zHxZRm3enbM/s1600/HighlightBookmarks.png)\n\n  \n\n\n  \n\n\nLoad the page completely that you want to bookmark, and star it. Choose the folder as 'Bookmarks Bar'. But before pressing 'Done' , remove the name, like this:\n\n  \n\n\n[![](https://4.bp.blogspot.com/-aFu1vKK9DAA/Vo6IpE9hplI/AAAAAAAAAtc/entWJaiBM3Q/s640/AddBookmark.png)](http://4.bp.blogspot.com/-aFu1vKK9DAA/Vo6IpE9hplI/AAAAAAAAAtc/entWJaiBM3Q/s1600/AddBookmark.png)\n\n  \n\n\n  \n\n\nYou will see the logo added on your bookmark bar. Most of the sites are popular, and you can recognize them by their logo. Even if you don't, hovering over the logo displays the name of the site.\n\nThis is quite a popular trick, but trust me! I discovered this on my own!\n\n  \n\n\n### Bookmarks Manager\n\nThe poor Bookmarks Manager has loads of work to do.\n\nI know googling is easy, but it saves a lot of time if we categorize our frequently visited sites under a single folder.\n\n  \n\n\n[![](https://2.bp.blogspot.com/-U1Tasjjg95o/Vo6JPBGE_nI/AAAAAAAAAtk/NacZDIIiKaU/s640/Folder.png)](http://2.bp.blogspot.com/-U1Tasjjg95o/Vo6JPBGE_nI/AAAAAAAAAtk/NacZDIIiKaU/s1600/Folder.png)\n\n  \n\n\n  \n\n\n### Open the most forgettable task on Startup\n\nWe open our browser many times a day, and your browser can remind of you a task you ususally forget.\n\nI use Toshl Finance Manager for managing my finance (try it! Its good), and it does its task pretty well.\n\nBut it can't help if I forget to make entries of daily transactions! set which pages we want to open automatically on start-up.\n\n  \n\n\n[![](https://3.bp.blogspot.com/-OfkYqPzh3_o/Vo6KFoRFlXI/AAAAAAAAAts/l8wc7OPxn_E/s400/StartUpPages.png)](http://3.bp.blogspot.com/-OfkYqPzh3_o/Vo6KFoRFlXI/AAAAAAAAAts/l8wc7OPxn_E/s1600/StartUpPages.png)\n\n  \n\n\n  \n\n\nGoogle News once used to be a part of startup pages as well, it is my home page now.\n\n  \n\n\n### Password Manager\n\nI would not suggest using your browser to save your passwords. For me, my brain is smart enough to remember my passwords. But yes, there are several sites that make us register with them with their complicated password policy. And if you think you can escape with having a single password for all accounts, that is dangerous, [Read Here](https://askleo.com/why_is_it_important_to_have_different_passwords_on_different_accounts/). So, in this case, Chrome's Password Manager comes handy.\n\n  \n\n\nGoogle Chrome also has its own password generator, though I haven't used it.\n\n  \n\n\n[![](https://4.bp.blogspot.com/-tl3eFsP5fP8/Vo6LABK-QPI/AAAAAAAAAt4/_90uSsvuyHQ/s320/PasswordGenerate.png)](http://4.bp.blogspot.com/-tl3eFsP5fP8/Vo6LABK-QPI/AAAAAAAAAt4/_90uSsvuyHQ/s1600/PasswordGenerate.png)\n\n  \n\n\n### Chrome's Task Manager\n\nNow that you have opened 20 tabs on chrome and your chrome can't survive it any more. Comes to the rescue, chrome's very own task manager.\n\nIt displays all the processes that are running on chrome. We can choose which one to keep and which ones to kill.\n\n  \n\n\n[![](https://2.bp.blogspot.com/-WuMba1BAtHc/Vo6LTMUkfyI/AAAAAAAAAuA/jJfUp239BQA/s320/TaskManager.png)](http://2.bp.blogspot.com/-WuMba1BAtHc/Vo6LTMUkfyI/AAAAAAAAAuA/jJfUp239BQA/s1600/TaskManager.png)\n\n  \n\n\n### Save as pdf\n\n### Chrome offers a wonderful feature that lets me save some pages offline as pdf. Just press ctrl+p and choose 'save as pdf'. This feature is really handy when I want to keep some pages for offline viewing later.\n\n### Extensions\n\nGoogle Chrome offers a handful of extensions and here are a few I use:\n\n  \n\n\n#### RescueTime\n\nThis one is my favourite. It gives me a record of how much 'productive' I have been, by recording my activities on my computer and categorizing them.\n\n  \n\n\n#### Google Dictionary\n\nA very handy extension, it provides me the meaning of a word by simply double clicking on the word.\n\n  \n\n\n#### Pocket\n\nFor me, it is the tool of procrastination, a read it later.\n\n  \n\n\n#### BuiltWith Technology Profiler\n\nIt tells me in brief, the technologies any site is built with.\n\n  \n\n\n#### AdBlocker\n\nA controversial extension, it frees me from those adds and render a neat page. Especially, it removes the adds from Youtube, giving me a much better watching experience.\n\n  \n\n\n  \n\n\nI use tons of other extensions, and many more features of Google Chrome. I can't say that these may not exist in any other browser, but the seamless experience that chrome has provided me, I must say I am one of its loyal fans!!  \n  \n  \nUpdate: Try Firefox :P\n"
            },
            "published": "2016-01-07T21:32:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "lets-plant-tree",
            "title": "Let's plant a tree!",
            "url": "http://blog.amitashukla.in/2016/01/lets-plant-tree.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2016-01-04",
                "slug": "lets-plant-tree",
                "title": "Let's plant a tree!"
              },
              "rawMarkdownBody": "\n[![](http://4.bp.blogspot.com/-ajriRld_14w/VoqIpnNSJCI/AAAAAAAAAsw/FDBRk_-CLXw/s320/1ff9c42b-52ba-429d-aaaf-f0c06bc1e894.jpg)](http://4.bp.blogspot.com/-ajriRld_14w/VoqIpnNSJCI/AAAAAAAAAsw/FDBRk_-CLXw/s1600/1ff9c42b-52ba-429d-aaaf-f0c06bc1e894.jpg)\n\n  \nTrees seem like an interesting topic but scared to start? Lets start by learning the basics of trees and move on to play with them! Like the trees' structure in relevance to computer science, we need to start from the root.  \n\n\n  \n\n\n## What is a Binary Tree?\n\nIf you have not read about trees before, this will blow your mind. A recursive definition for trees.\n\n> It is either empty, or consists of a root node which has its left and right trees, both of which are binary trees.\n\nSomewhat like this:  \n\n\n[![](http://www.sqa.org.uk/e-learning/LinkedDS04CD/images/pic026.jpg)](http://www.sqa.org.uk/e-learning/LinkedDS04CD/images/pic026.jpg)\n\n  \nDone with the textbook definition, why should we bother about binary trees?  \n  \n\n\n## When to choose Trees over linear data structures like Arrays and Linked Lists?\n\nThis leads us to:\n\n### On what basis we decide which data to use?\n\n### -   What needs to be stored:Trees are mostly used for storing hierarchical data.\n-   Cost Of operations:Trees are suitable for operations such as search, insert, delete.|   \n        | **Array (unsorted)** | **Linked List** | **Array (sorted)** | **BST** |\n| ---------- | -------------------- | --------------- | ------------------ | ------- |\n| **Search** | O(n)                 | O(n)            | O(n)               | O(lgn)  |\n| **Insert** | O(1)                 | O(n)            | O(n)               | O(lgn)  |\n| **Remove** | O(n)                 | O(n)            | O(n)               | O(lgn)  |  \n  \n-   Memory Consumption:BSTs, if efficiently built use O(lgn) space in average case and O(n) in the worst case.Enough with the introduction, lets go about how to start programming with them.We first of all need to learn how to create a tree. We know about several algorithms given in our textbooks, but we are seldom taught about how to start with them. So let's start!  \nThis is the implementation of a tree node:  \n<!-- HTML generated using hilite.me -->  \n    struct node{\n    int data;\n    struct node *left;\n    struct node *right;\n    };\n\n    typedef struct node *nodeptr;  \nBefore calling a create function, we need to data field to label a tree node as well. So we modify the above declaration:  \n  \n  \n    struct node{\n    int label; //represents the node number of the tree (0 indexed)\n    int data;\n    struct node *left;\n    struct node *right;\n    };\n\n    typedef struct node *nodeptr;  \nNow, we will start creating a tree. We need a function that asks the user to enter the data for a node label. So we have the following prototype:    void createTree(nodeptr);\n\n### How do we symbolize if a node is leaf?\n\nWe initialize its children with data = -1.\n\nIn the main function, we need to create a root node:  \n\n\n  \n\n\n    int main(){\n    int data = -1;\n    int label = 0;\n    printf(\"Provide data for the root node\\n\");\n    scanf(\"%d\",&data);\n    nodeptr root = getnode(label,data);\n    createTree(root);\n    printf(\"\\n=====================Preorder Traversal====================\\n\");\n    pretrav(root);\n    return 0;\n    }\n\n  \n\n\nNow let's define thecreateTree(nodeptr root) function:\n\n<!-- HTML generated using hilite.me -->\n\n  \n  \n  \n\n\n    void createTree(nodeptr root){\n    if(root == NULL)\n    return;\n    //Initialize left and right subtrees, which are currently null\n    nodeptr left = root->left;\n    nodeptr right = root->right;\n    //input the left child\n    int data = -1;\n    printf(\"Provide data for the left child of node %d (Enter -1 if current node is leaf)\\n\",root->label);\n    scanf(\"%d\",&data);\n    if(data != -1){\n    left = getnode(2*(root->label)+1,data);\n    root->left = left;\n    }\n    //input the right child\n    data = -1;\n    printf(\"Provide data for the right child of node %d (Enter -1 if current node is leaf)\\n\",root->label);\n    scanf(\"%d\",&data);\n    if(data != -1){\n    right = getnode(2*(root->label)+2,data);\n    root->right = right;\n    }\n    createTree(left);\n    createTree(right);\n    }\n\n  \n\n\nLike we see in the main function above, we first use the getnode() function to get the root node, ask the user to enter the data for root node, call the createTree() function, and then ask data for subsequent nodes.  \n\n\nAs you can see, this is a recursive function, after taking the data for left and right nodes, you recur over the left and right subtrees.\n\nAs you can see, the left and right child of the root node are only initialized with data if data!= null, hence if the noed is leaf, we enter data as -1.  \n  \n  \nYou can find the code above [here](https://github.com/amita-shukla/programs/blob/master/TreeCreate.c) in C and [here](https://github.com/amita-shukla/programs/blob/master/TreeNode.java), [here](https://github.com/amita-shukla/programs/blob/master/Tree.java) in java.\n"
            },
            "published": "2016-01-04T14:08:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "solve-n-queens-problem-using",
            "title": "Solve the N queen's problem using backtracking",
            "url": "http://blog.amitashukla.in/2015/12/solve-n-queens-problem-using.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2015-12-31",
                "slug": "solve-n-queens-problem-using",
                "title": "Solve the N queen's problem using backtracking"
              },
              "rawMarkdownBody": "\n### Problem Statement:\n\nGiven a NxN chess board, find a way to place N queens in such a way that no queen is in danger from another.\n\nA queen is said to be in danger from another when both the queens share the same row, column or diagonal.\n\nOne of the solutions to the 4-Queen's Puzzle is:\n\n  \n\n\n[![](http://4.bp.blogspot.com/-qrch24vNM4Q/VoVttnOzI9I/AAAAAAAAAr0/8woPBuzHis8/s1600/NQueen.png)](http://4.bp.blogspot.com/-qrch24vNM4Q/VoVttnOzI9I/AAAAAAAAAr0/8woPBuzHis8/s1600/NQueen.png)\n\n  \nSolutions to this problem exist for all natural numbers N, with N=2 and N=3 as exception.  \n  \nThis is a classic example of a problem that can be solved using a technique called **Recursive Backtracking**.  \n  \n\n\n### Strategy:\n\nHow do we go about solving this problem programmatically?\n\nWe can try all possible places one by one. But, we can observe, that we do not need to go beyond a certain limiting condition, when we realize that a solution is not possible.\n\n  \n\n\n-   Take one row at a time.\n-   Now, given a row, consider one column at a time and check if it is \"safe\" to place the queen in the cell.\n-   If we find the column is safe, then place the queen, and make a recursive call to place the queen on the next row.\n-   If we can’t find one, backtrack by returning from the recursive call, and try to find another safe column in the previous row.\n\nSo, the main routine is `findSafeColumn(int row)`\n\n  \n\n\n|      1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n    10\n    11\n    12\n    13\n    14\n    15\n    16\n    17\n    18\n    19\n    20\n    21 |     private static void findSafeColumn(int row) {\n     if (row == (boardSize)) {\n      addBoard();\n      return;\n     }\n     \n     // iterate over each column\n     for (int col = 0; col < boardSize; col++) {\n      if (isSafe(row, col)) {\n       placeQueen(row, col);\n       \n       // move on to next row\n       findSafeColumn(row + 1);\n\n       // when we have got here, means backTracked.\n       // now remove the queen you have placed so as \n       //to check the next col\n       removeQueen(row, col);\n      }   \n     }\n    } |\n| -------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n\n  \nThis is the main outline of the whole program.\n\n  \n\n\nLine 2 forms the base case, that is, if the variable row becomes equal to the size of the board, then the present configuration can be added as one of the solutions.  \nThe method `addBoard()` does exactly that.  \n  \nThe methods `placeQueen()` and `removeQueen()` will be described later.  \n  \n\n\n### How to implement the chess board?\n\nWe can implement a chess board using a 2-D boolean array, like,  \n  \nprivate static boolean\\[]\\[] board;  \n  \nWe also keep track of the board size, as we need it at many places later.  \n  \nprivate static int boardSize;  \n  \n\n\n### Implementing `placeQueen()`, `removeQueen()` , and `isSafe()`\n\nIt seems a 2- dimentional array is sufficient to implement placeQueen() and removeQueen functions as follows:  \n  \nprivate void placeQueen(int row, int col) {  \nboard\\[row]\\[col] = true;  \n}  \nprivate void removeQueen(int row, int col) {  \nboard\\[row]\\[col] = false;  \n}  \n  \nBut, the method isSafe() becomes too complex.  \n  \nA workaround this problem is introducing the following data structures (array of booleans):  \n  \nprivate static boolean\\[] colEmpty;  \nprivate static boolean\\[] upDiagEmpty;  \nprivate static boolean\\[] downDiagEmpty;  \n  \nAn entry in one of these arrays is  \ntrue if no queen is placed in the corresponding column or diagonal,  \nfalse otherwise  \n  \nBut now we need to map these boolean arrays to our 2 dimentional board:  \n\n\n| [![](http://4.bp.blogspot.com/-qiH-64xzPN4/VoV85r-YqyI/AAAAAAAAAsQ/OprNx8Q_AXM/s1600/DownDiag.png)](http://4.bp.blogspot.com/-qiH-64xzPN4/VoV85r-YqyI/AAAAAAAAAsQ/OprNx8Q_AXM/s1600/DownDiag.png) |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| upDiagonal = row + col                                                                                                                                                                            |\n\n  \n\n\n|   \n |     |\n| --- | --- |\n\n  \n  \n\n\n  \n\n\n  \n\n\n| [![](http://3.bp.blogspot.com/-znpNqpsZHR8/VoV85sEp0hI/AAAAAAAAAsM/CVq84A0BCEg/s1600/UpDiag.png)](http://3.bp.blogspot.com/-znpNqpsZHR8/VoV85sEp0hI/AAAAAAAAAsM/CVq84A0BCEg/s1600/UpDiag.png) |\n| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| downDiagonal = (boardSize - 1) + row - col                                                                                                                                                    |\n\n  \n\n\nWe use these additional arrays as follows:\n\n  \n\n\n|     1\n    2\n    3\n    4\n    5\n    6 |     private static void removeQueen(int row, int col) {\n     board[row][col] = false;\n     colEmpty[col] = true;\n     upDiagEmpty[row + col] = true;\n     downDiagEmpty[boardSize - 1 + row - col] = true;\n    } |\n| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n  \n\n\n|     1\n    2\n    3\n    4\n    5\n    6 |     private static void placeQueen(int row, int col) {\n     board[row][col] = true;\n     colEmpty[col] = false;\n     upDiagEmpty[row + col] = false;\n     downDiagEmpty[boardSize - 1 + row - col] = false;\n    } |\n| ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n|     1\n    2\n    3\n    4\n    5\n    6\n    7\n    8\n    9 |     private static boolean isSafe(int row, int col) {\n     // if col & up diag & down diag is empty, then the given position is\n     // safe\n     if (colEmpty[col] && upDiagEmpty[row + col]\n       && downDiagEmpty[boardSize - 1 + row - col]) {\n      return true;\n     }\n     return false;\n    } |\n| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n\n  \nTo save all the solutions of N-Queens problem, we can have an arraylist named `solutions` as follows:  \nstatic ArrayList&lt;ArrayList&lt;String>> solutions;  \n  \nMethod that initializes all the data structures used and calls the recursive `findSafeColumn()` method:  \n\n\n|      ```\n\n```     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n    10\n    11\n    12\n    13\n    14\n    15\n    16\n    17\n    18 | ```\n\n```    public static void solveNQueens(int n) {     // take the board as a boolean array. A true value indicates the\n     // presence of queen.\n     board = new boolean[n][n];\n     boardSize = n;\n     solutions = new ArrayList<ArrayList<String>>();\n     colEmpty = new boolean[n];\n     upDiagEmpty = new boolean[2 * n - 1];\n     downDiagEmpty = new boolean[2 * n - 1];\n     Arrays.fill(colEmpty,true);\n     Arrays.fill(upDiagEmpty, true);\n     Arrays.fill(downDiagEmpty, true);\n\n     // try the first row\n     findSafeColumn(0);\n      \n     //return solutions;\n    } |\n| ------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n  \nThe method `addBoard()` is used to fill up the solutions arrayList:  \n\n\n  \n\n\n|      1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n    10\n    11\n    12\n    13\n    14 |     private static void addBoard() {\n     ArrayList<String> boardList = new ArrayList<>();\n     for(int i=0; i<boardSize;i++){\n      String row = \"\";\n      for(int j=0;j<boardSize;j++){\n       if(board[i][j])\n        row = row.concat(\"Q\");\n       else\n        row = row.concat(\".\");\n      }\n      boardList.add(row);\n     }\n     solutions.add(boardList);\n    } |\n| ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n\n  \nWe're done!  \nCall the main method as:  \n\n\n  \n\n\n|     1\n    2\n    3\n    4\n    5\n    6 |     public static void main(String[] args) {\n      \n     solveNQueens(8);\n     System.out.println(solutions.toString());\n\n    } |\n| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n\n  \n\n\nThe output shown for 4 Queens is:\n\n\\[\\[.Q.., ...Q, Q..., ..Q.], \\[..Q., Q..., ...Q, .Q..]]\n\n  \n\n\nClick [here](https://github.com/amita-shukla/programs/blob/master/NQueens.java) to get the complete code.\n\n  \n\n"
            },
            "published": "2015-12-31T23:51:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "find-all-possible-subsets-of-given-set",
            "title": "Find all possible subsets of a given set",
            "url": "http://blog.amitashukla.in/2015/12/find-all-possible-subsets-of-given-set.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2015-12-25",
                "slug": "find-all-possible-subsets-of-given-set",
                "title": "Find all possible subsets of a given set"
              },
              "rawMarkdownBody": "\nThe problem is: Given a set of distinct integers, S, return all possible subsets.\n\n  \n\n\nElements in a subset must be in non-descending order.\n\nThe solution set must not contain duplicate subsets.\n\nAlso, the subsets should be sorted in lexicographic order.\n\n  \n\n\nFor example: For the set \\[1,2,3],\n\nThe solution would be:\n\n\\[\n\n\\[],\n\n\\[1],\n\n\\[1, 2],\n\n\\[1, 2, 3],\n\n\\[1, 3],\n\n\\[2],\n\n\\[2, 3],\n\n\\[3],\n\n]\n\n  \n\n\nThis problem can be approached by visualizing a tree:\n\n  \n\\[ ]  \n/ \\\\ \\\\  \n\\[1] \\[2] \\[3]  \n/ \\\\ |  \n\\[1,2] \\[1,3] \\[2,3]  \n\\|  \n\\[1,2,3]  \n\n\nStart with an empty node. Then, take one element. Let it be at an index 'i' of the given set.\n\nThe tree can be constructed by trying out the elements at the indexes after i.\n\nEach possibility makes a new branch.\n\nThe branching ends when we have tried out all the possibilities.\n\n  \n\n\nThe following code explains the above lines:  \n  \n\n\n<!-- HTML generated using hilite.me -->\n\n  \n\n\n|      1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n    10\n    11\n    12\n    13\n    14\n    15\n    16\n    17\n    18\n    19\n    20\n    21\n    22\n    23\n    24\n    25\n    26\n    27 |     import java.util.ArrayList;\n    import java.util.Collections;\n\n    public class FindSubsets {\n     static ArrayList<ArrayList<Integer>> sets;\n\n     public ArrayList<ArrayList<Integer>> subsets(ArrayList<Integer> set) {\n\n      Collections.sort(set);\n      sets = new ArrayList<ArrayList<Integer>>();\n      sets.add(new ArrayList<Integer>());\n      backtrack(set, 0, new ArrayList<Integer>());\n\n      return sets;\n     }\n\n     public static void backtrack(ArrayList<Integer> set, int index,\n       ArrayList<Integer> partial) {\n\n      for (int i = index; i < set.size(); i++) {\n       ArrayList<Integer> subset = new ArrayList<>(partial);\n       subset.add(set.get(i));\n       sets.add(subset);\n       backtrack(set, i + 1, subset);\n      }\n     }\n    } |\n| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n\n  \nGet the code at: <https://github.com/amita-shukla/programs/blob/master/FindSubsets.java>\n"
            },
            "published": "2015-12-26T01:01:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "cing-again-use-of-double-pointer-in",
            "title": "'C'ing again! - Use of double pointer in Linked List Insertion",
            "url": "http://blog.amitashukla.in/2015/12/cing-again-use-of-double-pointer-in.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2015-12-22",
                "slug": "cing-again-use-of-double-pointer-in",
                "title": "'C'ing again! - Use of double pointer in Linked List Insertion"
              },
              "rawMarkdownBody": "\nAs I was checking out some programming questions on the topic linked list, it was boring to just read the programs without implementing them.  \nSo, I decided to try out linked list again, trying to devise out some more efficient ways to solve a very simple problem.  \nBut before playing with the list, I needed to create a list.  \n  \nDuring the process, I revised an old concept:  \nWhy do we need to use double pointer whenever we need to change the head pointer?  \nThe function that I had to write was `insbgn()`.  \n  \n**Insertion at the beginning of the list:**  \n  \nInitial declarations:  \n\n\n     struct node{  \n         int data;  \n         struct node *next;  \n     };  \n       \n     typedef struct node *nodeptr;  \n\n  \nOn can think of the following implementation:  \n\n\n     void insbgn(nodeptr head, int data){  \n         nodeptr p = getnode();  \n         p->next = head;  \n         head = p;      \n     }  \n\n  \nBut you will observe no changes if you make a call to this function:  \n\n\n     print(head); //output: 1 2 3 4 5 6  \n     insbgn(head, 0);  \n     print(head); //output 1 2 3 4 5 6     \n\n  \nThis is because the head pointer is changing here.  \nwhen `insbgn()` is called,  \nthe pointer 'head' points to the head of the list.  \nChanges are made to the list accordingly but as soon as the function returns, the changes to the head are lost.  \n  \nTo show this, if I call print(head) from inside insbgn():  \n\n\n     void insbgn(nodeptr head, int data){  \n         nodeptr p = getnode();  \n         p->next = head;  \n         head = p;  \n         print(head);      \n     }  \n\n  \nThe output is:  \n  \n\n\n     print(head); //output: 1 2 3 4 5 6  \n     insbgn(head, 0); //output: 0 1 2 3 4 5 6  \n     print(head); //output 1 2 3 4 5 6  \n\n  \nHence you need to pass double pointer, i.e. pointer to the head pointer.  \n  \nSo, the correct way to define `insbgn()` is as follows:  \n  \n\n\n     void insbgn(nodeptr *headptr, int data){ //you get a pointer to the head pointer  \n         nodeptr p = getnode(data);  \n         p->next = *headptr; // p->next points to the value at headptr, i.e. the head of the list  \n         *headptr = p; // the value at headptr is set to p, i.e., head = p.  \n     }   \n\n  \nAs we have the pointer to the head, we can easily dereference it and manipulate the real head.  \nIf you do not know any other example than the swap problem for pass by value and pass by reference, this is another one you can count on!  \nBut if you really want to use the previous version, you will need to return the new head back:  \n  \n\n\n     nodeptr insbgn(nodeptr head, int data){  \n          nodeptr p = getnode(data);  \n          p->next = head;     head = p;  \n         printf(\"Linked list inside insbgn\\n\");  \n          print(head);  \n          printf(\"\\n\");  \n          return head;  \n      }  \n\n  \nAnd call it like:  \n`head = insbgn(head,data);`  \nThe problem with this approach is that you can assign the new head, and later go mad figuring where you got wrong.\n"
            },
            "published": "2015-12-23T02:00:00+05:30"
          }
        },
        {
          "node": {
            "kind": "blogger#post",
            "slug": "lets-innovate-we-all-seem-overwhelmed_19",
            "title": "Reinvent the wheel?",
            "url": "http://blog.amitashukla.in/2015/12/lets-innovate-we-all-seem-overwhelmed_19.html",
            "childMarkdownRemark": {
              "frontmatter": {
                "date": "2015-12-19",
                "slug": "lets-innovate-we-all-seem-overwhelmed_19",
                "title": "Reinvent the wheel?"
              },
              "rawMarkdownBody": "\n## \n\nWe all seem overwhelmed by the technology that has cloistered us. It is easy to get dazzled by large screen TVs, drones, cameras, watches, and our handy smartphones too. With new technologies releasing almost every day, a thought that flashes in my mind if this is what we can call the pinnacle of technology, and the second moment it is followed by disagreement to it. There is a lot yet to happen, and ‘true innovation’ is yet to come. So what is this ‘true innovation’ that I am talking about? Are we not innovating? Well, obviously, we are, as we trace updates to technology every now and then.  \n  \nWell, this is not innovation in true sense. Let me talk about one of the golden eras of innovation to make you appreciate the difference. The era was the period of the Industrial Revolution – which led to unanticipated advances in the areas of manufacturing and transportation. It marked a shift to powered, special purpose machinery, factories and mass production. The iron and textile industries, development of Steam engine by James Watt, improved systems in communication and banking. It was what that that steered us to an urbanized living, entirely changing the way we had been living. All these were innovation that quickly blended with our lifestyles.  \n  \nWhile the pace of technological change is making our heads spin, we tend to think of our age as the most innovative ever. We have smartphones and super computers, big data and nano technologies, gene therapy and stem cell transplants. Yet nobody recently has come up with an innovation half as useful as that took place half a century before.  \n  \nTake kitchens. Going by the data of American households, in 1900 kitchens in even the poshest of households had primitive things. Most households lacked electric lighting and running water. Fast forward to 1970 and middle class kitchens in America and Europe featured gas and electric hobs and ovens, fridges, food processors, microwaves and dishwashers. Move forward to another 40 years, things have scarcely changed. We are still relying on the same obsolete devices and techniques.  \n  \nOr take speed. In the 19th century horses and sailboats were replaced by railways and steamships. Internal-combustion engines and jet turbines made it possible to move more and more things faster and faster. By this time, considering the same growth rate, we must be commuting to the moon! But since the 1970s humanity has been coasting. Highway travel is little faster than it was decades ago; indeed, endemic congestion has many cities now reverting back their investment in bicycles. Supersonic passenger travel has been abandoned.  \n  \nMedicine offers another example. Life expectancy at birth in India soared from 32 years to 65 years since independence. Enormous technical advances have occurred since that time. Despite crores spent on research, people continue to fall to cancer, heart disease, stroke and organ failure. Molecular medicine has come nowhere close to matching the effects of improved sanitation.  \n  \nWhat we are witnessing is a series of improvements to an existing product, that usually helps to maintain or improve its competitive position overtime, termed as ‘incremental innovation’. android has come up with alpha, beta, cupcake, doughnut,… marshmallow. Apple has come up with iphone 1gen, 3G, 3GS, 4, 4S, 5, 5S, 6 and 6 Plus... Recently smart wearables have cropped up. These products only add to the aspirational value to their previous variant. But why is this that we are lacking innovation? May be because it is the safest bet for manufacturers. It saves them from investing hugely in R&D, which have unpredictable outcomes.  \n  \nInnovation, in its present form, is just an illusion, something that has been exaggerated to fit into our fantasies. So, I guess, the ‘real thing’ is yet to come, something, that revolutionizes our lifestyle, our culture, our world. Hopefully, the innovation engine will once again set itself to energize growth once more, in not too distant future.\n"
            },
            "published": "2015-12-19T22:03:00+05:30"
          }
        }
      ]
    }
  }
}
